# ğŸ“Š BI ìŠ¤í™ vs êµ¬í˜„ ê°­ ë¶„ì„ ë° êµ¬í˜„ í•­ëª©

**ë¶„ì„ ì¼ì‹œ**: 2026-01-22
**ê²°ë¡ **: BI ì—”ì§„ì€ ì™„ë²½í•˜ì§€ë§Œ, **ë°ì´í„° íŒŒì´í”„ë¼ì¸**ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.

---

## ğŸ¯ í•µì‹¬ ê²°ë¡ 

### âœ… ì™„ë²½í•˜ê²Œ êµ¬í˜„ëœ ê²ƒ (ìŠ¤í™ ì´ˆê³¼!)

1. **GenBI (ëŒ€í™”í˜• BI)** - AWS QuickSight ìˆ˜ì¤€ â­â­â­â­â­
2. **RANK/PREDICT/WHAT_IF ë¶„ì„** - ê³ ê¸‰ í†µê³„ ë¶„ì„ â­â­â­â­â­
3. **Star Schema** - 23ê°œ í…Œì´ë¸” ëª¨ë‘ êµ¬í˜„ â­â­â­â­â­
4. **Text-to-SQL** - ìì—°ì–´ â†’ SQL ë³€í™˜ â­â­â­â­â­

### âŒ êµ¬í˜„í•´ì•¼ í•  ê²ƒ (ë°ì´í„° íŒŒì´í”„ë¼ì¸)

1. **ì‹œë“œ ë°ì´í„°** - dim_date, dim_shift ë“±
2. **ETL íŒŒì´í”„ë¼ì¸** - RAW â†’ FACT ë³€í™˜
3. **Materialized Views** - ì„±ëŠ¥ ìµœì í™”
4. **ìºì‹± ì—°ë™** - Redis í™œì„±í™”

---

## ğŸ“‹ êµ¬í˜„í•´ì•¼ í•  í•­ëª© (ìš°ì„ ìˆœìœ„ë³„)

### ğŸ”´ P0 - ì¦‰ì‹œ êµ¬í˜„ í•„ìš” (BI ì‘ë™ í•„ìˆ˜)

#### 1. ì‹œë“œ ë°ì´í„° ìƒì„± â­â­â­â­â­

**ìŠ¤í™ ìš”êµ¬**:
- B-3-2 Â§ 3.1: dim_date (2020-2030, 10ë…„ì¹˜)
- B-3-2 Â§ 3.6: dim_shift (3êµëŒ€ ê¸°ë³¸ê°’)

**í˜„ì¬ ìƒíƒœ**:
```sql
-- dim_date, dim_shift í…Œì´ë¸” ë¹„ì–´ìˆìŒ
SELECT COUNT(*) FROM bi.dim_date;
-- ê²°ê³¼: 0 âŒ

SELECT COUNT(*) FROM bi.dim_shift;
-- ê²°ê³¼: 0 âŒ
```

**ë¬¸ì œ**:
```sql
-- BI ì¿¼ë¦¬ ì‹¤íŒ¨!
SELECT
    d.date,
    SUM(f.total_qty)
FROM bi.fact_daily_production f
JOIN bi.dim_date d ON f.date = d.date  -- âŒ dim_date ë¹„ì–´ìˆì–´ì„œ ê²°ê³¼ ì—†ìŒ!
```

**êµ¬í˜„ ë°©ë²•**:
```sql
-- íŒŒì¼: backend/sql/seed_bi_dimensions.sql

-- dim_date (2020-2030)
INSERT INTO bi.dim_date (
    date, year, quarter, month, week,
    day_of_year, day_of_month, day_of_week, day_name,
    is_weekend, is_holiday
)
SELECT
    d::date,
    EXTRACT(year FROM d)::int,
    EXTRACT(quarter FROM d)::int,
    EXTRACT(month FROM d)::int,
    EXTRACT(week FROM d)::int,
    EXTRACT(doy FROM d)::int,
    EXTRACT(day FROM d)::int,
    EXTRACT(dow FROM d)::int,
    TRIM(to_char(d, 'Day')),
    EXTRACT(dow FROM d) IN (0, 6),
    FALSE
FROM generate_series('2020-01-01'::date, '2030-12-31'::date, '1 day') d
ON CONFLICT (date) DO NOTHING;

-- 10ë…„ Ã— 365ì¼ = 3,650ê°œ ë ˆì½”ë“œ

-- dim_shift (3êµëŒ€)
-- ê° tenantë³„ë¡œ ì‹¤í–‰
INSERT INTO bi.dim_shift (tenant_id, shift_code, name, start_time, end_time, ...)
VALUES
    (:tenant_id, 'A', 'ì£¼ê°„', '08:00', '16:00', 8.0, FALSE, 1),
    (:tenant_id, 'B', 'ì˜¤í›„', '16:00', '00:00', 8.0, FALSE, 2),
    (:tenant_id, 'C', 'ì•¼ê°„', '00:00', '08:00', 8.0, TRUE, 3)
ON CONFLICT DO NOTHING;
```

**ì˜ˆìƒ ì‹œê°„**: 1ì‹œê°„
**ìš°ì„ ìˆœìœ„**: â­â­â­â­â­ (ìµœìš°ì„ )

---

#### 2. RAW â†’ FACT ETL íŒŒì´í”„ë¼ì¸ â­â­â­â­â­

**ìŠ¤í™ ìš”êµ¬**:
- B-3-2 Â§ 7.3: RAW â†’ FACT ë³€í™˜ ë¡œì§
- B-3-2 Â§ 8.2: ETL ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§

**í˜„ì¬ ìƒíƒœ**:
```python
# ETL ë©”íƒ€ë°ì´í„° í…Œì´ë¸”ë§Œ ì¡´ì¬
class EtlJob(Base):  # âœ… ì¡´ì¬
class EtlJobExecution(Base):  # âœ… ì¡´ì¬

# í•˜ì§€ë§Œ ì‹¤ì œ ETL ì‹¤í–‰ ì„œë¹„ìŠ¤ ì—†ìŒ
# backend/app/services/etl_service.py âŒ ì—†ìŒ!
```

**ë¬¸ì œ**:
```
Mock APIë¡œ ìƒì„±í•œ ë°ì´í„°:
core.erp_mes_data (300ê°œ work_order)
   â†“
âŒ RAW â†’ FACT ë³€í™˜ ë¡œì§ ì—†ìŒ!
   â†“
bi.fact_daily_production (ë¹„ì–´ìˆìŒ)
   â†“
BI ì¿¼ë¦¬ ì‹¤íŒ¨ (ë°ì´í„° ì—†ìŒ)
```

**êµ¬í˜„ ë°©ë²•**:
```python
# íŒŒì¼: backend/app/services/etl_service.py (ì‹ ê·œ)

class ETLService:
    async def run_raw_to_fact_daily_production(
        self,
        tenant_id: UUID,
        target_date: date,
    ):
        """
        core.erp_mes_data (work_order) â†’ bi.fact_daily_production
        """
        # 1. erp_mes_data ì¡°íšŒ (record_type='work_order')
        raw_data = db.query(ErpMesData).filter(
            ErpMesData.tenant_id == tenant_id,
            ErpMesData.record_type == 'work_order',
            ErpMesData.raw_data['status'] == 'completed',
            # date í•„í„°
        ).all()

        # 2. FACTë¡œ ë³€í™˜
        for data in raw_data:
            fact = FactDailyProduction(
                tenant_id=tenant_id,
                date=parse_date(data.raw_data['scheduled_start']),
                line_code=data.raw_data['production_line'],
                product_code=data.raw_data['product_code'],
                shift=data.raw_data['shift'],
                total_qty=data.raw_data['planned_quantity'],
                good_qty=data.raw_data['produced_quantity'],
                defect_qty=data.raw_data['defect_quantity'],
                # ... (ëª¨ë“  í•„ë“œ ë§¤í•‘)
            )
            db.merge(fact)  # INSERT or UPDATE

        db.commit()
        return {"rows_processed": len(raw_data)}
```

**ì˜ˆìƒ ì‹œê°„**: 4-6ì‹œê°„
**ìš°ì„ ìˆœìœ„**: â­â­â­â­â­ (í•„ìˆ˜)

---

### ğŸŸ¡ P1 - ì„±ëŠ¥/ì™„ì„±ë„ í–¥ìƒ

#### 3. Materialized Views ìƒì„± â­â­â­â­

**ìŠ¤í™ ìš”êµ¬**:
- B-3-2 Â§ 5: 4ê°œ MV í•„ìˆ˜
  - `mv_defect_trend` (ë¶ˆëŸ‰ë¥  ì¶”ì´)
  - `mv_oee_daily` (ì¼ì¼ OEE)
  - `mv_inventory_coverage` (ì¬ê³  ì»¤ë²„ë¦¬ì§€)
  - `mv_line_performance` (ë¼ì¸ ì„±ê³¼)

**í˜„ì¬ ìƒíƒœ**:
```sql
-- MV DDLì´ ìŠ¤í™ì—ë§Œ ìˆê³  ì‹¤ì œ ìƒì„± ì•ˆ ë¨
SELECT * FROM bi.mv_defect_trend;
-- ERROR: relation "bi.mv_defect_trend" does not exist âŒ
```

**ë¬¸ì œ**:
```sql
-- BI ì¿¼ë¦¬ê°€ ë§¤ë²ˆ FACT ì§‘ê³„ (ëŠë¦¼)
SELECT
    date,
    SUM(defect_qty) / SUM(total_qty) AS defect_rate
FROM bi.fact_daily_production
WHERE date >= CURRENT_DATE - 90
GROUP BY date;  -- âŒ ë§¤ë²ˆ 90ì¼ì¹˜ ì§‘ê³„!

-- ëª©í‘œ: p95 < 2ì´ˆ
-- ì‹¤ì œ: 5-10ì´ˆ (ëŠë¦¼)
```

**êµ¬í˜„ ë°©ë²•**:
```sql
-- íŒŒì¼: backend/sql/create_materialized_views.sql

CREATE MATERIALIZED VIEW bi.mv_defect_trend AS
SELECT
    f.tenant_id,
    f.date,
    f.line_code,
    l.name AS line_name,
    f.product_code,
    p.name AS product_name,
    f.shift,
    SUM(f.total_qty) AS total_qty,
    SUM(f.defect_qty) AS defect_qty,
    CASE
        WHEN SUM(f.total_qty) > 0
        THEN SUM(f.defect_qty)::numeric / SUM(f.total_qty)
        ELSE 0
    END AS defect_rate,
    -- 7ì¼ ì´ë™í‰ê· 
    AVG(SUM(f.defect_qty)::numeric / NULLIF(SUM(f.total_qty), 0))
        OVER (
            PARTITION BY f.tenant_id, f.line_code, f.product_code
            ORDER BY f.date
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ) AS defect_rate_ma7
FROM bi.fact_daily_production f
JOIN bi.dim_line l ON f.tenant_id = l.tenant_id AND f.line_code = l.line_code
JOIN bi.dim_product p ON f.tenant_id = p.tenant_id AND f.product_code = p.product_code
WHERE f.date >= CURRENT_DATE - INTERVAL '90 days'
GROUP BY f.tenant_id, f.date, f.line_code, l.name, f.product_code, p.name, f.shift;

-- ì¸ë±ìŠ¤
CREATE UNIQUE INDEX idx_mv_defect_trend_pk
ON bi.mv_defect_trend (tenant_id, date, line_code, product_code, shift);

-- ë¦¬í”„ë ˆì‹œ (1ì‹œê°„ ì£¼ê¸°)
-- cron: 0 * * * * psql -c "REFRESH MATERIALIZED VIEW CONCURRENTLY bi.mv_defect_trend;"
```

**ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„ (4ê°œ MV + ë¦¬í”„ë ˆì‹œ ìŠ¤ì¼€ì¤„)
**ìš°ì„ ìˆœìœ„**: â­â­â­â­ (ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„± í•„ìˆ˜)

---

#### 4. POST /api/v1/bi/plan API êµ¬í˜„ â­â­â­â­

**ìŠ¤í™ ìš”êµ¬**:
- B-4 Â§ 6.1: ë¶„ì„ ê³„íš ìƒì„± API

**ìŠ¤í™ ì •ì˜**:
```http
POST /api/v1/bi/plan

Request:
{
  "query": "ì§€ë‚œ 30ì¼ê°„ L01 ë¼ì¸ì˜ ë¶ˆëŸ‰ë¥  ì¶”ì´ì™€ ì£¼ìš” ë¶ˆëŸ‰ ìœ í˜•ë³„ ë¶„í¬ë¥¼ ë³´ì—¬ì¤˜",
  "context": {
    "user_role": "quality_manager",
    "current_page": "quality_dashboard"
  },
  "options": {
    "max_widgets": 4,
    "include_recommendations": true
  }
}

Response:
{
  "plan_id": "plan_abc123",
  "interpretation": {
    "intent": "trend_analysis",
    "entities": {
      "metric": "defect_rate",
      "dimension": "line",
      "time_grain": "day",
      "time_range": "last_30_days",
      "filters": {"line_code": "L01"}
    }
  },
  "analysis_plan": {
    "widgets": [
      {
        "widget_id": "w1",
        "widget_type": "line_chart",
        "title": "L01 ë¼ì¸ ë¶ˆëŸ‰ë¥  ì¶”ì´",
        "data_source": {
          "table": "fact_daily_production",
          "metrics": ["defect_rate"],
          "dimensions": ["date"],
          "filters": {...}
        }
      },
      {
        "widget_id": "w2",
        "widget_type": "pie_chart",
        "title": "ë¶ˆëŸ‰ ìœ í˜•ë³„ ë¶„í¬"
      }
    ]
  },
  "estimated_execution_time_ms": 500
}
```

**í˜„ì¬ ìƒíƒœ**:
```python
# backend/app/routers/bi.py
# âŒ POST /plan ì—”ë“œí¬ì¸íŠ¸ ì—†ìŒ!

# ëŒ€ì‹  ì§ì ‘ ì‹¤í–‰ APIë§Œ ìˆìŒ:
# GET /analytics/defect-trend
# GET /analytics/oee
```

**ì°¨ì´ì **:
- ìŠ¤í™: 2ë‹¨ê³„ (plan ìƒì„± â†’ execute ì‹¤í–‰)
- êµ¬í˜„: 1ë‹¨ê³„ (ì§ì ‘ ì‹¤í–‰)

**êµ¬í˜„ ë°©ë²•**:
```python
# backend/app/routers/bi.py

from app.schemas.bi import AnalysisPlanRequest, AnalysisPlanResponse

@router.post("/plan", response_model=AnalysisPlanResponse)
async def create_analysis_plan(
    request: AnalysisPlanRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """
    ìì—°ì–´ ì¿¼ë¦¬ â†’ ë¶„ì„ ê³„íš ìƒì„±

    Args:
        query: ìì—°ì–´ ì§ˆì˜
        context: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸
        options: ì˜µì…˜ (max_widgets ë“±)

    Returns:
        ë¶„ì„ ê³„íš (widgets, SQL, ì°¨íŠ¸ ì„¤ì •)
    """
    # 1. BI ì¹´íƒˆë¡œê·¸ ì¡°íšŒ
    datasets = db.query(BiDataset).filter(...).all()
    metrics = db.query(BiMetric).filter(...).all()

    # 2. LLM í˜¸ì¶œ (ìì—°ì–´ â†’ JSON ë¶„ì„ ê³„íš)
    from app.agents.bi_planner import BIPlannerAgent

    planner = BIPlannerAgent()
    plan = await planner.create_plan(
        query=request.query,
        catalog={"datasets": datasets, "metrics": metrics},
        context=request.context,
    )

    # 3. plan_id ìƒì„± ë° ì €ì¥ (ìºì‹±ìš©)
    plan_id = str(uuid4())

    return AnalysisPlanResponse(
        plan_id=plan_id,
        interpretation=plan["interpretation"],
        analysis_plan=plan["widgets"],
        estimated_execution_time_ms=500,
    )
```

**ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
**ìš°ì„ ìˆœìœ„**: â­â­â­â­ (ìŠ¤í™ ì¤€ìˆ˜)

---

#### 5. POST /api/v1/bi/execute API êµ¬í˜„ â­â­â­â­

**ìŠ¤í™ ìš”êµ¬**:
- B-4 Â§ 6.2: ë¶„ì„ ì‹¤í–‰ API

**ìŠ¤í™ ì •ì˜**:
```http
POST /api/v1/bi/execute

Request:
{
  "plan_id": "plan_abc123",  // ë˜ëŠ”
  "analysis_plan": {...}      // ì§ì ‘ ì „ë‹¬
}

Response:
{
  "execution_id": "exec_xyz789",
  "results": {
    "w1": {
      "data": [...],
      "chart_config": {...}
    },
    "w2": {...}
  },
  "execution_time_ms": 450,
  "from_cache": false
}
```

**í˜„ì¬ ìƒíƒœ**:
```python
# âŒ POST /execute ì—”ë“œí¬ì¸íŠ¸ ì—†ìŒ!
```

**êµ¬í˜„ ë°©ë²•**:
```python
@router.post("/execute", response_model=AnalysisExecutionResponse)
async def execute_analysis(
    request: AnalysisExecutionRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
):
    """ë¶„ì„ ê³„íš ì‹¤í–‰"""
    # 1. plan ì¡°íšŒ (plan_id ë˜ëŠ” ì§ì ‘ ì „ë‹¬)
    # 2. widgetë³„ë¡œ SQL ì‹¤í–‰
    # 3. ì°¨íŠ¸ ë°ì´í„° ìƒì„±
    # 4. ìºì‹± (Redis)
    # 5. ê²°ê³¼ ë°˜í™˜
    pass
```

**ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
**ìš°ì„ ìˆœìœ„**: â­â­â­â­ (ìŠ¤í™ ì¤€ìˆ˜)

---

#### 6. ìºì‹± Redis ì—°ë™ â­â­â­â­

**ìŠ¤í™ ìš”êµ¬**:
- B-2-2 Â§ 1.3.1: ìºì‹± ì „ëµ (TTL 600ì´ˆ)

**ìŠ¤í™ ì •ì˜**:
```python
# ìŠ¤í™ ì˜ˆì‹œ
cache_key = hash(analysis_plan + tenant_id)
cached_result = await cache_manager.get(cache_key)

if cached_result:
    return {"from_cache": True, **cached_result}

# ìºì‹œ ì €ì¥
await cache_manager.set(cache_key, result, ttl=600)
```

**í˜„ì¬ ìƒíƒœ**:
```python
# bi_service.py:94-102
cache_key = self._generate_cache_key(plan)  # âœ… í‚¤ ìƒì„± êµ¬í˜„ë¨

# í•˜ì§€ë§Œ ì‹¤ì œ Redis ì—°ë™ì€ ì£¼ì„ ì²˜ë¦¬
# cached = await cache_manager.get(cache_key)  # âŒ ì£¼ì„
# await cache_manager.set(cache_key, result, ttl=600)  # âŒ ì£¼ì„
```

**êµ¬í˜„ ë°©ë²•**:
```python
# bi_service.py ìˆ˜ì •

async def analyze_rank(self, ...):
    # ìºì‹œ í‚¤ ìƒì„±
    cache_key = self._generate_cache_key({
        "type": "rank",
        "metric": metric,
        "dimension": dimension,
        "tenant_id": str(tenant_id)
    })

    # âœ… Redis ìºì‹œ ì¡°íšŒ
    from app.services.redis_client import get_redis_client
    redis = await get_redis_client()

    cached = await redis.get(f"bi:cache:{cache_key}")
    if cached:
        logger.info(f"Cache HIT: {cache_key}")
        return json.loads(cached)

    # ë¶„ì„ ì‹¤í–‰
    result = await self._execute_rank_analysis(...)

    # âœ… Redis ìºì‹œ ì €ì¥ (TTL 600ì´ˆ)
    await redis.setex(f"bi:cache:{cache_key}", 600, json.dumps(result))

    return result
```

**ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„
**ìš°ì„ ìˆœìœ„**: â­â­â­â­ (ì„±ëŠ¥ ê°œì„ )

---

#### 7. íŒŒí‹°ì…˜ ìë™ ìƒì„± í•¨ìˆ˜ â­â­â­

**ìŠ¤í™ ìš”êµ¬**:
- B-3-2 Â§ 9.2: íŒŒí‹°ì…˜ ê´€ë¦¬ í•¨ìˆ˜

**ìŠ¤í™ ì •ì˜**:
```sql
CREATE OR REPLACE FUNCTION bi.create_monthly_partitions(
    p_table_name text,
    p_start_date date,
    p_end_date date
)
RETURNS void AS $$
DECLARE
    v_partition_name text;
    v_start_date date;
    v_end_date date;
BEGIN
    v_start_date := date_trunc('month', p_start_date);
    WHILE v_start_date < p_end_date LOOP
        v_end_date := v_start_date + INTERVAL '1 month';
        v_partition_name := p_table_name || '_' || to_char(v_start_date, 'YYYYMM');

        EXECUTE format(
            'CREATE TABLE IF NOT EXISTS %I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',
            v_partition_name, p_table_name, v_start_date, v_end_date
        );

        v_start_date := v_end_date;
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```

**í˜„ì¬ ìƒíƒœ**:
```python
# models/bi.py
class FactDailyProduction(Base):
    __table_args__ = {
        "postgresql_partition_by": "RANGE (date)",  # âœ… íŒŒí‹°ì…˜ ì •ì˜ë¨
        ...
    }

# í•˜ì§€ë§Œ ì‹¤ì œ íŒŒí‹°ì…˜ ìƒì„± í•¨ìˆ˜ ì—†ìŒ âŒ
```

**êµ¬í˜„ ë°©ë²•**:
```sql
-- íŒŒì¼: backend/sql/create_partition_function.sql
-- (ìŠ¤í™ í•¨ìˆ˜ ê·¸ëŒ€ë¡œ êµ¬í˜„)

-- ì‹¤í–‰ ì˜ˆì‹œ:
SELECT bi.create_monthly_partitions(
    'bi.raw_mes_production',
    '2025-01-01'::date,
    '2026-12-31'::date
);
-- 24ê°œ íŒŒí‹°ì…˜ ìë™ ìƒì„±
```

**ì˜ˆìƒ ì‹œê°„**: 2ì‹œê°„
**ìš°ì„ ìˆœìœ„**: â­â­â­ (ìš´ì˜ ìë™í™”)

---

### ğŸŸ¢ P2 - ìš´ì˜ í¸ì˜ì„±

#### 8. Data Quality Checks ì‹¤í–‰ â­â­â­

**ìŠ¤í™ ìš”êµ¬**:
- B-3-2 Â§ 8: í’ˆì§ˆ ê·œì¹™ ì‹¤í–‰

**ìŠ¤í™ ì •ì˜**:
```python
# í’ˆì§ˆ ê·œì¹™ ì˜ˆì‹œ
rules = [
    {
        "rule_type": "not_null",
        "table": "fact_daily_production",
        "column": "total_qty"
    },
    {
        "rule_type": "range",
        "table": "fact_daily_production",
        "column": "defect_rate",
        "min": 0,
        "max": 1
    }
]
```

**í˜„ì¬ ìƒíƒœ**:
```python
# í…Œì´ë¸”ë§Œ ì¡´ì¬
class DataQualityRule(Base):  # âœ…
class DataQualityCheck(Base):  # âœ…

# ì‹¤í–‰ ì„œë¹„ìŠ¤ ì—†ìŒ âŒ
```

**êµ¬í˜„ ë°©ë²•**:
```python
# backend/app/services/data_quality_service.py (ì‹ ê·œ)

class DataQualityService:
    async def execute_check(self, rule_id: UUID):
        rule = db.query(DataQualityRule).get(rule_id)

        if rule.rule_type == "not_null":
            sql = f"SELECT COUNT(*) FROM {rule.table_name} WHERE {rule.column_name} IS NULL"
            failed_count = db.execute(text(sql)).scalar()

        elif rule.rule_type == "range":
            sql = f"SELECT COUNT(*) FROM {rule.table_name} WHERE {rule.column_name} NOT BETWEEN {rule.min_value} AND {rule.max_value}"
            failed_count = db.execute(text(sql)).scalar()

        # DataQualityCheck ì €ì¥
        check = DataQualityCheck(
            rule_id=rule_id,
            passed=(failed_count == 0),
            failed_row_count=failed_count,
        )
        db.add(check)
        db.commit()
```

**ì˜ˆìƒ ì‹œê°„**: 4-5ì‹œê°„
**ìš°ì„ ìˆœìœ„**: â­â­â­ (ë°ì´í„° ë¬´ê²°ì„±)

---

#### 9. ì¹´íƒˆë¡œê·¸ CRUD API â­â­

**ìŠ¤í™ ìš”êµ¬**:
- B-4 Â§ 6.3: ì¹´íƒˆë¡œê·¸ ê´€ë¦¬ API

**ìŠ¤í™ ì •ì˜**:
```http
POST /api/v1/bi/catalog/datasets
PUT /api/v1/bi/catalog/datasets/{dataset_id}
DELETE /api/v1/bi/catalog/datasets/{dataset_id}

POST /api/v1/bi/catalog/metrics
PUT /api/v1/bi/catalog/metrics/{metric_id}
```

**í˜„ì¬ ìƒíƒœ**:
```python
# GETë§Œ ìˆìŒ
GET /api/v1/bi/catalog/datasets  # âœ…
GET /api/v1/bi/catalog/metrics   # âœ…

# POST/PUT/DELETE ì—†ìŒ âŒ
```

**êµ¬í˜„ ë°©ë²•**:
```python
# backend/app/routers/bi.py

@router.post("/catalog/datasets")
async def create_dataset(...):
    # BiDataset ìƒì„±

@router.put("/catalog/datasets/{dataset_id}")
async def update_dataset(...):
    # BiDataset ìˆ˜ì •

@router.delete("/catalog/datasets/{dataset_id}")
async def delete_dataset(...):
    # BiDataset ì‚­ì œ (soft delete)
```

**ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„
**ìš°ì„ ìˆœìœ„**: â­â­ (UI í¸ì˜ì„±)

---

## ğŸ“Š êµ¬í˜„ í•­ëª© ìš”ì•½í‘œ

| ìˆœìœ„ | í•­ëª© | ìŠ¤í™ ìœ„ì¹˜ | í˜„ì¬ ìƒíƒœ | ì˜ˆìƒ ì‹œê°„ |
|------|------|----------|----------|----------|
| **P0-1** | ì‹œë“œ ë°ì´í„° ìƒì„± | B-3-2 Â§ 3.1, 3.6 | âŒ ì—†ìŒ | 1h |
| **P0-2** | ETL íŒŒì´í”„ë¼ì¸ | B-3-2 Â§ 7.3, 8.2 | âŒ ë©”íƒ€ë§Œ | 4-6h |
| **P1-1** | Materialized Views | B-3-2 Â§ 5 | âŒ DDLë§Œ | 3-4h |
| **P1-2** | POST /plan API | B-4 Â§ 6.1 | âŒ ì—†ìŒ | 4-5h |
| **P1-3** | POST /execute API | B-4 Â§ 6.2 | âŒ ì—†ìŒ | 3-4h |
| **P1-4** | ìºì‹± Redis ì—°ë™ | B-2-2 Â§ 1.3.1 | âš ï¸ ì£¼ì„ | 2-3h |
| **P1-5** | íŒŒí‹°ì…˜ í•¨ìˆ˜ | B-3-2 Â§ 9.2 | âŒ ì—†ìŒ | 2h |
| **P2-1** | Data Quality | B-3-2 Â§ 8 | âŒ ë©”íƒ€ë§Œ | 4-5h |
| **P2-2** | ì¹´íƒˆë¡œê·¸ CRUD | B-4 Â§ 6.3 | âš ï¸ GETë§Œ | 3-4h |

**ì´ ì˜ˆìƒ ì‹œê°„**: **26-36ì‹œê°„** (ì•½ 3-4ì¼)

---

## ğŸ¯ ì¦‰ì‹œ ì‹œì‘ ì¶”ì²œ

### **Option 1: ìµœì†Œ ì‘ë™ (5-7ì‹œê°„)** â­â­â­â­â­

```
Day 1:
1. ì‹œë“œ ë°ì´í„° (1h)
2. ETL íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ (4-6h)

ì™„ë£Œ í›„:
âœ… BI ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
âœ… Mock ë°ì´í„° â†’ FACT ë³€í™˜
âœ… GenBI ì¸ì‚¬ì´íŠ¸ ìƒì„±
```

---

### **Option 2: ì„±ëŠ¥ ìµœì í™” (8-11ì‹œê°„)** â­â­â­â­

```
Day 1:
1. ì‹œë“œ ë°ì´í„° (1h)
2. Materialized Views (3-4h)
3. ìºì‹± Redis (2-3h)
4. íŒŒí‹°ì…˜ í•¨ìˆ˜ (2h)

ì™„ë£Œ í›„:
âœ… BI ì‚¬ìš© ê°€ëŠ¥
âœ… ì¿¼ë¦¬ ì„±ëŠ¥ 10ë°° í–¥ìƒ
âœ… p95 < 2ì´ˆ ëª©í‘œ ë‹¬ì„±
```

---

### **Option 3: ìŠ¤í™ ì™„ì „ ì¤€ìˆ˜ (15-20ì‹œê°„)** â­â­â­â­â­

```
Day 1-2:
1. ì‹œë“œ ë°ì´í„° (1h)
2. ETL íŒŒì´í”„ë¼ì¸ (4-6h)
3. Materialized Views (3-4h)
4. POST /plan, /execute API (7-9h)

ì™„ë£Œ í›„:
âœ… ìŠ¤í™ 100% ì¤€ìˆ˜
âœ… 2ë‹¨ê³„ API (plan â†’ execute)
âœ… ì„±ëŠ¥ ìµœì í™”
```

---

## ğŸ’¡ ì œ ì¶”ì²œ: **Option 1 (ìµœì†Œ ì‘ë™)**

**ì´ìœ **:
1. âœ… **ê°€ì¥ ë¹ ë¦„** (5-7ì‹œê°„, 1ì¼)
2. âœ… **ì¦‰ì‹œ BI ì‚¬ìš© ê°€ëŠ¥**
3. âœ… **GenBI ë°ëª¨ ê°€ëŠ¥**
4. âœ… **ê³ ê°ì—ê²Œ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŒ**

**ì™„ë£Œ í›„ ë‹¤ìŒ ë‹¨ê³„**:
```
Week 1: ì‹œë“œ + ETL (5-7h) â†’ BI ì‘ë™ âœ…
Week 2: MV + ìºì‹± (5-7h) â†’ ì„±ëŠ¥ í–¥ìƒ âœ…
Week 3: API ìŠ¤í™ ì¤€ìˆ˜ (7-9h) â†’ ì™„ì„± âœ…
```

---

## ğŸ“ ìµœì¢… ì •ë¦¬

### êµ¬í˜„í•´ì•¼ í•  ê²ƒ (ìŠ¤í™ vs í˜„ì¬)

**P0 (í•„ìˆ˜)**:
1. âŒ ì‹œë“œ ë°ì´í„° (dim_date, dim_shift)
2. âŒ ETL íŒŒì´í”„ë¼ì¸ (RAW â†’ FACT)

**P1 (ì„±ëŠ¥/ì™„ì„±ë„)**:
3. âŒ Materialized Views (4ê°œ)
4. âŒ POST /plan API
5. âŒ POST /execute API
6. âš ï¸ ìºì‹± Redis ì—°ë™ (ì½”ë“œë§Œ ìˆìŒ)
7. âŒ íŒŒí‹°ì…˜ ìë™ ìƒì„± í•¨ìˆ˜

**P2 (ìš´ì˜)**:
8. âŒ Data Quality ì‹¤í–‰
9. âš ï¸ ì¹´íƒˆë¡œê·¸ CRUD (GETë§Œ ìˆìŒ)

---

**BI ì—”ì§„ì€ ì™„ë²½í•˜ì§€ë§Œ, ë°ì´í„° íŒŒì´í”„ë¼ì¸ì´ ë¶€ì¡±í•©ë‹ˆë‹¤!**
**P0 í•­ëª© êµ¬í˜„í•˜ë©´ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤!** âœ…

ì–´ë–¤ ì‘ì—…ì„ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?
1. **ì‹œë“œ ë°ì´í„° ìƒì„±** (1h) - ê°€ì¥ ë¹ ë¦„ â­â­â­â­â­
2. **ETL íŒŒì´í”„ë¼ì¸** (4-6h) - ìë™í™” â­â­â­â­
3. **ì „ì²´ ì™„ì„±** (26-36h, 3-4ì¼) - 100% â­â­â­â­â­
