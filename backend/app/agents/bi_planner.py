"""
BI Planner Agent
Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Î∞è Ï∞®Ìä∏ ÏÉùÏÑ± (Text-to-SQL)

V2 Phase 2 ÌôïÏû•:
- RANK Î∂ÑÏÑù (ÏÉÅÏúÑ/ÌïòÏúÑ NÍ∞ú, Î∞±Î∂ÑÏúÑ)
- PREDICT Î∂ÑÏÑù (Ïù¥ÎèôÌèâÍ∑†, ÏÑ†ÌòïÌöåÍ∑Ä)
- WHAT_IF ÏãúÎÆ¨Î†àÏù¥ÏÖò

V2 Phase 3 ÌôïÏû• (GenBI):
- refine_chart: Ï∞®Ìä∏ ÏàòÏ†ï (Refinement Loop)
- generate_insight: AI Ïù∏ÏÇ¨Ïù¥Ìä∏ ÏÉùÏÑ± (Executive Summary)
"""
from typing import Any, Dict, List
import json
import logging
from pathlib import Path
from uuid import UUID

from .base_agent import BaseAgent
from app.tools.db import get_table_schema, execute_safe_sql
from app.services.bi_service import get_bi_service, TimeGranularity

logger = logging.getLogger(__name__)


class BIPlannerAgent(BaseAgent):
    """
    BI Planner Agent
    - Text-to-SQL: ÏûêÏó∞Ïñ¥Î•º SQL ÏøºÎ¶¨Î°ú Î≥ÄÌôò
    - Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù: ÏÑºÏÑú Îç∞Ïù¥ÌÑ∞, ÏÉùÏÇ∞ Îç∞Ïù¥ÌÑ∞, ÌíàÏßà Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù
    - ÏãúÍ∞ÅÌôî ÏÑ§Í≥Ñ: Î∂ÑÏÑù Í≤∞Í≥ºÎ•º Ï∞®Ìä∏Î°ú ÌëúÌòÑ
    """

    def __init__(self):
        super().__init__(
            name="BIPlannerAgent",
            model="claude-sonnet-4-5-20250929",
            max_tokens=4096,
        )
        # ÎèÑÎ©îÏù∏ Î†àÏßÄÏä§Ìä∏Î¶¨
        from app.services.domain_registry import get_domain_registry
        self.domain_registry = get_domain_registry()

    def get_system_prompt(self, context: dict = None) -> str:
        """
        ÏãúÏä§ÌÖú ÌîÑÎ°¨ÌîÑÌä∏ Î°úÎìú + ÎèÑÎ©îÏù∏ Ïä§ÌÇ§Îßà ÎèôÏ†Å ÏÉùÏÑ± + Ïª®ÌÖçÏä§Ìä∏ ÌûåÌä∏
        """
        # Í∏∞Î≥∏ ÌîÑÎ°¨ÌîÑÌä∏ Î°úÎìú
        prompt_path = Path(__file__).parent.parent / "prompts" / "bi_planner.md"
        try:
            with open(prompt_path, "r", encoding="utf-8") as f:
                base_prompt = f.read()
        except FileNotFoundError:
            logger.warning(f"Prompt file not found: {prompt_path}, using default")
            base_prompt = "You are a BI Planner Agent for TriFlow AI."

        # Ïª®ÌÖçÏä§Ìä∏ ÌûåÌä∏ ÏÉùÏÑ±
        context_hint = ""
        if context:
            current_tab = context.get('current_tab')
            schema_hint = context.get('schema_hint')

            if current_tab == 'korea_biopharm' or schema_hint == 'korea_biopharm':
                context_hint = """
## üéØ CURRENT CONTEXT: ÌïúÍµ≠Î∞îÏù¥Ïò§Ìåú (Korea Biopharm)

ÏÇ¨Ïö©ÏûêÎäî ÌòÑÏû¨ **ÌïúÍµ≠Î∞îÏù¥Ïò§Ìåú ÌÉ≠**Ïóê ÏûàÏäµÎãàÎã§!

**ÏûêÎèô Ïä§ÌÇ§Îßà ÏÑ†ÌÉù**:
- Ï†úÌíà, Î†àÏãúÌîº, ÏÑ±Î∂Ñ, ÏõêÎ£å, Î∞∞Ìï© Í¥ÄÎ†® ÏßàÎ¨∏ ‚Üí **korea_biopharm Ïä§ÌÇ§Îßà** Ïö∞ÏÑ† ÏÇ¨Ïö©
- Ï£ºÏöî ÌÖåÏù¥Î∏î:
  * `recipe_metadata` - Î†àÏãúÌîº Î©îÌÉÄÎç∞Ïù¥ÌÑ∞
  * `historical_recipes` - Î∞∞Ìï© ÏÉÅÏÑ∏
  * `ingredient` - ÏõêÎ£å Ï†ïÎ≥¥

**Ï§ëÏöî Í∑úÏπô**:
1. ÎπÑÌÉÄÎØº, Ï†úÌíàÎ™Ö, ÌöåÏÇ¨Î™Ö Îì± ‚Üí korea_biopharm Ïä§ÌÇ§Îßà
2. Ïò®ÎèÑ, ÏïïÎ†•, LINE_A Îì± ‚Üí core Ïä§ÌÇ§Îßà (ÏÑºÏÑú Îç∞Ïù¥ÌÑ∞)
3. ÏùòÏã¨Ïä§Îü¨Ïö∞Î©¥ korea_biopharm Ïö∞ÏÑ†!

---
"""

        # ÎèÑÎ©îÏù∏ Ïä§ÌÇ§Îßà Ï†ïÎ≥¥ ÎèôÏ†Å ÏÉùÏÑ± (ÏóêÎü¨ Î∞úÏÉù Ïãú Í∏∞Î≥∏ ÌîÑÎ°¨ÌîÑÌä∏Îßå ÏÇ¨Ïö©)
        try:
            domain_schemas = self.domain_registry.generate_schema_docs()

            # ÎèÑÎ©îÏù∏ ÌÇ§ÏõåÎìú Ìä∏Î¶¨Í±∞ ÏÉùÏÑ±
            trigger_section = f"""
## üî• DOMAIN KEYWORD TRIGGERS üî•

ÏÇ¨Ïö©ÏûêÍ∞Ä Îã§Ïùå ÌÇ§ÏõåÎìúÎ•º Ïñ∏Í∏âÌïòÎ©¥ Ìï¥Îãπ Î™®Îìà Ïä§ÌÇ§Îßà ÏÇ¨Ïö©:

{self._generate_keyword_table()}

**Ï§ëÏöî**: Ïù¥ ÌÇ§ÏõåÎìúÎì§ÏùÄ Ï†úÏ°∞ ÏÑºÏÑú Îç∞Ïù¥ÌÑ∞(LINE_A, Ïò®ÎèÑ, ÏïïÎ†•)ÏôÄ Î¨¥Í¥ÄÌï©ÎãàÎã§!

---
"""

            # ÏµúÏ¢Ö ÌîÑÎ°¨ÌîÑÌä∏ Ï°∞Ìï©
            return f"{context_hint}{trigger_section}\n{base_prompt}\n\n{domain_schemas}"
        except Exception as e:
            logger.error(f"Failed to generate dynamic prompt, using base prompt only: {e}")
            return f"{context_hint}{base_prompt}"

    def _generate_keyword_table(self) -> str:
        """ÎèÑÎ©îÏù∏ ÌÇ§ÏõåÎìú ÌÖåÏù¥Î∏î ÏÉùÏÑ±"""
        if not self.domain_registry.domains:
            return "(Îì±Î°ùÎêú ÎèÑÎ©îÏù∏ ÏóÜÏùå)"

        rows = []
        for domain in self.domain_registry.domains.values():
            keywords_str = ", ".join(domain.keywords[:5])
            if len(domain.keywords) > 5:
                keywords_str += f" (Ïô∏ {len(domain.keywords) - 5}Í∞ú)"

            rows.append(f"- **{domain.name}**: {keywords_str} ‚Üí `{domain.schema_name}` Ïä§ÌÇ§Îßà")

        return "\n".join(rows)

    def get_tools(self) -> List[Dict[str, Any]]:
        """
        BI Planner AgentÏùò Tool Ï†ïÏùò (ÎèôÏ†Å Ïä§ÌÇ§Îßà enum)
        """
        # ÎèôÏ†Å Ïä§ÌÇ§Îßà Î™©Î°ù ÏÉùÏÑ± (ÏóêÎü¨ Î∞úÏÉù Ïãú Í∏∞Î≥∏ Ïä§ÌÇ§ÎßàÎßå ÏÇ¨Ïö©)
        try:
            allowed_schemas = self.domain_registry.get_all_schemas()
        except Exception as e:
            logger.error(f"Failed to get dynamic schemas, using defaults: {e}")
            allowed_schemas = ["core", "bi", "rag", "audit", "korea_biopharm"]

        return [
            {
                "name": "get_table_schema",
                "description": "Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌÖåÏù¥Î∏î Ïä§ÌÇ§ÎßàÎ•º Ï°∞ÌöåÌï©ÎãàÎã§.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "table_name": {
                            "type": "string",
                            "description": "Ï°∞ÌöåÌï† ÌÖåÏù¥Î∏î Ïù¥Î¶Ñ (Ïòà: sensor_data, judgment_executions, recipe_metadata, historical_recipes)",
                        },
                        "schema": {
                            "type": "string",
                            "description": "Ïä§ÌÇ§Îßà Ïù¥Î¶Ñ (Í∏∞Î≥∏Í∞í: core)",
                            "enum": allowed_schemas,  # ÎèôÏ†Å ÏÉùÏÑ±!
                            "default": "core",
                        },
                    },
                    "required": ["table_name"],
                },
            },
            {
                "name": "execute_safe_sql",
                "description": "ÏïàÏ†ÑÌïú SQL ÏøºÎ¶¨Î•º Ïã§ÌñâÌï©ÎãàÎã§ (SELECTÎßå ÌóàÏö©). CRITICAL: tenant_id ÌïÑÌÑ∞ ÌïÑÏàò!",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "sql_query": {
                            "type": "string",
                            "description": "Ïã§ÌñâÌï† SQL ÏøºÎ¶¨ (SELECT Î¨∏Îßå ÌóàÏö©). Î∞òÎìúÏãú tenant_id ÌïÑÌÑ∞ Ìè¨Ìï® ÌïÑÏöî. ÌååÎùºÎØ∏ÌÑ∞Îäî :param_name ÌòïÏãù ÏÇ¨Ïö©.",
                        },
                        "params": {
                            "type": "object",
                            "description": "ÏøºÎ¶¨ ÌååÎùºÎØ∏ÌÑ∞ (SQL Injection Î∞©ÏßÄÏö©)",
                        },
                    },
                    "required": ["sql_query"],
                },
            },
            {
                "name": "generate_chart_config",
                "description": "Î∂ÑÏÑù Í≤∞Í≥ºÎ•º ÏãúÍ∞ÅÌôîÌï† Ï∞®Ìä∏ ÏÑ§Ï†ïÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "data": {
                            "type": "array",
                            "description": "Ï∞®Ìä∏Ïóê ÌëúÏãúÌï† Îç∞Ïù¥ÌÑ∞ (JSON Î∞∞Ïó¥)",
                        },
                        "chart_type": {
                            "type": "string",
                            "description": "Ï∞®Ìä∏ Ïú†Ìòï",
                            "enum": ["line", "bar", "pie", "area", "scatter", "table"],
                        },
                        "analysis_goal": {
                            "type": "string",
                            "description": "Î∂ÑÏÑù Î™©Ï†Å (Ïòà: Ï∂îÏù¥ Î∂ÑÏÑù, ÎπÑÍµê, Î∂ÑÌè¨)",
                        },
                        "x_axis": {
                            "type": "string",
                            "description": "XÏ∂ï Îç∞Ïù¥ÌÑ∞ ÌÇ§ (line, bar, area, scatterÏóêÏÑú ÌïÑÏàò)",
                        },
                        "y_axis": {
                            "type": "string",
                            "description": "YÏ∂ï Îç∞Ïù¥ÌÑ∞ ÌÇ§ (line, bar, area, scatterÏóêÏÑú ÌïÑÏàò)",
                        },
                        "group_by": {
                            "type": "string",
                            "description": "Í∑∏Î£πÌôî Í∏∞Ï§Ä (ÏÑ†ÌÉù)",
                        },
                    },
                    "required": ["data", "chart_type", "analysis_goal"],
                },
            },
            # V2 Phase 2: RANK Î∂ÑÏÑù
            {
                "name": "analyze_rank",
                "description": "RANK Î∂ÑÏÑù: ÏÉÅÏúÑ/ÌïòÏúÑ NÍ∞ú Ìï≠Î™©ÏùÑ Î∂ÑÏÑùÌï©ÎãàÎã§. Î∂àÎüâÎ•†, ÏÉùÏÇ∞Îüâ, Ïò®ÎèÑ Îì±Ïùò ÏàúÏúÑÎ•º Ï∞®ÏõêÎ≥ÑÎ°ú Î∂ÑÏÑùÌï† Îïå ÏÇ¨Ïö©Ìï©ÎãàÎã§.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "tenant_id": {
                            "type": "string",
                            "description": "ÌÖåÎÑåÌä∏ ID (UUID)",
                        },
                        "metric": {
                            "type": "string",
                            "description": "Î∂ÑÏÑù ÏßÄÌëú",
                            "enum": [
                                "defect_rate", "production_count", "defect_count",
                                "avg_confidence", "avg_execution_time",
                                "avg_temperature", "max_temperature", "min_temperature",
                                "avg_value", "sum_value"
                            ],
                        },
                        "dimension": {
                            "type": "string",
                            "description": "Í∑∏Î£πÌôî Ï∞®Ïõê (Ïòà: line_code, sensor_type, shift, ruleset_id)",
                        },
                        "limit": {
                            "type": "integer",
                            "description": "Î∞òÌôòÌï† Ìï≠Î™© Ïàò (Í∏∞Î≥∏ 5)",
                            "default": 5,
                        },
                        "order": {
                            "type": "string",
                            "description": "Ï†ïÎ†¨ ÏàúÏÑú: desc=ÏÉÅÏúÑ, asc=ÌïòÏúÑ",
                            "enum": ["desc", "asc"],
                            "default": "desc",
                        },
                        "time_range_days": {
                            "type": "integer",
                            "description": "Î∂ÑÏÑù Í∏∞Í∞Ñ (Ïùº, Í∏∞Î≥∏ 7)",
                            "default": 7,
                        },
                    },
                    "required": ["tenant_id", "metric", "dimension"],
                },
            },
            # V2 Phase 2: PREDICT Î∂ÑÏÑù
            {
                "name": "analyze_predict",
                "description": "PREDICT Î∂ÑÏÑù: ÏãúÍ≥ÑÏó¥ ÏòàÏ∏°ÏùÑ ÏàòÌñâÌï©ÎãàÎã§. Ïù¥ÎèôÌèâÍ∑† ÎòêÎäî ÏÑ†ÌòïÌöåÍ∑Ä Í∏∞Î∞òÏúºÎ°ú ÎØ∏Îûò Í∞íÏùÑ ÏòàÏ∏°Ìï©ÎãàÎã§.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "tenant_id": {
                            "type": "string",
                            "description": "ÌÖåÎÑåÌä∏ ID (UUID)",
                        },
                        "metric": {
                            "type": "string",
                            "description": "ÏòàÏ∏° ÏßÄÌëú",
                            "enum": [
                                "defect_rate", "production_count",
                                "avg_temperature", "avg_value"
                            ],
                        },
                        "dimension": {
                            "type": "string",
                            "description": "Í∑∏Î£πÌôî Ï∞®Ïõê (ÏÑ†ÌÉù)",
                        },
                        "time_range_days": {
                            "type": "integer",
                            "description": "ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Í∏∞Í∞Ñ (Í∏∞Î≥∏ 30Ïùº)",
                            "default": 30,
                        },
                        "forecast_periods": {
                            "type": "integer",
                            "description": "ÏòàÏ∏° Í∏∞Í∞Ñ (Í∏∞Î≥∏ 7Ïùº)",
                            "default": 7,
                        },
                        "method": {
                            "type": "string",
                            "description": "ÏòàÏ∏° Î∞©Î≤ï",
                            "enum": ["moving_average", "linear_regression"],
                            "default": "moving_average",
                        },
                        "granularity": {
                            "type": "string",
                            "description": "ÏãúÍ∞Ñ Îã®ÏúÑ",
                            "enum": ["minute", "hour", "day", "week", "month"],
                            "default": "day",
                        },
                    },
                    "required": ["tenant_id", "metric"],
                },
            },
            # V2 Phase 2: WHAT_IF ÏãúÎÆ¨Î†àÏù¥ÏÖò
            {
                "name": "analyze_what_if",
                "description": "WHAT_IF ÏãúÎÆ¨Î†àÏù¥ÏÖò: Í∞ÄÏ†ï Í∏∞Î∞ò ÏòÅÌñ• Î∂ÑÏÑùÏùÑ ÏàòÌñâÌï©ÎãàÎã§. 'Ïò®ÎèÑÍ∞Ä 5ÎèÑ Ïò¨ÎùºÍ∞ÄÎ©¥ Î∂àÎüâÎ•†Ïù¥ Ïñ¥ÎñªÍ≤å Îê†Íπå?' Í∞ôÏùÄ ÏãúÎÇòÎ¶¨Ïò§ Î∂ÑÏÑùÏóê ÏÇ¨Ïö©Ìï©ÎãàÎã§.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "tenant_id": {
                            "type": "string",
                            "description": "ÌÖåÎÑåÌä∏ ID (UUID)",
                        },
                        "metric": {
                            "type": "string",
                            "description": "Î∂ÑÏÑù ÎåÄÏÉÅ Î©îÌä∏Î¶≠ (Ïòà: defect_rate)",
                        },
                        "dimension": {
                            "type": "string",
                            "description": "Î≥ÄÍ≤Ω Ï∞®Ïõê",
                        },
                        "baseline_value": {
                            "type": "number",
                            "description": "ÌòÑÏû¨ Í∏∞Ï§ÄÍ∞í (Ïòà: ÌòÑÏû¨ Î∂àÎüâÎ•† 2.5)",
                        },
                        "scenario_changes": {
                            "type": "object",
                            "description": "Î≥ÄÍ≤Ω ÏãúÎÇòÎ¶¨Ïò§ (Ïòà: {\"temperature\": 5, \"pressure\": -10})",
                            "additionalProperties": {
                                "type": "number"
                            },
                        },
                        "time_range_days": {
                            "type": "integer",
                            "description": "Í∏∞Ï§Ä Îç∞Ïù¥ÌÑ∞ Í∏∞Í∞Ñ (Í∏∞Î≥∏ 30Ïùº)",
                            "default": 30,
                        },
                    },
                    "required": ["tenant_id", "metric", "dimension", "baseline_value", "scenario_changes"],
                },
            },
            # V2 Phase 3 (GenBI): Chart Refinement
            {
                "name": "refine_chart",
                "description": "Í∏∞Ï°¥ Ï∞®Ìä∏Î•º ÏÇ¨Ïö©Ïûê ÏßÄÏãúÏóê Îî∞Îùº ÏàòÏ†ïÌï©ÎãàÎã§. Ï∞®Ìä∏ Ïú†Ìòï Î≥ÄÍ≤Ω(ÎßâÎåÄ‚ÜíÎùºÏù∏), ÏÉâÏÉÅ Î≥ÄÍ≤Ω, Ï†úÎ™© ÏàòÏ†ï, Ï∂ï Î†àÏù¥Î∏î Î≥ÄÍ≤Ω Îì±Ïóê ÏÇ¨Ïö©Ìï©ÎãàÎã§.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "original_config": {
                            "type": "object",
                            "description": "ÏõêÎ≥∏ Ï∞®Ìä∏ ÏÑ§Ï†ï (ChartConfig JSON)",
                        },
                        "instruction": {
                            "type": "string",
                            "description": "ÏàòÏ†ï ÏßÄÏãú (Ïòà: 'ÎßâÎåÄ Ï∞®Ìä∏Î°ú Î∞îÍøîÏ§ò', 'Ï†úÎ™©ÏùÑ ÏõîÎ≥Ñ ÏÉùÏÇ∞ÎüâÏúºÎ°ú Î≥ÄÍ≤Ω')",
                        },
                        "preserve_data": {
                            "type": "boolean",
                            "description": "Îç∞Ïù¥ÌÑ∞ Ïú†ÏßÄ Ïó¨Î∂Ä (Í∏∞Î≥∏ true)",
                            "default": True,
                        },
                    },
                    "required": ["original_config", "instruction"],
                },
            },
            # V2 Phase 3 (GenBI): AI Insight Generation
            {
                "name": "generate_insight",
                "description": "Ï∞®Ìä∏/Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú AI Ïù∏ÏÇ¨Ïù¥Ìä∏Î•º ÏÉùÏÑ±Ìï©ÎãàÎã§. AWS QuickSight GenBI Ïä§ÌÉÄÏùºÏùò Fact/Reasoning/Action Íµ¨Ï°∞Î°ú Executive SummaryÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "data": {
                            "type": "array",
                            "description": "Î∂ÑÏÑùÌï† Îç∞Ïù¥ÌÑ∞ (JSON Î∞∞Ïó¥)",
                        },
                        "chart_config": {
                            "type": "object",
                            "description": "Í¥ÄÎ†® Ï∞®Ìä∏ ÏÑ§Ï†ï (ÏÑ†ÌÉù)",
                        },
                        "focus_metrics": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "ÏßëÏ§ë Î∂ÑÏÑùÌï† Î©îÌä∏Î¶≠ Ïù¥Î¶Ñ Î™©Î°ù",
                        },
                        "time_range": {
                            "type": "string",
                            "description": "Î∂ÑÏÑù Í∏∞Í∞Ñ (Ïòà: '24h', '7d')",
                        },
                    },
                    "required": ["data"],
                },
            },
            # StatCard Í¥ÄÎ¶¨ ÎèÑÍµ¨
            {
                "name": "manage_stat_cards",
                "description": "ÎåÄÏãúÎ≥¥Îìú StatCardÎ•º Í¥ÄÎ¶¨Ìï©ÎãàÎã§. KPI, DB ÏøºÎ¶¨, MCP ÎèÑÍµ¨ Í∏∞Î∞ò Ïπ¥ÎìúÎ•º Ï∂îÍ∞Ä/ÏÇ≠Ï†ú/Ïû¨Ï†ïÎ†¨Ìï† Ïàò ÏûàÏäµÎãàÎã§. ÏÇ¨Ïö© Ïòà: 'OEE Ïπ¥Îìú Ï∂îÍ∞ÄÌï¥Ï§ò', 'Î∂àÎüâÎ•† Ïπ¥Îìú ÏÇ≠Ï†úÌï¥Ï§ò', 'ÌòÑÏû¨ Ïπ¥Îìú Î™©Î°ù Î≥¥Ïó¨Ï§ò'",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "action": {
                            "type": "string",
                            "description": "ÏàòÌñâÌï† Ïï°ÏÖò",
                            "enum": ["add_kpi", "add_db_query", "add_mcp", "remove", "list", "reorder"],
                        },
                        "tenant_id": {
                            "type": "string",
                            "description": "ÌÖåÎÑåÌä∏ ID (UUID)",
                        },
                        "user_id": {
                            "type": "string",
                            "description": "ÏÇ¨Ïö©Ïûê ID (UUID)",
                        },
                        # add_kpiÏö©
                        "kpi_code": {
                            "type": "string",
                            "description": "KPI ÏΩîÎìú (add_kpi Ïï°ÏÖòÏóêÏÑú ÏÇ¨Ïö©). Ïòà: defect_rate, oee, yield_rate, downtime",
                        },
                        # add_db_queryÏö©
                        "table_name": {
                            "type": "string",
                            "description": "ÌÖåÏù¥Î∏îÎ™Ö (add_db_query). Ïòà: fact_daily_production",
                        },
                        "column_name": {
                            "type": "string",
                            "description": "Ïª¨ÎüºÎ™Ö (add_db_query). Ïòà: defect_rate, production_count",
                        },
                        "aggregation": {
                            "type": "string",
                            "description": "ÏßëÍ≥Ñ Ìï®Ïàò (add_db_query)",
                            "enum": ["sum", "avg", "min", "max", "count", "last"],
                        },
                        # add_mcpÏö©
                        "mcp_server_id": {
                            "type": "string",
                            "description": "MCP ÏÑúÎ≤Ñ ID (add_mcp Ïï°ÏÖòÏóêÏÑú ÏÇ¨Ïö©)",
                        },
                        "mcp_tool_name": {
                            "type": "string",
                            "description": "MCP ÎèÑÍµ¨ Ïù¥Î¶Ñ (add_mcp Ïï°ÏÖòÏóêÏÑú ÏÇ¨Ïö©)",
                        },
                        # removeÏö©
                        "card_id": {
                            "type": "string",
                            "description": "ÏÇ≠Ï†úÌï† Ïπ¥Îìú ID (remove Ïï°ÏÖòÏóêÏÑú ÏÇ¨Ïö©)",
                        },
                        # reorderÏö©
                        "card_ids": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "ÏàúÏÑúÎåÄÎ°ú Ï†ïÎ†¨Îêú Ïπ¥Îìú ID Î™©Î°ù (reorder Ïï°ÏÖòÏóêÏÑú ÏÇ¨Ïö©)",
                        },
                        # Í≥µÌÜµ ÌëúÏãú ÏÑ§Ï†ï
                        "title": {
                            "type": "string",
                            "description": "Ïª§Ïä§ÌÖÄ Ïπ¥Îìú Ï†úÎ™© (ÏÑ†ÌÉù)",
                        },
                        "unit": {
                            "type": "string",
                            "description": "Ïª§Ïä§ÌÖÄ Îã®ÏúÑ (ÏÑ†ÌÉù). Ïòà: %, Í±¥, Í∞ú",
                        },
                        "icon": {
                            "type": "string",
                            "description": "ÏïÑÏù¥ÏΩò Ïù¥Î¶Ñ (ÏÑ†ÌÉù). Ïòà: BarChart3, AlertTriangle, Activity",
                        },
                    },
                    "required": ["action", "tenant_id", "user_id"],
                },
            },
        ]

    def execute_tool(self, tool_name: str, tool_input: Dict[str, Any]) -> Any:
        """
        Tool Ïã§Ìñâ
        """
        if tool_name == "get_table_schema":
            return self._get_table_schema(
                table_name=tool_input["table_name"],
                schema=tool_input.get("schema", "core"),
            )

        elif tool_name == "execute_safe_sql":
            return self._execute_safe_sql(
                sql_query=tool_input["sql_query"],
                params=tool_input.get("params"),
            )

        elif tool_name == "generate_chart_config":
            return self._generate_chart_config(
                data=tool_input["data"],
                chart_type=tool_input["chart_type"],
                analysis_goal=tool_input["analysis_goal"],
                x_axis=tool_input.get("x_axis"),
                y_axis=tool_input.get("y_axis"),
                group_by=tool_input.get("group_by"),
            )

        # V2 Phase 2: RANK Î∂ÑÏÑù
        elif tool_name == "analyze_rank":
            return self._analyze_rank(
                tenant_id=tool_input["tenant_id"],
                metric=tool_input["metric"],
                dimension=tool_input["dimension"],
                limit=tool_input.get("limit", 5),
                order=tool_input.get("order", "desc"),
                time_range_days=tool_input.get("time_range_days", 7),
            )

        # V2 Phase 2: PREDICT Î∂ÑÏÑù
        elif tool_name == "analyze_predict":
            return self._analyze_predict(
                tenant_id=tool_input["tenant_id"],
                metric=tool_input["metric"],
                dimension=tool_input.get("dimension"),
                time_range_days=tool_input.get("time_range_days", 30),
                forecast_periods=tool_input.get("forecast_periods", 7),
                method=tool_input.get("method", "moving_average"),
                granularity=tool_input.get("granularity", "day"),
            )

        # V2 Phase 2: WHAT_IF ÏãúÎÆ¨Î†àÏù¥ÏÖò
        elif tool_name == "analyze_what_if":
            return self._analyze_what_if(
                tenant_id=tool_input["tenant_id"],
                metric=tool_input["metric"],
                dimension=tool_input["dimension"],
                baseline_value=tool_input["baseline_value"],
                scenario_changes=tool_input["scenario_changes"],
                time_range_days=tool_input.get("time_range_days", 30),
            )

        # V2 Phase 3 (GenBI): Chart Refinement
        elif tool_name == "refine_chart":
            return self._refine_chart(
                original_config=tool_input["original_config"],
                instruction=tool_input["instruction"],
                preserve_data=tool_input.get("preserve_data", True),
            )

        # V2 Phase 3 (GenBI): AI Insight Generation
        elif tool_name == "generate_insight":
            return self._generate_insight(
                data=tool_input["data"],
                chart_config=tool_input.get("chart_config"),
                focus_metrics=tool_input.get("focus_metrics"),
                time_range=tool_input.get("time_range"),
            )

        # StatCard Í¥ÄÎ¶¨
        elif tool_name == "manage_stat_cards":
            return self._manage_stat_cards(
                action=tool_input["action"],
                tenant_id=tool_input["tenant_id"],
                user_id=tool_input["user_id"],
                kpi_code=tool_input.get("kpi_code"),
                table_name=tool_input.get("table_name"),
                column_name=tool_input.get("column_name"),
                aggregation=tool_input.get("aggregation"),
                mcp_server_id=tool_input.get("mcp_server_id"),
                mcp_tool_name=tool_input.get("mcp_tool_name"),
                card_id=tool_input.get("card_id"),
                card_ids=tool_input.get("card_ids"),
                title=tool_input.get("title"),
                unit=tool_input.get("unit"),
                icon=tool_input.get("icon"),
            )

        else:
            raise ValueError(f"Unknown tool: {tool_name}")

    def _get_table_schema(
        self,
        table_name: str,
        schema: str = "core",
    ) -> Dict[str, Any]:
        """
        ÌÖåÏù¥Î∏î Ïä§ÌÇ§Îßà Ï°∞Ìöå
        """
        try:
            schema_info = get_table_schema(schema, table_name)

            logger.info(f"Retrieved schema for {schema}.{table_name}: {len(schema_info['columns'])} columns")

            return {
                "success": True,
                "schema": schema,
                "table": table_name,
                "columns": schema_info["columns"],
            }

        except Exception as e:
            logger.error(f"Error getting table schema: {e}")
            return {
                "success": False,
                "error": str(e),
                "columns": [],
            }

    def _execute_safe_sql(
        self,
        sql_query: str,
        params: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """
        ÏïàÏ†ÑÌïú SQL ÏøºÎ¶¨ Ïã§Ìñâ
        """
        try:
            # tenant_id ÌïÑÌÑ∞ Ï≤¥ÌÅ¨ (Î≥¥Ïïà)
            if "tenant_id" not in sql_query.lower():
                logger.warning("SQL query without tenant_id filter - rejecting for security")
                return {
                    "success": False,
                    "error": "tenant_id filter is required for all queries (multi-tenant security)",
                    "data": [],
                }

            # SQL Ïã§Ìñâ
            results = execute_safe_sql(sql_query, params or {})

            logger.info(f"Executed SQL query: {len(results)} rows returned")

            return {
                "success": True,
                "row_count": len(results),
                "data": results,
            }

        except ValueError as e:
            # ÌóàÏö©ÎêòÏßÄ ÏïäÎäî SQL (SELECT Ïô∏)
            logger.error(f"Invalid SQL query: {e}")
            return {
                "success": False,
                "error": f"Only SELECT queries are allowed: {str(e)}",
                "data": [],
            }

        except Exception as e:
            # Í∏∞ÌÉÄ Ïã§Ìñâ ÏóêÎü¨
            logger.error(f"SQL execution error: {e}")
            return {
                "success": False,
                "error": str(e),
                "data": [],
            }

    def _generate_chart_config(
        self,
        data: List[Dict[str, Any]],
        chart_type: str,
        analysis_goal: str,
        x_axis: str = None,
        y_axis: str = None,
        group_by: str = None,
    ) -> Dict[str, Any]:
        """
        Ï∞®Ìä∏ ÏÑ§Ï†ï ÏÉùÏÑ± (Recharts Ìò∏Ìôò)
        """
        try:
            # Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù
            if not data or len(data) == 0:
                return {
                    "success": False,
                    "error": "No data provided for chart",
                }

            # Ï∞®Ìä∏ ÌÉÄÏûÖÎ≥Ñ ÏÑ§Ï†ï ÏÉùÏÑ±
            config = {
                "type": chart_type,
                "data": data,
                "analysis_goal": analysis_goal,
            }

            if chart_type == "line":
                config.update({
                    "xAxis": {"dataKey": x_axis or "date", "label": x_axis or "Date"},
                    "yAxis": {"label": y_axis or "Value"},
                    "lines": self._extract_numeric_keys(data, exclude=[x_axis]),
                })

            elif chart_type == "bar":
                config.update({
                    "xAxis": {"dataKey": x_axis or "category", "label": x_axis or "Category"},
                    "yAxis": {"label": y_axis or "Value"},
                    "bars": self._extract_numeric_keys(data, exclude=[x_axis]),
                })

            elif chart_type == "pie":
                config.update({
                    "nameKey": x_axis or "name",
                    "dataKey": y_axis or "value",
                })

            elif chart_type == "area":
                config.update({
                    "xAxis": {"dataKey": x_axis or "date", "label": x_axis or "Date"},
                    "yAxis": {"label": y_axis or "Value"},
                    "areas": self._extract_numeric_keys(data, exclude=[x_axis]),
                })

            elif chart_type == "scatter":
                config.update({
                    "xAxis": {"dataKey": x_axis, "label": x_axis},
                    "yAxis": {"dataKey": y_axis, "label": y_axis},
                })

            elif chart_type == "table":
                config.update({
                    "columns": list(data[0].keys()) if data else [],
                })

            logger.info(f"Generated chart config: {chart_type}, {len(data)} data points")

            return {
                "success": True,
                "config": config,
            }

        except Exception as e:
            logger.error(f"Error generating chart config: {e}")
            return {
                "success": False,
                "error": str(e),
            }

    def _extract_numeric_keys(
        self,
        data: List[Dict[str, Any]],
        exclude: List[str] = None,
    ) -> List[str]:
        """
        Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ïà´Ïûê ÌÉÄÏûÖ Ïª¨Îüº Ï∂îÏ∂ú (Ï∞®Ìä∏ ÏãúÎ¶¨Ï¶àÏö©)
        """
        if not data:
            return []

        exclude = exclude or []
        first_row = data[0]
        numeric_keys = []

        for key, value in first_row.items():
            if key in exclude:
                continue
            if isinstance(value, (int, float)):
                numeric_keys.append(key)

        return numeric_keys

    # =========================================
    # V2 Phase 2: Advanced Analysis Methods
    # =========================================

    def _analyze_rank(
        self,
        tenant_id: str,
        metric: str,
        dimension: str,
        limit: int = 5,
        order: str = "desc",
        time_range_days: int = 7,
    ) -> Dict[str, Any]:
        """
        RANK Î∂ÑÏÑù Ïã§Ìñâ (BIService ÏúÑÏûÑ)
        """
        import asyncio

        try:
            bi_service = get_bi_service()
            tenant_uuid = UUID(tenant_id)

            # ÎèôÍ∏∞ Ïª®ÌÖçÏä§Ìä∏ÏóêÏÑú ÎπÑÎèôÍ∏∞ Ìï®Ïàò Ìò∏Ï∂ú
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # Ïù¥ÎØ∏ Ïã§Ìñâ Ï§ëÏù∏ Ïù¥Î≤§Ìä∏ Î£®ÌîÑ ÎÇ¥ÏóêÏÑúÎäî ÏÉàÎ°úÏö¥ ÌÉúÏä§ÌÅ¨ ÏÉùÏÑ±
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(
                        asyncio.run,
                        bi_service.analyze_rank(
                            tenant_id=tenant_uuid,
                            metric=metric,
                            dimension=dimension,
                            limit=limit,
                            order=order,
                            time_range_days=time_range_days,
                        )
                    )
                    result = future.result()
            else:
                result = loop.run_until_complete(
                    bi_service.analyze_rank(
                        tenant_id=tenant_uuid,
                        metric=metric,
                        dimension=dimension,
                        limit=limit,
                        order=order,
                        time_range_days=time_range_days,
                    )
                )

            logger.info(f"RANK analysis completed: {len(result.data)} items")

            return {
                "success": True,
                "analysis_type": "rank",
                "data": result.data,
                "summary": result.summary,
                "chart_config": result.chart_config,
                "insights": result.insights,
                "metadata": result.metadata,
            }

        except Exception as e:
            logger.error(f"RANK analysis error: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis_type": "rank",
            }

    def _analyze_predict(
        self,
        tenant_id: str,
        metric: str,
        dimension: str = None,
        time_range_days: int = 30,
        forecast_periods: int = 7,
        method: str = "moving_average",
        granularity: str = "day",
    ) -> Dict[str, Any]:
        """
        PREDICT Î∂ÑÏÑù Ïã§Ìñâ (BIService ÏúÑÏûÑ)
        """
        import asyncio

        try:
            bi_service = get_bi_service()
            tenant_uuid = UUID(tenant_id)
            granularity_enum = TimeGranularity(granularity)

            loop = asyncio.get_event_loop()
            if loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(
                        asyncio.run,
                        bi_service.analyze_predict(
                            tenant_id=tenant_uuid,
                            metric=metric,
                            dimension=dimension,
                            time_range_days=time_range_days,
                            forecast_periods=forecast_periods,
                            method=method,
                            granularity=granularity_enum,
                        )
                    )
                    result = future.result()
            else:
                result = loop.run_until_complete(
                    bi_service.analyze_predict(
                        tenant_id=tenant_uuid,
                        metric=metric,
                        dimension=dimension,
                        time_range_days=time_range_days,
                        forecast_periods=forecast_periods,
                        method=method,
                        granularity=granularity_enum,
                    )
                )

            logger.info(f"PREDICT analysis completed: method={method}, periods={forecast_periods}")

            return {
                "success": True,
                "analysis_type": "predict",
                "data": result.data,
                "summary": result.summary,
                "chart_config": result.chart_config,
                "insights": result.insights,
                "metadata": result.metadata,
            }

        except Exception as e:
            logger.error(f"PREDICT analysis error: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis_type": "predict",
            }

    def _analyze_what_if(
        self,
        tenant_id: str,
        metric: str,
        dimension: str,
        baseline_value: float,
        scenario_changes: Dict[str, float],
        time_range_days: int = 30,
    ) -> Dict[str, Any]:
        """
        WHAT_IF ÏãúÎÆ¨Î†àÏù¥ÏÖò Ïã§Ìñâ (BIService ÏúÑÏûÑ)
        """
        import asyncio

        try:
            bi_service = get_bi_service()
            tenant_uuid = UUID(tenant_id)

            loop = asyncio.get_event_loop()
            if loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(
                        asyncio.run,
                        bi_service.analyze_what_if(
                            tenant_id=tenant_uuid,
                            metric=metric,
                            dimension=dimension,
                            baseline_value=baseline_value,
                            scenario_changes=scenario_changes,
                            time_range_days=time_range_days,
                        )
                    )
                    result = future.result()
            else:
                result = loop.run_until_complete(
                    bi_service.analyze_what_if(
                        tenant_id=tenant_uuid,
                        metric=metric,
                        dimension=dimension,
                        baseline_value=baseline_value,
                        scenario_changes=scenario_changes,
                        time_range_days=time_range_days,
                    )
                )

            logger.info(f"WHAT_IF analysis completed: baseline={baseline_value}, changes={scenario_changes}")

            return {
                "success": True,
                "analysis_type": "what_if",
                "data": result.data,
                "summary": result.summary,
                "chart_config": result.chart_config,
                "insights": result.insights,
                "metadata": result.metadata,
            }

        except Exception as e:
            logger.error(f"WHAT_IF analysis error: {e}")
            return {
                "success": False,
                "error": str(e),
                "analysis_type": "what_if",
            }

    # =========================================
    # V2 Phase 3 (GenBI): Chart Refinement & Insight
    # =========================================

    def _refine_chart(
        self,
        original_config: Dict[str, Any],
        instruction: str,
        preserve_data: bool = True,
    ) -> Dict[str, Any]:
        """
        Ï∞®Ìä∏ ÏàòÏ†ï (Refinement Loop)
        LLMÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏÇ¨Ïö©Ïûê ÏßÄÏãúÏóê Îî∞Îùº Ï∞®Ìä∏ ÏÑ§Ï†ïÏùÑ ÏàòÏ†ï
        """
        from anthropic import Anthropic
        from app.config import settings

        try:
            client = Anthropic(api_key=settings.anthropic_api_key)

            system_prompt = """ÎãπÏã†ÏùÄ Ï∞®Ìä∏ ÏàòÏ†ï Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.
ÏÇ¨Ïö©ÏûêÏùò ÏßÄÏãúÏóê Îî∞Îùº Ï∞®Ìä∏ ÏÑ§Ï†ïÏùÑ ÏàòÏ†ïÌï©ÎãàÎã§.

## Ï∞®Ìä∏ Ïú†Ìòï
- line: ÎùºÏù∏ Ï∞®Ìä∏ (Ï∂îÏÑ∏, ÏãúÍ≥ÑÏó¥)
- bar: ÎßâÎåÄ Ï∞®Ìä∏ (ÎπÑÍµê, Ïπ¥ÌÖåÍ≥†Î¶¨)
- pie: ÌååÏù¥ Ï∞®Ìä∏ (ÎπÑÏú®, Íµ¨ÏÑ±)
- area: ÏòÅÏó≠ Ï∞®Ìä∏ (ÎàÑÏ†Å, Ï∂îÏÑ∏)
- scatter: ÏÇ∞Ï†êÎèÑ (ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ)
- table: ÌÖåÏù¥Î∏î (ÏÉÅÏÑ∏ Îç∞Ïù¥ÌÑ∞)

## ÏàòÏ†ï Í∞ÄÎä• Ìï≠Î™©
- type: Ï∞®Ìä∏ Ïú†Ìòï Î≥ÄÍ≤Ω
- title: Ï†úÎ™© Î≥ÄÍ≤Ω
- xAxis.label, yAxis.label: Ï∂ï Î†àÏù¥Î∏î Î≥ÄÍ≤Ω
- colors: ÏÉâÏÉÅ Î≥ÄÍ≤Ω

## Ï∂úÎ†• ÌòïÏãù
Î∞òÎìúÏãú Îã§Ïùå JSON ÌòïÏãùÏúºÎ°ú Ï∂úÎ†•ÌïòÏÑ∏Ïöî:
```json
{
  "refined_config": { ... ÏàòÏ†ïÎêú Ï∞®Ìä∏ ÏÑ§Ï†ï ... },
  "changes_made": ["Î≥ÄÍ≤ΩÏÇ¨Ìï≠1", "Î≥ÄÍ≤ΩÏÇ¨Ìï≠2"]
}
```
"""

            user_message = f"""Îã§Ïùå Ï∞®Ìä∏ ÏÑ§Ï†ïÏùÑ ÏàòÏ†ïÌï¥Ï£ºÏÑ∏Ïöî.

## ÏõêÎ≥∏ Ï∞®Ìä∏ ÏÑ§Ï†ï
```json
{json.dumps(original_config, indent=2, ensure_ascii=False)}
```

## ÏàòÏ†ï ÏßÄÏãú
{instruction}

## ÏòµÏÖò
- Îç∞Ïù¥ÌÑ∞ Ïú†ÏßÄ: {preserve_data}

ÏúÑ ÏßÄÏãúÏóê Îî∞Îùº Ï∞®Ìä∏ ÏÑ§Ï†ïÏùÑ ÏàòÏ†ïÌïòÍ≥† JSON ÌòïÏãùÏúºÎ°ú Ï∂úÎ†•Ìï¥Ï£ºÏÑ∏Ïöî."""

            response = client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=2048,
                system=system_prompt,
                messages=[{"role": "user", "content": user_message}],
            )

            content = ""
            for block in response.content:
                if hasattr(block, "text"):
                    content += block.text

            # JSON ÌååÏã±
            json_start = content.find("{")
            json_end = content.rfind("}") + 1
            if json_start != -1 and json_end > json_start:
                result = json.loads(content[json_start:json_end])

                # Îç∞Ïù¥ÌÑ∞ Ïú†ÏßÄ ÏòµÏÖò Ï≤òÎ¶¨
                if preserve_data and "data" in original_config:
                    result["refined_config"]["data"] = original_config["data"]

                logger.info(f"Chart refined: {result.get('changes_made', [])}")

                return {
                    "success": True,
                    "refined_config": result.get("refined_config", original_config),
                    "changes_made": result.get("changes_made", []),
                }
            else:
                raise ValueError("No valid JSON in response")

        except Exception as e:
            logger.error(f"Chart refinement error: {e}")
            return {
                "success": False,
                "error": str(e),
                "refined_config": original_config,
                "changes_made": [],
            }

    def _generate_insight(
        self,
        data: List[Dict[str, Any]],
        chart_config: Dict[str, Any] = None,
        focus_metrics: List[str] = None,
        time_range: str = None,
    ) -> Dict[str, Any]:
        """
        AI Ïù∏ÏÇ¨Ïù¥Ìä∏ ÏÉùÏÑ± (Executive Summary)
        AWS QuickSight GenBI Ïä§ÌÉÄÏùºÏùò Fact/Reasoning/Action Íµ¨Ï°∞
        """
        from anthropic import Anthropic
        from app.config import settings

        try:
            client = Anthropic(api_key=settings.anthropic_api_key)

            system_prompt = """ÎãπÏã†ÏùÄ Ï†úÏ°∞ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.
Ï£ºÏñ¥ÏßÑ Îç∞Ïù¥ÌÑ∞Î•º Î∂ÑÏÑùÌïòÏó¨ AWS QuickSight GenBI Ïä§ÌÉÄÏùºÏùò Executive SummaryÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§.

## Ï∂úÎ†• ÌòïÏãù
Î∞òÎìúÏãú Îã§Ïùå JSON ÌòïÏãùÏúºÎ°ú Ï∂úÎ†•ÌïòÏÑ∏Ïöî:

```json
{
  "title": "Ïù∏ÏÇ¨Ïù¥Ìä∏ Ï†úÎ™©",
  "summary": "ÌïµÏã¨ ÏöîÏïΩ (1-2Î¨∏Ïû•)",
  "facts": [
    {
      "metric_name": "Î©îÌä∏Î¶≠ Ïù¥Î¶Ñ",
      "current_value": Ïà´Ïûê,
      "change_percent": Î≥ÄÌôîÏú® ÎòêÎäî null,
      "trend": "up" | "down" | "stable",
      "period": "Ï∏°Ï†ï Í∏∞Í∞Ñ",
      "unit": "Îã®ÏúÑ"
    }
  ],
  "reasoning": {
    "analysis": "Î∂ÑÏÑù ÎÇ¥Ïö© (2-3Î¨∏Ïû•)",
    "contributing_factors": ["ÏõêÏù∏1", "ÏõêÏù∏2"],
    "confidence": 0.0 ~ 1.0
  },
  "actions": [
    {
      "priority": "high" | "medium" | "low",
      "action": "Í∂åÏû• Ï°∞Ïπò",
      "expected_impact": "ÏòàÏÉÅ Ìö®Í≥º"
    }
  ]
}
```

## Ï†úÏ°∞ ÎèÑÎ©îÏù∏ ÏûÑÍ≥ÑÍ∞í
- Ïò®ÎèÑ: 70¬∞C Ï¥àÍ≥º Ï£ºÏùò, 80¬∞C Ï¥àÍ≥º ÏúÑÌóò
- ÏïïÎ†•: 8 bar Ï¥àÍ≥º Ï£ºÏùò, 10 bar Ï¥àÍ≥º ÏúÑÌóò
- ÏÉùÏÇ∞ Ìö®Ïú®: 90% Ïù¥ÏÉÅ Î™©Ìëú
"""

            data_str = json.dumps(data[:50], indent=2, ensure_ascii=False, default=str)

            user_message = f"""Îã§Ïùå Îç∞Ïù¥ÌÑ∞Î•º Î∂ÑÏÑùÌïòÏó¨ Executive SummaryÎ•º ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.

## Îç∞Ïù¥ÌÑ∞
```json
{data_str}
```

## Î∂ÑÏÑù Í∏∞Í∞Ñ
{time_range or "ÏµúÍ∑º 24ÏãúÍ∞Ñ"}
"""

            if focus_metrics:
                user_message += f"\n## ÏßëÏ§ë Î∂ÑÏÑù Î©îÌä∏Î¶≠\n{', '.join(focus_metrics)}\n"

            if chart_config:
                user_message += f"\n## Ï∞®Ìä∏ Ï†ïÎ≥¥\nÏú†Ìòï: {chart_config.get('type', 'unknown')}\nÎ™©Ï†Å: {chart_config.get('analysis_goal', 'N/A')}\n"

            response = client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=2048,
                system=system_prompt,
                messages=[{"role": "user", "content": user_message}],
            )

            content = ""
            for block in response.content:
                if hasattr(block, "text"):
                    content += block.text

            # JSON ÌååÏã±
            json_start = content.find("{")
            json_end = content.rfind("}") + 1
            if json_start != -1 and json_end > json_start:
                insight = json.loads(content[json_start:json_end])

                logger.info(
                    f"Insight generated: {len(insight.get('facts', []))} facts, "
                    f"{len(insight.get('actions', []))} actions"
                )

                return {
                    "success": True,
                    "insight": insight,
                }
            else:
                raise ValueError("No valid JSON in response")

        except Exception as e:
            logger.error(f"Insight generation error: {e}")
            return {
                "success": False,
                "error": str(e),
                "insight": {
                    "title": "Î∂ÑÏÑù Ïò§Î•ò",
                    "summary": str(e),
                    "facts": [],
                    "reasoning": {"analysis": "Î∂ÑÏÑùÏùÑ ÏôÑÎ£åÌï† Ïàò ÏóÜÏäµÎãàÎã§.", "contributing_factors": [], "confidence": 0},
                    "actions": [],
                },
            }

    # =========================================
    # StatCard Í¥ÄÎ¶¨
    # =========================================

    def _manage_stat_cards(
        self,
        action: str,
        tenant_id: str,
        user_id: str,
        kpi_code: str = None,
        table_name: str = None,
        column_name: str = None,
        aggregation: str = None,
        mcp_server_id: str = None,
        mcp_tool_name: str = None,
        card_id: str = None,
        card_ids: List[str] = None,
        title: str = None,
        unit: str = None,
        icon: str = None,
    ) -> Dict[str, Any]:
        """
        StatCard Í¥ÄÎ¶¨ (CRUD Î∞è Ïû¨Ï†ïÎ†¨)
        """
        import asyncio
        from app.services.stat_card_service import StatCardService
        from app.database import SessionLocal
        from app.schemas.statcard import StatCardConfigCreate

        try:
            tenant_uuid = UUID(tenant_id)
            user_uuid = UUID(user_id)

            db = SessionLocal()
            try:
                service = StatCardService(db)

                if action == "list":
                    # Ïπ¥Îìú Î™©Î°ù Ï°∞Ìöå
                    loop = asyncio.get_event_loop()
                    if loop.is_running():
                        import concurrent.futures
                        with concurrent.futures.ThreadPoolExecutor() as executor:
                            future = executor.submit(
                                asyncio.run,
                                service.get_card_values(tenant_id=tenant_uuid, user_id=user_uuid)
                            )
                            result = future.result()
                    else:
                        result = loop.run_until_complete(
                            service.get_card_values(tenant_id=tenant_uuid, user_id=user_uuid)
                        )

                    cards_info = []
                    for card in result.cards:
                        cards_info.append({
                            "config_id": str(card.config.config_id),
                            "title": card.value.title,
                            "source_type": card.config.source_type,
                            "value": card.value.formatted_value or card.value.value,
                            "status": card.value.status,
                            "display_order": card.config.display_order,
                        })

                    logger.info(f"Listed {len(cards_info)} stat cards")

                    return {
                        "success": True,
                        "action": "list",
                        "cards": cards_info,
                        "total": result.total,
                    }

                elif action == "add_kpi":
                    if not kpi_code:
                        return {"success": False, "error": "kpi_code is required for add_kpi action"}

                    config = StatCardConfigCreate(
                        source_type="kpi",
                        kpi_code=kpi_code,
                        display_order=99,
                        is_visible=True,
                        higher_is_better=True,
                        cache_ttl_seconds=60,
                        custom_title=title,
                        custom_unit=unit,
                        custom_icon=icon,
                    )

                    created = service.create_config(tenant_id=tenant_uuid, user_id=user_uuid, config=config)

                    logger.info(f"Created KPI stat card: {kpi_code}")

                    return {
                        "success": True,
                        "action": "add_kpi",
                        "config_id": str(created.config_id),
                        "kpi_code": kpi_code,
                        "message": f"KPI '{kpi_code}' Ïπ¥ÎìúÍ∞Ä Ï∂îÍ∞ÄÎêòÏóàÏäµÎãàÎã§.",
                    }

                elif action == "add_db_query":
                    if not table_name or not column_name or not aggregation:
                        return {"success": False, "error": "table_name, column_name, and aggregation are required"}

                    config = StatCardConfigCreate(
                        source_type="db_query",
                        table_name=table_name,
                        column_name=column_name,
                        aggregation=aggregation,
                        display_order=99,
                        is_visible=True,
                        higher_is_better=True,
                        cache_ttl_seconds=60,
                        custom_title=title,
                        custom_unit=unit,
                        custom_icon=icon,
                    )

                    created = service.create_config(tenant_id=tenant_uuid, user_id=user_uuid, config=config)

                    logger.info(f"Created DB query stat card: {table_name}.{column_name}")

                    return {
                        "success": True,
                        "action": "add_db_query",
                        "config_id": str(created.config_id),
                        "table_name": table_name,
                        "column_name": column_name,
                        "aggregation": aggregation,
                        "message": f"DB ÏøºÎ¶¨ Ïπ¥Îìú ({table_name}.{column_name})Í∞Ä Ï∂îÍ∞ÄÎêòÏóàÏäµÎãàÎã§.",
                    }

                elif action == "add_mcp":
                    if not mcp_server_id or not mcp_tool_name:
                        return {"success": False, "error": "mcp_server_id and mcp_tool_name are required"}

                    config = StatCardConfigCreate(
                        source_type="mcp_tool",
                        mcp_server_id=UUID(mcp_server_id),
                        mcp_tool_name=mcp_tool_name,
                        display_order=99,
                        is_visible=True,
                        higher_is_better=True,
                        cache_ttl_seconds=60,
                        custom_title=title,
                        custom_unit=unit,
                        custom_icon=icon,
                    )

                    created = service.create_config(tenant_id=tenant_uuid, user_id=user_uuid, config=config)

                    logger.info(f"Created MCP tool stat card: {mcp_tool_name}")

                    return {
                        "success": True,
                        "action": "add_mcp",
                        "config_id": str(created.config_id),
                        "mcp_tool_name": mcp_tool_name,
                        "message": f"MCP ÎèÑÍµ¨ Ïπ¥Îìú ({mcp_tool_name})Í∞Ä Ï∂îÍ∞ÄÎêòÏóàÏäµÎãàÎã§.",
                    }

                elif action == "remove":
                    if not card_id:
                        return {"success": False, "error": "card_id is required for remove action"}

                    success = service.delete_config(
                        tenant_id=tenant_uuid,
                        user_id=user_uuid,
                        config_id=UUID(card_id),
                    )

                    if success:
                        logger.info(f"Deleted stat card: {card_id}")
                        return {
                            "success": True,
                            "action": "remove",
                            "deleted_id": card_id,
                            "message": "Ïπ¥ÎìúÍ∞Ä ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§.",
                        }
                    else:
                        return {"success": False, "error": "Card not found or unauthorized"}

                elif action == "reorder":
                    if not card_ids:
                        return {"success": False, "error": "card_ids is required for reorder action"}

                    card_uuids = [UUID(cid) for cid in card_ids]
                    service.reorder_configs(tenant_id=tenant_uuid, user_id=user_uuid, config_ids=card_uuids)

                    logger.info(f"Reordered {len(card_ids)} stat cards")

                    return {
                        "success": True,
                        "action": "reorder",
                        "new_order": card_ids,
                        "message": "Ïπ¥Îìú ÏàúÏÑúÍ∞Ä Î≥ÄÍ≤ΩÎêòÏóàÏäµÎãàÎã§.",
                    }

                else:
                    return {"success": False, "error": f"Unknown action: {action}"}

            finally:
                db.close()

        except Exception as e:
            logger.error(f"StatCard management error: {e}")
            return {
                "success": False,
                "error": str(e),
                "action": action,
            }
