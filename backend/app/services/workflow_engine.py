"""
ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì—”ì§„
ì¡°ê±´ í‰ê°€ ë° ì•¡ì…˜ ì‹¤í–‰

ìŠ¤í™ ì°¸ì¡°: B-5_Workflow_State_Machine.md (15ê°œ ë…¸ë“œ íƒ€ì…)

ì§€ì› ë…¸ë“œ íƒ€ì… (11ê°œ êµ¬í˜„, 4ê°œ ì˜ˆì •):
- condition: ì¡°ê±´ í‰ê°€ (ìˆœì°¨ ì§„í–‰)
- action: ì•¡ì…˜ ì‹¤í–‰
- if_else: ì¡°ê±´ ë¶„ê¸° (then/else ë¸Œëœì¹˜)
- loop: ë°˜ë³µ ì‹¤í–‰ (ì¡°ê±´ ê¸°ë°˜ ë˜ëŠ” íšŸìˆ˜ ê¸°ë°˜)
- parallel: ë³‘ë ¬ ì‹¤í–‰
- data: ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ì¡°íšŒ
- wait: ëŒ€ê¸° (ì§€ì • ì‹œê°„ ë˜ëŠ” ì´ë²¤íŠ¸)
- approval: ì¸ê°„ ìŠ¹ì¸ ëŒ€ê¸°
- switch: ë‹¤ì¤‘ ë¶„ê¸° (ë‹¤ìˆ˜ case)
- trigger: ì›Œí¬í”Œë¡œìš° ìë™ ì‹œì‘ íŠ¸ë¦¬ê±° (V2 ì¶”ê°€)
- code: Python ìƒŒë“œë°•ìŠ¤ ì‹¤í–‰ (V2 ì¶”ê°€)

ë¯¸êµ¬í˜„ (Phase 3):
- judgment: íŒë‹¨ ì—ì´ì „íŠ¸ í˜¸ì¶œ (ë…¸ë“œ íƒ€ì…)
- bi: BI ë¶„ì„ ì—ì´ì „íŠ¸ í˜¸ì¶œ (ë…¸ë“œ íƒ€ì…)
- mcp: MCP ì™¸ë¶€ ë„êµ¬ í˜¸ì¶œ (ë…¸ë“œ íƒ€ì…)
- compensation: ë³´ìƒ íŠ¸ëœì­ì…˜
- deploy: ë°°í¬
- rollback: ë¡¤ë°±
- simulate: ì‹œë®¬ë ˆì´ì…˜
"""
import asyncio
import csv
import io
import json
import logging
import os
import time
from datetime import datetime
from typing import Any, Dict, List, Optional
from uuid import uuid4

from app.services.notifications import notification_manager, NotificationStatus

logger = logging.getLogger(__name__)

# Optional MinIO import
try:
    from minio import Minio
    MINIO_AVAILABLE = True
except ImportError:
    MINIO_AVAILABLE = False
    logger.warning("MinIO client not available. export_to_csv will use local filesystem.")


# ============ ì‹¤í–‰ ë¡œê·¸ ì €ì¥ì†Œ (ì¸ë©”ëª¨ë¦¬) ============

class ExecutionLogStore:
    """ì¸ë©”ëª¨ë¦¬ ì‹¤í–‰ ë¡œê·¸ ì €ì¥ì†Œ (MVPìš©)"""

    def __init__(self, max_logs: int = 1000):
        self._logs: List[Dict[str, Any]] = []
        self._max_logs = max_logs

    def add_log(self, log_entry: Dict[str, Any]) -> str:
        """ë¡œê·¸ ì¶”ê°€"""
        log_id = str(uuid4())
        log_entry["log_id"] = log_id
        log_entry["timestamp"] = datetime.utcnow().isoformat()

        self._logs.append(log_entry)

        # ìµœëŒ€ ê°œìˆ˜ ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ ë¡œê·¸ ì‚­ì œ
        if len(self._logs) > self._max_logs:
            self._logs = self._logs[-self._max_logs:]

        return log_id

    def get_logs(
        self,
        workflow_id: Optional[str] = None,
        event_type: Optional[str] = None,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """ë¡œê·¸ ì¡°íšŒ"""
        logs = self._logs.copy()

        if workflow_id:
            logs = [log for log in logs if log.get("workflow_id") == workflow_id]

        if event_type:
            logs = [log for log in logs if log.get("event_type") == event_type]

        # ìµœì‹ ìˆœ ì •ë ¬
        logs.sort(key=lambda x: x.get("timestamp", ""), reverse=True)

        return logs[:limit]

    def clear(self):
        """ëª¨ë“  ë¡œê·¸ ì‚­ì œ"""
        self._logs = []


# ì „ì—­ ë¡œê·¸ ì €ì¥ì†Œ
execution_log_store = ExecutionLogStore()


# ============ ì„¼ì„œ ë°ì´í„° ì‹œë®¬ë ˆì´í„° ============

class SensorSimulator:
    """ì„¼ì„œ ë°ì´í„° ì‹œë®¬ë ˆì´í„°"""

    def __init__(self):
        import random
        self._random = random

        # ê¸°ë³¸ ì„¼ì„œ ê°’ ë²”ìœ„
        self._sensor_ranges = {
            "temperature": (20.0, 100.0),
            "pressure": (0.0, 15.0),
            "humidity": (20.0, 90.0),
            "vibration": (0.0, 100.0),
            "defect_rate": (0.0, 20.0),
            "consecutive_defects": (0, 10),
            "runtime_hours": (0, 24),
            "production_count": (0, 2000),
            "units_per_hour": (50, 200),
            "current_hour": (0, 23),
        }

        # ì¥ë¹„ ìƒíƒœ ì˜µì…˜
        self._equipment_statuses = ["running", "stopped", "error", "maintenance"]

    def generate_sensor_data(
        self,
        sensors: Optional[List[str]] = None,
        scenario: str = "normal"
    ) -> Dict[str, Any]:
        """
        ì„¼ì„œ ë°ì´í„° ìƒì„±

        scenarios:
        - normal: ì •ìƒ ë²”ìœ„ ë°ì´í„°
        - alert: ì„ê³„ê°’ ì´ˆê³¼ ë°ì´í„°
        - random: ì™„ì „ ëœë¤ ë°ì´í„°
        """
        data: Dict[str, Any] = {}

        target_sensors = sensors or list(self._sensor_ranges.keys())

        for sensor in target_sensors:
            if sensor in self._sensor_ranges:
                min_val, max_val = self._sensor_ranges[sensor]

                if scenario == "normal":
                    # ì •ìƒ ë²”ìœ„ (ì¤‘ì•™ 50%)
                    range_size = max_val - min_val
                    data[sensor] = min_val + range_size * 0.25 + self._random.random() * range_size * 0.5
                elif scenario == "alert":
                    # ê²½ê³  ë²”ìœ„ (ìƒìœ„ 25%)
                    range_size = max_val - min_val
                    data[sensor] = max_val - range_size * 0.25 + self._random.random() * range_size * 0.25
                else:
                    # ì™„ì „ ëœë¤
                    if isinstance(min_val, int):
                        data[sensor] = self._random.randint(min_val, max_val)
                    else:
                        data[sensor] = min_val + self._random.random() * (max_val - min_val)

                # ì •ìˆ˜í˜• ì„¼ì„œ
                if sensor in ["consecutive_defects", "runtime_hours", "production_count", "units_per_hour", "current_hour"]:
                    data[sensor] = int(data[sensor])

            elif sensor == "equipment_status":
                if scenario == "alert":
                    data[sensor] = "error"
                elif scenario == "normal":
                    data[sensor] = "running"
                else:
                    data[sensor] = self._random.choice(self._equipment_statuses)

        data["generated_at"] = datetime.utcnow().isoformat()
        data["scenario"] = scenario

        return data

    def generate_test_scenario(self, scenario_name: str) -> Dict[str, Any]:
        """
        ì‚¬ì „ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
        """
        scenarios = {
            "high_temperature": {
                "temperature": 85.0,
                "humidity": 45.0,
                "pressure": 5.5,
                "equipment_status": "running",
            },
            "low_pressure": {
                "temperature": 55.0,
                "humidity": 50.0,
                "pressure": 1.5,
                "equipment_status": "running",
            },
            "equipment_error": {
                "temperature": 95.0,
                "vibration": 80.0,
                "equipment_status": "error",
            },
            "high_defect_rate": {
                "defect_rate": 12.5,
                "consecutive_defects": 5,
                "production_count": 500,
            },
            "production_delay": {
                "units_per_hour": 75,
                "production_count": 300,
                "runtime_hours": 6,
            },
            "shift_change": {
                "current_hour": 18,
                "production_count": 1000,
                "equipment_status": "running",
            },
            "normal_operation": {
                "temperature": 55.0,
                "humidity": 50.0,
                "pressure": 5.0,
                "vibration": 25.0,
                "defect_rate": 2.0,
                "equipment_status": "running",
            },
        }

        if scenario_name in scenarios:
            data = scenarios[scenario_name].copy()
            data["scenario_name"] = scenario_name
            data["generated_at"] = datetime.utcnow().isoformat()
            return data

        return self.generate_sensor_data(scenario="random")


# ì „ì—­ ì‹œë®¬ë ˆì´í„°
sensor_simulator = SensorSimulator()


# ============ ì¡°ê±´ í‰ê°€ê¸° ============

class ConditionEvaluator:
    """
    ì¡°ê±´ì‹ í‰ê°€ê¸°
    ê°„ë‹¨í•œ ìˆ˜ì‹ í‰ê°€ (Rhai ëŒ€ì²´ - MVPìš©)
    """

    def __init__(self):
        # ì§€ì›í•˜ëŠ” ì—°ì‚°ì
        self._operators = {
            ">=": lambda a, b: a >= b,
            "<=": lambda a, b: a <= b,
            "==": lambda a, b: a == b,
            "!=": lambda a, b: a != b,
            ">": lambda a, b: a > b,
            "<": lambda a, b: a < b,
        }

    def evaluate(
        self,
        condition: str,
        context: Dict[str, Any]
    ) -> tuple[bool, str]:
        """
        ì¡°ê±´ì‹ í‰ê°€

        Returns:
            (ê²°ê³¼, ë©”ì‹œì§€)
        """
        if not condition or not condition.strip():
            return True, "ë¹ˆ ì¡°ê±´ (í•­ìƒ ì°¸)"

        try:
            # && (AND) ì²˜ë¦¬
            if "&&" in condition:
                parts = condition.split("&&")
                for part in parts:
                    result, msg = self._evaluate_single(part.strip(), context)
                    if not result:
                        return False, f"AND ì¡°ê±´ ì‹¤íŒ¨: {part.strip()} -> {msg}"
                return True, "ëª¨ë“  AND ì¡°ê±´ ì¶©ì¡±"

            # || (OR) ì²˜ë¦¬
            if "||" in condition:
                parts = condition.split("||")
                for part in parts:
                    result, msg = self._evaluate_single(part.strip(), context)
                    if result:
                        return True, f"OR ì¡°ê±´ ì¶©ì¡±: {part.strip()}"
                return False, "ëª¨ë“  OR ì¡°ê±´ ì‹¤íŒ¨"

            # ë‹¨ì¼ ì¡°ê±´
            return self._evaluate_single(condition, context)

        except Exception as e:
            logger.error(f"ì¡°ê±´ í‰ê°€ ì˜¤ë¥˜: {condition} - {e}")
            return False, f"í‰ê°€ ì˜¤ë¥˜: {str(e)}"

    def _evaluate_single(
        self,
        condition: str,
        context: Dict[str, Any]
    ) -> tuple[bool, str]:
        """ë‹¨ì¼ ì¡°ê±´ì‹ í‰ê°€"""
        condition = condition.strip()

        # ì—°ì‚°ì ì°¾ê¸°
        for op in [">=", "<=", "==", "!=", ">", "<"]:
            if op in condition:
                parts = condition.split(op)
                if len(parts) == 2:
                    left = parts[0].strip()
                    right = parts[1].strip()

                    # ì¢Œë³€ ê°’ ê°€ì ¸ì˜¤ê¸°
                    left_value = self._get_value(left, context)
                    # ìš°ë³€ ê°’ ê°€ì ¸ì˜¤ê¸°
                    right_value = self._get_value(right, context)

                    if left_value is None:
                        return False, f"ë³€ìˆ˜ '{left}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"

                    # ì—°ì‚° ìˆ˜í–‰
                    try:
                        result = self._operators[op](left_value, right_value)
                        return result, f"{left}({left_value}) {op} {right}({right_value}) = {result}"
                    except TypeError as e:
                        return False, f"íƒ€ì… ì˜¤ë¥˜: {e}"

        return False, f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì¡°ê±´ì‹: {condition}"

    def _get_value(self, expr: str, context: Dict[str, Any]) -> Any:
        """í‘œí˜„ì‹ì—ì„œ ê°’ ì¶”ì¶œ"""
        expr = expr.strip()

        # ë¬¸ìì—´ ë¦¬í„°ëŸ´ ("value" ë˜ëŠ” 'value')
        if (expr.startswith('"') and expr.endswith('"')) or \
           (expr.startswith("'") and expr.endswith("'")):
            return expr[1:-1]

        # ìˆ«ì ë¦¬í„°ëŸ´
        try:
            if '.' in expr:
                return float(expr)
            return int(expr)
        except ValueError:
            pass

        # ë³€ìˆ˜ (contextì—ì„œ ì¡°íšŒ)
        if expr in context:
            return context[expr]

        return None


# ì „ì—­ ì¡°ê±´ í‰ê°€ê¸°
condition_evaluator = ConditionEvaluator()


# ============ ì•¡ì…˜ ì‹¤í–‰ê¸° ============

class ActionExecutor:
    """
    ì›Œí¬í”Œë¡œìš° ì•¡ì…˜ ì‹¤í–‰ê¸°
    """

    def __init__(self):
        self._action_handlers = {
            # ë°ì´í„° ì•¡ì…˜
            "log_event": self._log_event,
            "save_to_database": self._save_to_database,
            "export_to_csv": self._export_to_csv,
            # ì œì–´ ì•¡ì…˜ (Mock)
            "stop_production_line": self._stop_production_line,
            "adjust_sensor_threshold": self._adjust_sensor_threshold,
            "trigger_maintenance": self._trigger_maintenance,
            # ë¶„ì„ ì•¡ì…˜
            "calculate_defect_rate": self._calculate_defect_rate,
            "calculate_metric": self._calculate_metric,
            "analyze_sensor_trend": self._analyze_sensor_trend,
            "predict_equipment_failure": self._predict_equipment_failure,
            # ì¸ì‚¬ì´íŠ¸ ì•¡ì…˜ (ì‹ ê·œ)
            "execute_sql": self._execute_sql,
            "aggregate_data": self._aggregate_data,
            "evaluate_threshold": self._evaluate_threshold,
            "generate_chart": self._generate_chart,
            "format_insight": self._format_insight,
        }

    async def execute(
        self,
        action_name: str,
        parameters: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì•¡ì…˜ ì‹¤í–‰

        Returns:
            {"success": bool, "message": str, "data": Any}
        """
        if action_name in self._action_handlers:
            try:
                result = await self._action_handlers[action_name](parameters, context)
                return {
                    "success": True,
                    "action": action_name,
                    **result
                }
            except Exception as e:
                logger.error(f"ì•¡ì…˜ ì‹¤í–‰ ì˜¤ë¥˜: {action_name} - {e}")
                return {
                    "success": False,
                    "action": action_name,
                    "message": f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
                }
        else:
            return {
                "success": False,
                "action": action_name,
                "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•¡ì…˜: {action_name}",
            }

    # ============ ë°ì´í„° ì•¡ì…˜ ============

    async def _log_event(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì´ë²¤íŠ¸ ë¡œê·¸ ê¸°ë¡"""
        event_type = params.get("event_type", "general")
        details = params.get("details", {})

        log_entry = {
            "event_type": event_type,
            "details": details,
            "context": context,
            "workflow_id": context.get("workflow_id"),
            "node_id": context.get("node_id"),
        }

        log_id = execution_log_store.add_log(log_entry)

        logger.info(f"[LOG_EVENT] {event_type}: {details}")

        return {
            "message": f"ì´ë²¤íŠ¸ ë¡œê·¸ ê¸°ë¡ë¨: {event_type}",
            "log_id": log_id,
            "data": log_entry,
        }

    async def _save_to_database(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥

        íŒŒë¼ë¯¸í„°:
            table: í…Œì´ë¸”ëª… (workflow_data ê³ ì • ë˜ëŠ” ì§€ì •)
            data: ì €ì¥í•  ë°ì´í„° (dict)

        workflow_data í…Œì´ë¸”ì— JSON í˜•íƒœë¡œ ì €ì¥
        """
        from app.database import get_db_context
        from sqlalchemy import text

        table = params.get("table", "workflow_data")
        data = params.get("data", {})
        workflow_id = context.get("workflow_id")

        try:
            with get_db_context() as db:
                # workflow_data í…Œì´ë¸”ì— ì €ì¥ (core ìŠ¤í‚¤ë§ˆ)
                # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„± (ë™ì  í…Œì´ë¸” ìƒì„±)
                create_table_sql = text("""
                    CREATE TABLE IF NOT EXISTS core.workflow_data (
                        id SERIAL PRIMARY KEY,
                        workflow_id VARCHAR(100),
                        table_name VARCHAR(100),
                        data JSONB,
                        created_at TIMESTAMP DEFAULT NOW()
                    )
                """)
                db.execute(create_table_sql)
                db.commit()

                # ë°ì´í„° ì‚½ì…
                insert_sql = text("""
                    INSERT INTO core.workflow_data (workflow_id, table_name, data)
                    VALUES (:workflow_id, :table_name, :data)
                    RETURNING id
                """)
                result = db.execute(
                    insert_sql,
                    {
                        "workflow_id": workflow_id or "unknown",
                        "table_name": table,
                        "data": json.dumps(data, ensure_ascii=False),
                    }
                )
                db.commit()
                row_id = result.scalar()

            log_entry = {
                "event_type": "database_save",
                "details": {"table": table, "data": data, "row_id": row_id},
                "context": context,
                "workflow_id": workflow_id,
            }
            execution_log_store.add_log(log_entry)

            return {
                "message": f"ë°ì´í„° ì €ì¥ ì™„ë£Œ: {table}",
                "data": {"table": table, "row_id": row_id, "rows_affected": 1},
            }

        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨ ì‹œì—ë„ ë¡œê·¸ëŠ” ê¸°ë¡
            log_entry = {
                "event_type": "database_save_failed",
                "details": {"table": table, "data": data, "error": str(e)},
                "context": context,
                "workflow_id": workflow_id,
            }
            execution_log_store.add_log(log_entry)

            return {
                "message": f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}",
                "data": {"table": table, "error": str(e)},
            }

    async def _export_to_csv(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        CSV ë‚´ë³´ë‚´ê¸°

        íŒŒë¼ë¯¸í„°:
            filename: íŒŒì¼ëª… (ì˜ˆ: "sensor_data_20241201.csv")
            data: ë‚´ë³´ë‚¼ ë°ì´í„° (list of dict)
            fields: í•„ë“œ ëª©ë¡ (ì„ íƒ, ë¯¸ì§€ì • ì‹œ data[0]ì˜ í‚¤ ì‚¬ìš©)

        MinIOê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ MinIOì— ì €ì¥, ì—†ìœ¼ë©´ ë¡œì»¬ íŒŒì¼ì‹œìŠ¤í…œì— ì €ì¥
        """
        from app.config import settings

        filename = params.get("filename", f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
        data = params.get("data", [])
        fields = params.get("fields", None)
        workflow_id = context.get("workflow_id")

        if not isinstance(data, list) or len(data) == 0:
            return {
                "message": "ë‚´ë³´ë‚¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤",
                "data": {"filename": filename, "rows": 0},
            }

        # CSV ë°ì´í„° ìƒì„±
        output = io.StringIO()

        # í•„ë“œ ê²°ì •
        if fields is None:
            fields = list(data[0].keys()) if isinstance(data[0], dict) else []

        writer = csv.DictWriter(output, fieldnames=fields, extrasaction='ignore')
        writer.writeheader()

        for row in data:
            if isinstance(row, dict):
                writer.writerow(row)

        csv_content = output.getvalue()
        output.close()

        # ì €ì¥ ê²½ë¡œ ê²°ì •
        storage_path = None
        storage_type = "local"

        # MinIO ì €ì¥ ì‹œë„
        if MINIO_AVAILABLE and settings.minio_endpoint:
            try:
                client = Minio(
                    settings.minio_endpoint,
                    access_key=settings.minio_access_key,
                    secret_key=settings.minio_secret_key,
                    secure=settings.minio_secure,
                )

                # ë²„í‚· í™•ì¸/ìƒì„±
                bucket_name = settings.minio_bucket_name
                if not client.bucket_exists(bucket_name):
                    client.make_bucket(bucket_name)

                # íŒŒì¼ ì—…ë¡œë“œ
                object_name = f"exports/{workflow_id or 'unknown'}/{filename}"
                csv_bytes = csv_content.encode('utf-8')

                client.put_object(
                    bucket_name,
                    object_name,
                    io.BytesIO(csv_bytes),
                    len(csv_bytes),
                    content_type='text/csv',
                )

                storage_path = f"minio://{bucket_name}/{object_name}"
                storage_type = "minio"
                logger.info(f"CSV íŒŒì¼ MinIO ì €ì¥: {storage_path}")

            except Exception as e:
                logger.warning(f"MinIO ì €ì¥ ì‹¤íŒ¨, ë¡œì»¬ ì €ì¥ìœ¼ë¡œ ëŒ€ì²´: {e}")

        # MinIO ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ì €ì¥
        if storage_type == "local":
            try:
                # exports ë””ë ‰í† ë¦¬ ìƒì„±
                export_dir = os.path.join(os.getcwd(), "exports", workflow_id or "unknown")
                os.makedirs(export_dir, exist_ok=True)

                file_path = os.path.join(export_dir, filename)
                with open(file_path, 'w', encoding='utf-8', newline='') as f:
                    f.write(csv_content)

                storage_path = file_path
                logger.info(f"CSV íŒŒì¼ ë¡œì»¬ ì €ì¥: {storage_path}")

            except Exception as e:
                logger.error(f"ë¡œì»¬ ì €ì¥ë„ ì‹¤íŒ¨: {e}")
                return {
                    "message": f"CSV ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}",
                    "data": {"filename": filename, "error": str(e)},
                }

        # ë¡œê·¸ ê¸°ë¡
        log_entry = {
            "event_type": "csv_export",
            "details": {
                "filename": filename,
                "rows": len(data),
                "storage_type": storage_type,
                "storage_path": storage_path,
            },
            "context": context,
            "workflow_id": workflow_id,
        }
        execution_log_store.add_log(log_entry)

        return {
            "message": f"CSV íŒŒì¼ ìƒì„± ì™„ë£Œ: {filename}",
            "data": {
                "filename": filename,
                "rows": len(data),
                "storage_type": storage_type,
                "storage_path": storage_path,
            },
        }

    # ============ ì œì–´ ì•¡ì…˜ (Mock) ============

    async def _stop_production_line(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ìƒì‚° ë¼ì¸ ì •ì§€ (Mock)"""
        line_code = params.get("line_code", "LINE_01")
        reason = params.get("reason", "Unknown")

        log_entry = {
            "event_type": "production_line_stop",
            "details": {"line_code": line_code, "reason": reason},
            "context": context,
            "workflow_id": context.get("workflow_id"),
        }
        execution_log_store.add_log(log_entry)

        return {
            "message": f"ìƒì‚° ë¼ì¸ ì •ì§€ ìš”ì²­ë¨: {line_code}",
            "data": {"line_code": line_code, "reason": reason, "status": "stopped"},
        }

    async def _adjust_sensor_threshold(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì„¼ì„œ ì„ê³„ê°’ ì¡°ì • (Mock)"""
        sensor_id = params.get("sensor_id", "SENSOR_01")
        threshold = params.get("threshold", 0)

        return {
            "message": f"ì„¼ì„œ ì„ê³„ê°’ ì¡°ì •ë¨: {sensor_id} -> {threshold}",
            "data": {"sensor_id": sensor_id, "new_threshold": threshold},
        }

    async def _trigger_maintenance(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ìœ ì§€ë³´ìˆ˜ ìš”ì²­ (Mock)"""
        equipment_id = params.get("equipment_id", "EQUIP_01")
        priority = params.get("priority", "medium")

        log_entry = {
            "event_type": "maintenance_triggered",
            "details": {"equipment_id": equipment_id, "priority": priority},
            "context": context,
            "workflow_id": context.get("workflow_id"),
        }
        execution_log_store.add_log(log_entry)

        return {
            "message": f"ìœ ì§€ë³´ìˆ˜ ìš”ì²­ ìƒì„±ë¨: {equipment_id} ({priority})",
            "data": {"equipment_id": equipment_id, "priority": priority, "ticket_id": str(uuid4())[:8]},
        }

    # ============ ë¶„ì„ ì•¡ì…˜ (Mock) ============

    async def _calculate_defect_rate(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë¶ˆëŸ‰ë¥  ê³„ì‚° (Mock)"""
        line_code = params.get("line_code", "LINE_01")
        time_range = params.get("time_range", "1h")

        # Mock ê²°ê³¼
        import random
        defect_rate = round(random.uniform(0, 10), 2)

        return {
            "message": f"ë¶ˆëŸ‰ë¥  ê³„ì‚° ì™„ë£Œ: {line_code}",
            "data": {
                "line_code": line_code,
                "time_range": time_range,
                "defect_rate": defect_rate,
                "total_produced": random.randint(100, 1000),
                "defects_found": int(defect_rate * 10),
            },
        }

    async def _analyze_sensor_trend(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì„¼ì„œ ì¶”ì„¸ ë¶„ì„ (ì‹¤ì œ êµ¬í˜„)

        íŒŒë¼ë¯¸í„°:
            data: ì‹œê³„ì—´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (list of dict)
                ì˜ˆ: [{"timestamp": "...", "value": 75.3}, ...]
            value_key: ê°’ í‚¤ (ê¸°ë³¸ê°’: "value")
            timestamp_key: íƒ€ì„ìŠ¤íƒ¬í”„ í‚¤ (ê¸°ë³¸ê°’: "timestamp")
            window_size: ì´ë™í‰ê·  ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ê°’: 5)
            sensor_type: ì„¼ì„œ ìœ í˜• (í‘œì‹œìš©)

        ì¶œë ¥:
            trend: ì¶”ì„¸ (increasing, decreasing, stable)
            average: í‰ê· ê°’
            min: ìµœì†Œê°’
            max: ìµœëŒ€ê°’
            std_dev: í‘œì¤€í¸ì°¨
            moving_average: ì´ë™í‰ê·  ë°ì´í„°
        """
        from statistics import mean, stdev

        data = params.get("data", [])
        value_key = params.get("value_key", "value")
        timestamp_key = params.get("timestamp_key", "timestamp")
        window_size = params.get("window_size", 5)
        sensor_type = params.get("sensor_type", "sensor")
        hours = params.get("hours", 24)

        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ Mock ë°ì´í„° ì‚¬ìš©
        if not data:
            import random
            trend = random.choice(["increasing", "decreasing", "stable"])
            return {
                "message": f"ì„¼ì„œ ì¶”ì„¸ ë¶„ì„ ì™„ë£Œ (Mock): {sensor_type}",
                "data": {
                    "sensor_type": sensor_type,
                    "hours_analyzed": hours,
                    "trend": trend,
                    "average": round(random.uniform(40, 80), 2),
                    "min": round(random.uniform(20, 40), 2),
                    "max": round(random.uniform(80, 100), 2),
                    "std_dev": round(random.uniform(1, 10), 2),
                    "data_points": 0,
                    "is_mock": True,
                },
            }

        # ê°’ ì¶”ì¶œ
        values = []
        for item in data:
            val = item.get(value_key)
            if val is not None:
                try:
                    values.append(float(val))
                except (TypeError, ValueError):
                    pass

        if not values:
            return {
                "message": "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤",
                "data": {"error": "no valid values"},
            }

        # ê¸°ë³¸ í†µê³„
        avg_value = round(mean(values), 2)
        min_value = round(min(values), 2)
        max_value = round(max(values), 2)
        std_value = round(stdev(values), 2) if len(values) > 1 else 0

        # ì´ë™í‰ê·  ê³„ì‚°
        moving_avg = []
        for i in range(len(values)):
            start_idx = max(0, i - window_size + 1)
            window = values[start_idx:i + 1]
            moving_avg.append(round(mean(window), 2))

        # ì¶”ì„¸ íŒë³„ (ì„ í˜• íšŒê·€ ê°„ëµ ë²„ì „)
        n = len(values)
        if n >= 3:
            # ê°„ë‹¨í•œ ì¶”ì„¸: ì²˜ìŒ 1/3 vs ë§ˆì§€ë§‰ 1/3 ë¹„êµ
            first_third = values[:n // 3]
            last_third = values[-(n // 3):]

            first_avg = mean(first_third) if first_third else 0
            last_avg = mean(last_third) if last_third else 0

            diff_ratio = (last_avg - first_avg) / (first_avg if first_avg != 0 else 1)

            if diff_ratio > 0.05:  # 5% ì´ìƒ ì¦ê°€
                trend = "increasing"
            elif diff_ratio < -0.05:  # 5% ì´ìƒ ê°ì†Œ
                trend = "decreasing"
            else:
                trend = "stable"
        else:
            trend = "stable"

        return {
            "message": f"ì„¼ì„œ ì¶”ì„¸ ë¶„ì„ ì™„ë£Œ: {sensor_type}",
            "data": {
                "sensor_type": sensor_type,
                "hours_analyzed": hours,
                "trend": trend,
                "average": avg_value,
                "min": min_value,
                "max": max_value,
                "std_dev": std_value,
                "data_points": len(values),
                "moving_average": moving_avg[-10:] if len(moving_avg) > 10 else moving_avg,
                "is_mock": False,
            },
        }

    async def _predict_equipment_failure(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì¥ë¹„ ê³ ì¥ ì˜ˆì¸¡ (ê·œì¹™ ê¸°ë°˜ + í†µê³„ì  ë¶„ì„)

        íŒŒë¼ë¯¸í„°:
            equipment_id: ì„¤ë¹„ ID
            sensor_data: ì„¼ì„œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (list of dict)
                ì˜ˆ: [{"temperature": 75, "vibration": 2.5, "pressure": 100}, ...]
            thresholds: ì„ê³„ê°’ ì„¤ì • (dict)
                ì˜ˆ: {"temperature": {"warning": 80, "critical": 90},
                     "vibration": {"warning": 3.0, "critical": 5.0}}
            history_days: ë¶„ì„í•  ê³¼ê±° ì¼ìˆ˜ (ê¸°ë³¸ê°’: 30)

        ì¶œë ¥:
            failure_probability: ê³ ì¥ í™•ë¥  (0~1)
            estimated_days_to_failure: ì˜ˆìƒ ì”ì—¬ ì¼ìˆ˜
            risk_factors: ìœ„í—˜ ìš”ì†Œ ë¦¬ìŠ¤íŠ¸
            recommendation: ê¶Œì¥ ì¡°ì¹˜
        """
        from statistics import mean, stdev

        equipment_id = params.get("equipment_id", "EQUIP_01")
        sensor_data = params.get("sensor_data", [])
        thresholds = params.get("thresholds", {
            "temperature": {"warning": 80, "critical": 95},
            "vibration": {"warning": 3.0, "critical": 5.0},
            "pressure": {"warning": 150, "critical": 180},
        })
        history_days = params.get("history_days", 30)

        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ Mock ê²°ê³¼ ë°˜í™˜
        if not sensor_data:
            import random
            failure_probability = round(random.uniform(0, 0.5), 3)
            days_to_failure = random.randint(7, 90) if failure_probability < 0.3 else random.randint(1, 7)

            return {
                "message": f"ì¥ë¹„ ê³ ì¥ ì˜ˆì¸¡ ì™„ë£Œ (Mock): {equipment_id}",
                "data": {
                    "equipment_id": equipment_id,
                    "failure_probability": failure_probability,
                    "estimated_days_to_failure": days_to_failure,
                    "recommendation": "ìœ ì§€ë³´ìˆ˜ ê¶Œì¥" if failure_probability > 0.2 else "ì •ìƒ ìš´ì˜",
                    "risk_factors": [],
                    "is_mock": True,
                },
            }

        # ìœ„í—˜ ìš”ì†Œ ë¶„ì„
        risk_factors = []
        risk_score = 0.0

        for metric, limits in thresholds.items():
            values = [d.get(metric) for d in sensor_data if d.get(metric) is not None]

            if not values:
                continue

            try:
                values = [float(v) for v in values]
            except (TypeError, ValueError):
                continue

            avg = mean(values)
            max_val = max(values)
            std = stdev(values) if len(values) > 1 else 0

            warning_threshold = limits.get("warning", float("inf"))
            critical_threshold = limits.get("critical", float("inf"))

            # ìµœëŒ€ê°’ì´ ì„ê³„ê°’ ì´ˆê³¼
            if max_val >= critical_threshold:
                risk_factors.append({
                    "metric": metric,
                    "severity": "critical",
                    "message": f"{metric} ìµœëŒ€ê°’({max_val:.1f})ì´ ìœ„í—˜ ìˆ˜ì¤€({critical_threshold}) ì´ˆê³¼",
                    "contribution": 0.3,
                })
                risk_score += 0.3
            elif max_val >= warning_threshold:
                risk_factors.append({
                    "metric": metric,
                    "severity": "warning",
                    "message": f"{metric} ìµœëŒ€ê°’({max_val:.1f})ì´ ê²½ê³  ìˆ˜ì¤€({warning_threshold}) ì´ˆê³¼",
                    "contribution": 0.15,
                })
                risk_score += 0.15

            # í‰ê· ì´ ê²½ê³  ìˆ˜ì¤€ì— ê·¼ì ‘
            if avg >= warning_threshold * 0.9:
                risk_factors.append({
                    "metric": metric,
                    "severity": "warning",
                    "message": f"{metric} í‰ê· ({avg:.1f})ì´ ê²½ê³  ìˆ˜ì¤€ì— ê·¼ì ‘",
                    "contribution": 0.1,
                })
                risk_score += 0.1

            # ë†’ì€ ë³€ë™ì„±
            if std > avg * 0.2:  # ë³€ë™ê³„ìˆ˜ > 20%
                risk_factors.append({
                    "metric": metric,
                    "severity": "info",
                    "message": f"{metric} ë³€ë™ì„±ì´ ë†’ìŒ (í‘œì¤€í¸ì°¨: {std:.2f})",
                    "contribution": 0.05,
                })
                risk_score += 0.05

        # ê³ ì¥ í™•ë¥  ê³„ì‚° (0~1 ë²”ìœ„ë¡œ ì •ê·œí™”)
        failure_probability = min(risk_score, 1.0)
        failure_probability = round(failure_probability, 3)

        # ì”ì—¬ ì¼ìˆ˜ ì¶”ì •
        import random as rnd
        if failure_probability >= 0.7:
            days_to_failure = rnd.randint(1, 7)
        elif failure_probability >= 0.4:
            days_to_failure = rnd.randint(7, 30)
        elif failure_probability >= 0.2:
            days_to_failure = rnd.randint(30, 60)
        else:
            days_to_failure = rnd.randint(60, 180)

        # ê¶Œì¥ ì¡°ì¹˜ ê²°ì •
        if failure_probability >= 0.5:
            recommendation = "ì¦‰ì‹œ ìœ ì§€ë³´ìˆ˜ í•„ìš”"
        elif failure_probability >= 0.3:
            recommendation = "ì˜ˆë°© ì •ë¹„ ê¶Œì¥"
        elif failure_probability >= 0.1:
            recommendation = "ëª¨ë‹ˆí„°ë§ ê°•í™” ê¶Œì¥"
        else:
            recommendation = "ì •ìƒ ìš´ì˜"

        return {
            "message": f"ì¥ë¹„ ê³ ì¥ ì˜ˆì¸¡ ì™„ë£Œ: {equipment_id}",
            "data": {
                "equipment_id": equipment_id,
                "failure_probability": failure_probability,
                "estimated_days_to_failure": days_to_failure,
                "risk_factors": risk_factors,
                "risk_score": round(risk_score, 3),
                "recommendation": recommendation,
                "analysis_period_days": history_days,
                "data_points": len(sensor_data),
                "is_mock": False,
            },
        }

    # ============ ì¸ì‚¬ì´íŠ¸ ì•¡ì…˜ (ì‹ ê·œ) ============

    async def _execute_sql(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        SQL ì¿¼ë¦¬ ì‹¤í–‰ ë° ë°ì´í„° ì¡°íšŒ

        íŒŒë¼ë¯¸í„°:
            query: SQL ì¿¼ë¦¬ ë¬¸ìì—´
            params: ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° (dict)
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ, ê¸°ë³¸ê°’ 30)

        ì¶œë ¥:
            rows: ì¡°íšŒëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            columns: ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸
            row_count: í–‰ ê°œìˆ˜
        """
        from app.database import get_db_context
        from sqlalchemy import text

        query = params.get("query", "")
        query_params = params.get("params", {})
        timeout = params.get("timeout", 30)
        workflow_id = context.get("workflow_id")

        if not query or not query.strip():
            return {
                "message": "SQL ì¿¼ë¦¬ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                "data": {"rows": [], "columns": [], "row_count": 0},
            }

        # ë³´ì•ˆ: SELECT ì¿¼ë¦¬ë§Œ í—ˆìš©
        query_upper = query.strip().upper()
        if not query_upper.startswith("SELECT"):
            return {
                "message": "SELECT ì¿¼ë¦¬ë§Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                "data": {"rows": [], "columns": [], "row_count": 0, "error": "SELECT only"},
            }

        try:
            with get_db_context() as db:
                result = db.execute(text(query), query_params)
                columns = list(result.keys()) if result.keys() else []
                rows = [dict(zip(columns, row)) for row in result.fetchall()]

            log_entry = {
                "event_type": "sql_executed",
                "details": {"query": query[:200], "row_count": len(rows)},
                "context": context,
                "workflow_id": workflow_id,
            }
            execution_log_store.add_log(log_entry)

            return {
                "message": f"SQL ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ: {len(rows)}ê±´ ì¡°íšŒ",
                "data": {
                    "rows": rows,
                    "columns": columns,
                    "row_count": len(rows),
                },
            }

        except Exception as e:
            logger.error(f"SQL ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return {
                "message": f"SQL ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
                "data": {"rows": [], "columns": [], "row_count": 0, "error": str(e)},
            }

    async def _aggregate_data(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ë°ì´í„° ì§‘ê³„ (SUM, AVG, COUNT, MIN, MAX, GROUP BY)

        íŒŒë¼ë¯¸í„°:
            data: ì§‘ê³„í•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (list of dict)
            group_by: ê·¸ë£¹í™” í‚¤ (str ë˜ëŠ” list)
            aggregations: ì§‘ê³„ ì •ì˜ (dict)
                ì˜ˆ: {"total": {"field": "value", "func": "sum"},
                     "average": {"field": "value", "func": "avg"}}

        ì¶œë ¥:
            result: ì§‘ê³„ ê²°ê³¼
        """
        from collections import defaultdict
        from statistics import mean

        data = params.get("data", [])
        group_by = params.get("group_by")
        aggregations = params.get("aggregations", {})

        if not data:
            return {
                "message": "ì§‘ê³„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤",
                "data": {"result": [], "total_groups": 0},
            }

        # ê·¸ë£¹í™” í‚¤ ì •ê·œí™”
        if isinstance(group_by, str):
            group_keys = [group_by]
        elif isinstance(group_by, list):
            group_keys = group_by
        else:
            group_keys = []

        # ì§‘ê³„ í•¨ìˆ˜ ë§¤í•‘
        agg_funcs = {
            "sum": sum,
            "avg": lambda x: mean(x) if x else 0,
            "mean": lambda x: mean(x) if x else 0,
            "count": len,
            "min": lambda x: min(x) if x else 0,
            "max": lambda x: max(x) if x else 0,
        }

        # ê·¸ë£¹í™” ì—†ì´ ì „ì²´ ì§‘ê³„
        if not group_keys:
            result = {}
            for agg_name, agg_config in aggregations.items():
                field = agg_config.get("field")
                func_name = agg_config.get("func", "sum").lower()
                func = agg_funcs.get(func_name, sum)

                values = [row.get(field, 0) for row in data if field in row]
                try:
                    result[agg_name] = round(func(values), 2) if values else 0
                except (TypeError, ValueError):
                    result[agg_name] = 0

            return {
                "message": "ì „ì²´ ì§‘ê³„ ì™„ë£Œ",
                "data": {"result": result, "total_groups": 1},
            }

        # ê·¸ë£¹í™” ì§‘ê³„
        groups = defaultdict(list)
        for row in data:
            key = tuple(row.get(k, "") for k in group_keys)
            groups[key].append(row)

        results = []
        for key, group_data in groups.items():
            group_result = dict(zip(group_keys, key))

            for agg_name, agg_config in aggregations.items():
                field = agg_config.get("field")
                func_name = agg_config.get("func", "sum").lower()
                func = agg_funcs.get(func_name, sum)

                values = [row.get(field, 0) for row in group_data if field in row]
                try:
                    group_result[agg_name] = round(func(values), 2) if values else 0
                except (TypeError, ValueError):
                    group_result[agg_name] = 0

            results.append(group_result)

        return {
            "message": f"ê·¸ë£¹ ì§‘ê³„ ì™„ë£Œ: {len(results)}ê°œ ê·¸ë£¹",
            "data": {"result": results, "total_groups": len(results)},
        }

    async def _evaluate_threshold(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ë‹¤ì¤‘ ë ˆë²¨ ì„ê³„ê°’ íŒì •

        íŒŒë¼ë¯¸í„°:
            value: í‰ê°€í•  ê°’ (ìˆ«ì)
            thresholds: ì„ê³„ê°’ ì •ì˜ ë¦¬ìŠ¤íŠ¸ (ë†’ì€ ìˆœì„œëŒ€ë¡œ)
                ì˜ˆ: [
                    {"min": 95, "status": "EXCELLENT", "message": "ìš°ìˆ˜"},
                    {"min": 85, "status": "GOOD", "message": "ì–‘í˜¸"},
                    {"min": 70, "status": "WARNING", "message": "ì£¼ì˜"},
                    {"min": 0, "status": "CRITICAL", "message": "ìœ„í—˜"}
                ]
            metric_name: ì§€í‘œ ì´ë¦„ (í‘œì‹œìš©)
            inverse: Trueë©´ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ (ë¶ˆëŸ‰ë¥  ë“±)

        ì¶œë ¥:
            status: íŒì • ìƒíƒœ
            message: íŒì • ë©”ì‹œì§€
            level: ë ˆë²¨ ì¸ë±ìŠ¤ (0=ìµœìƒ)
        """
        value = params.get("value", 0)
        thresholds = params.get("thresholds", [])
        metric_name = params.get("metric_name", "ê°’")
        inverse = params.get("inverse", False)

        if not thresholds:
            # ê¸°ë³¸ 3ë‹¨ê³„ íŒì •
            thresholds = [
                {"min": 80, "status": "GREEN", "message": "ì •ìƒ"},
                {"min": 50, "status": "YELLOW", "message": "ì£¼ì˜"},
                {"min": 0, "status": "RED", "message": "ìœ„í—˜"},
            ]

        # inverse ëª¨ë“œ: ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ (ë¶ˆëŸ‰ë¥  ë“±)
        if inverse:
            thresholds = [
                {"max": 2, "status": "GREEN", "message": "ìš°ìˆ˜"},
                {"max": 5, "status": "YELLOW", "message": "ì£¼ì˜"},
                {"max": 100, "status": "RED", "message": "ìœ„í—˜"},
            ]
            for idx, t in enumerate(thresholds):
                if value <= t.get("max", float("inf")):
                    return {
                        "message": f"{metric_name} íŒì • ì™„ë£Œ",
                        "data": {
                            "value": value,
                            "status": t.get("status", "UNKNOWN"),
                            "status_message": t.get("message", ""),
                            "level": idx,
                            "metric_name": metric_name,
                        },
                    }
        else:
            # ì¼ë°˜ ëª¨ë“œ: ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
            for idx, t in enumerate(thresholds):
                if value >= t.get("min", float("-inf")):
                    return {
                        "message": f"{metric_name} íŒì • ì™„ë£Œ",
                        "data": {
                            "value": value,
                            "status": t.get("status", "UNKNOWN"),
                            "status_message": t.get("message", ""),
                            "level": idx,
                            "metric_name": metric_name,
                        },
                    }

        # ê¸°ë³¸ê°’
        return {
            "message": f"{metric_name} íŒì • ì™„ë£Œ",
            "data": {
                "value": value,
                "status": "UNKNOWN",
                "status_message": "íŒì • ë¶ˆê°€",
                "level": -1,
                "metric_name": metric_name,
            },
        }

    async def _generate_chart(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Recharts í˜¸í™˜ ì°¨íŠ¸ JSON ìƒì„±

        íŒŒë¼ë¯¸í„°:
            chart_type: ì°¨íŠ¸ ìœ í˜• (bar, line, pie, gauge)
            data: ì°¨íŠ¸ ë°ì´í„° (list of dict)
            options: ì°¨íŠ¸ ì˜µì…˜
                - title: ì°¨íŠ¸ ì œëª©
                - x_key: Xì¶• í‚¤ (bar, line)
                - y_key: Yì¶• í‚¤ (bar, line)
                - name_key: ì´ë¦„ í‚¤ (pie)
                - value_key: ê°’ í‚¤ (pie, gauge)
                - style: ìŠ¤íƒ€ì¼ (gradient_rounded, glow_smooth_curve ë“±)
                - colors: ìƒ‰ìƒ ë°°ì—´

        ì¶œë ¥:
            chart_json: Recharts í˜¸í™˜ JSON ê°ì²´
        """
        chart_type = params.get("chart_type", "bar").lower()
        data = params.get("data", [])
        options = params.get("options", {})

        title = options.get("title", "ì°¨íŠ¸")
        x_key = options.get("x_key", "name")
        y_key = options.get("y_key", "value")
        name_key = options.get("name_key", "name")
        value_key = options.get("value_key", "value")
        style = options.get("style", "default")
        colors = options.get("colors", ["#8884d8", "#82ca9d", "#ffc658", "#ff7c43", "#a4de6c"])

        chart_json = {
            "type": chart_type,
            "title": title,
            "style": style,
            "data": data,
        }

        if chart_type == "bar":
            chart_json.update({
                "xAxisDataKey": x_key,
                "bars": [{"dataKey": y_key, "fill": colors[0], "radius": [4, 4, 0, 0]}],
                "config": {
                    "gradient": style == "gradient_rounded",
                    "rounded": "rounded" in style,
                },
            })

        elif chart_type == "line":
            chart_json.update({
                "xAxisDataKey": x_key,
                "lines": [{"dataKey": y_key, "stroke": colors[0], "strokeWidth": 2}],
                "config": {
                    "glow": "glow" in style,
                    "smooth": "smooth" in style,
                    "dot": True,
                },
            })

        elif chart_type == "pie":
            # Pie ë°ì´í„° ë³€í™˜
            pie_data = []
            for idx, item in enumerate(data):
                pie_data.append({
                    "name": item.get(name_key, f"í•­ëª©{idx+1}"),
                    "value": item.get(value_key, 0),
                    "fill": colors[idx % len(colors)],
                })
            chart_json.update({
                "data": pie_data,
                "config": {
                    "innerRadius": 60 if "donut" in style else 0,
                    "outerRadius": 80,
                    "paddingAngle": 2,
                },
            })

        elif chart_type == "gauge":
            # Gauge ë°ì´í„°
            value = data[0].get(value_key, 0) if data else 0
            chart_json.update({
                "value": value,
                "max": options.get("max", 100),
                "min": options.get("min", 0),
                "config": {
                    "startAngle": 180,
                    "endAngle": 0,
                    "innerRadius": "70%",
                    "outerRadius": "100%",
                },
            })

        return {
            "message": f"{chart_type} ì°¨íŠ¸ ìƒì„± ì™„ë£Œ",
            "data": {"chart_json": chart_json},
        }

    async def _format_insight(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ì¸ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸ ìƒì„± (ë§ˆí¬ë‹¤ìš´ í¬ë§·)

        íŒŒë¼ë¯¸í„°:
            template: í…œí”Œë¦¿ ë¬¸ìì—´ (ì˜ˆ: "í˜„ì¬ {metric}ì€(ëŠ”) {value}ì…ë‹ˆë‹¤.")
            data: í…œí”Œë¦¿ ë³€ìˆ˜ (dict)
            status: ìƒíƒœ ì •ë³´ (optional)
            sections: ì„¹ì…˜ ì •ì˜ (list of dict)
                ì˜ˆ: [
                    {"type": "summary", "content": "..."},
                    {"type": "table", "headers": [...], "rows": [...]},
                    {"type": "recommendation", "content": "..."}
                ]

        ì¶œë ¥:
            insight_text: í¬ë§·íŒ…ëœ ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´
        """
        template = params.get("template", "")
        data = params.get("data", {})
        status = params.get("status", {})
        sections = params.get("sections", [])

        lines = []

        # í…œí”Œë¦¿ ê¸°ë°˜ í…ìŠ¤íŠ¸ ìƒì„±
        if template:
            try:
                formatted = template.format(**data)
                lines.append(formatted)
            except KeyError as e:
                lines.append(f"í…œí”Œë¦¿ ì˜¤ë¥˜: ë³€ìˆ˜ {e} ëˆ„ë½")

        # ì„¹ì…˜ë³„ ìƒì„±
        for section in sections:
            section_type = section.get("type", "text")

            if section_type == "summary":
                lines.append(f"\n**ìš”ì•½:** {section.get('content', '')}")

            elif section_type == "table":
                headers = section.get("headers", [])
                rows = section.get("rows", [])
                if headers:
                    lines.append("\n| " + " | ".join(headers) + " |")
                    lines.append("| " + " | ".join(["---"] * len(headers)) + " |")
                    for row in rows:
                        lines.append("| " + " | ".join(str(v) for v in row) + " |")

            elif section_type == "recommendation":
                lines.append(f"\n**ê¶Œì¥ ì¡°ì¹˜:** {section.get('content', '')}")

            elif section_type == "status":
                status_text = status.get("status", "UNKNOWN")
                status_msg = status.get("status_message", "")
                emoji = {"GREEN": "ğŸŸ¢", "YELLOW": "ğŸŸ¡", "RED": "ğŸ”´"}.get(status_text, "âšª")
                lines.append(f"\n**ìƒíƒœ:** {emoji} {status_text} - {status_msg}")

        insight_text = "\n".join(lines)

        return {
            "message": "ì¸ì‚¬ì´íŠ¸ í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ",
            "data": {"insight_text": insight_text},
        }

    async def _calculate_metric(
        self,
        params: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ë²”ìš© ì§€í‘œ ê³„ì‚° (ê°€ë™ë¥ , í•©ê²©ë¥ , ë¶ˆëŸ‰ë¥  ë“±)

        íŒŒë¼ë¯¸í„°:
            metric_type: ì§€í‘œ ìœ í˜•
                - "oee": ì„¤ë¹„ì¢…í•©íš¨ìœ¨
                - "yield": ìˆ˜ìœ¨/í•©ê²©ë¥ 
                - "defect_rate": ë¶ˆëŸ‰ë¥ 
                - "availability": ê°€ë™ë¥ 
                - "custom": ì‚¬ìš©ì ì •ì˜ ìˆ˜ì‹
            numerator: ë¶„ì ê°’
            denominator: ë¶„ëª¨ ê°’
            formula: ì‚¬ìš©ì ì •ì˜ ìˆ˜ì‹ (customì¸ ê²½ìš°)
            data: ì¶”ê°€ ë°ì´í„° (dict)

        ì¶œë ¥:
            value: ê³„ì‚°ëœ ê°’ (%)
            raw_value: ì›ë³¸ ë¹„ìœ¨
        """
        metric_type = params.get("metric_type", "custom")
        numerator = params.get("numerator", 0)
        denominator = params.get("denominator", 1)
        formula = params.get("formula", "")
        data = params.get("data", {})

        result_value = 0.0
        calculation_details = {}

        try:
            if metric_type == "oee":
                # OEE = ê°€ë™ë¥  Ã— ì„±ëŠ¥ë¥  Ã— í’ˆì§ˆë¥ 
                availability = data.get("availability", 100)
                performance = data.get("performance", 100)
                quality = data.get("quality", 100)
                result_value = (availability * performance * quality) / 10000
                calculation_details = {
                    "availability": availability,
                    "performance": performance,
                    "quality": quality,
                }

            elif metric_type == "yield":
                # ìˆ˜ìœ¨ = ì–‘í’ˆ / ì´ìƒì‚° Ã— 100
                good_count = numerator or data.get("good_count", 0)
                total_count = denominator or data.get("total_count", 1)
                result_value = (good_count / total_count) * 100 if total_count > 0 else 0
                calculation_details = {"good_count": good_count, "total_count": total_count}

            elif metric_type == "defect_rate":
                # ë¶ˆëŸ‰ë¥  = ë¶ˆëŸ‰ / ì´ìƒì‚° Ã— 100
                defect_count = numerator or data.get("defect_count", 0)
                total_count = denominator or data.get("total_count", 1)
                result_value = (defect_count / total_count) * 100 if total_count > 0 else 0
                calculation_details = {"defect_count": defect_count, "total_count": total_count}

            elif metric_type == "availability":
                # ê°€ë™ë¥  = ê°€ë™ì‹œê°„ / ê³„íšì‹œê°„ Ã— 100
                run_time = numerator or data.get("run_time", 0)
                planned_time = denominator or data.get("planned_time", 1)
                result_value = (run_time / planned_time) * 100 if planned_time > 0 else 0
                calculation_details = {"run_time": run_time, "planned_time": planned_time}

            elif metric_type == "custom":
                # ì‚¬ìš©ì ì •ì˜: ë¶„ì/ë¶„ëª¨
                if denominator > 0:
                    result_value = (numerator / denominator) * 100
                calculation_details = {"numerator": numerator, "denominator": denominator}

        except (TypeError, ZeroDivisionError) as e:
            logger.error(f"ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {e}")
            result_value = 0

        result_value = round(result_value, 2)

        return {
            "message": f"{metric_type} ì§€í‘œ ê³„ì‚° ì™„ë£Œ: {result_value}%",
            "data": {
                "metric_type": metric_type,
                "value": result_value,
                "raw_value": result_value / 100,
                "calculation_details": calculation_details,
            },
        }


# ì „ì—­ ì•¡ì…˜ ì‹¤í–‰ê¸°
action_executor = ActionExecutor()


# ============ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ê¸° ============

class WorkflowEngine:
    """
    ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì—”ì§„
    ì¡°ê±´ í‰ê°€ + ì•¡ì…˜ ì‹¤í–‰ í†µí•©

    ì§€ì› ë…¸ë“œ íƒ€ì… (ìŠ¤í™ B-5):
    - condition: ì¡°ê±´ í‰ê°€ (ìˆœì°¨ ì§„í–‰, ì‹¤íŒ¨ ì‹œ ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨)
    - action: ì•¡ì…˜ ì‹¤í–‰
    - if_else: ì¡°ê±´ ë¶„ê¸° (then/else ë¸Œëœì¹˜)
    - loop: ë°˜ë³µ ì‹¤í–‰ (ì¡°ê±´ ê¸°ë°˜ while ë˜ëŠ” íšŸìˆ˜ ê¸°ë°˜ for)
    - parallel: ë³‘ë ¬ ì‹¤í–‰
    - data: ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ì¡°íšŒ (Phase 3)
    - wait: ëŒ€ê¸° (ì§€ì • ì‹œê°„ ë˜ëŠ” ì´ë²¤íŠ¸ ê¸°ë°˜) (Phase 3)
    - approval: ì¸ê°„ ìŠ¹ì¸ ëŒ€ê¸° (Phase 3)
    - switch: ë‹¤ì¤‘ ë¶„ê¸° (ë‹¤ìˆ˜ case)
    - judgment: íŒë‹¨ ì—ì´ì „íŠ¸ í˜¸ì¶œ
    - bi: BI ë¶„ì„ ì—ì´ì „íŠ¸ í˜¸ì¶œ
    - mcp: MCP ì™¸ë¶€ ë„êµ¬ í˜¸ì¶œ
    """

    # Loop ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    MAX_LOOP_ITERATIONS = 100

    # Wait ë…¸ë“œ ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    MAX_WAIT_SECONDS = 3600  # 1ì‹œê°„

    # Approval ë…¸ë“œ ê¸°ë³¸ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    DEFAULT_APPROVAL_TIMEOUT = 86400  # 24ì‹œê°„

    def __init__(self):
        self.condition_evaluator = condition_evaluator
        self.action_executor = action_executor
        self.sensor_simulator = sensor_simulator

    async def execute_workflow(
        self,
        workflow_id: str,
        dsl: Dict[str, Any],
        input_data: Optional[Dict[str, Any]] = None,
        use_simulated_data: bool = False
    ) -> Dict[str, Any]:
        """
        ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

        Args:
            workflow_id: ì›Œí¬í”Œë¡œìš° ID
            dsl: ì›Œí¬í”Œë¡œìš° DSL ì •ì˜
            input_data: ì…ë ¥ ë°ì´í„° (ì„¼ì„œ ê°’ ë“±)
            use_simulated_data: Trueë©´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì‚¬ìš©

        Returns:
            ì‹¤í–‰ ê²°ê³¼
        """
        start_time = time.time()

        # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
        if use_simulated_data and not input_data:
            input_data = self.sensor_simulator.generate_sensor_data(scenario="random")

        context = {
            "workflow_id": workflow_id,
            "input_data": input_data or {},
            **(input_data or {})  # ì„¼ì„œ ê°’ì„ ìµœìƒìœ„ì—ë„ ë³µì‚¬
        }

        nodes = dsl.get("nodes", [])

        # ë…¸ë“œ ì‹¤í–‰
        exec_result = await self._execute_nodes(nodes, context)

        execution_time_ms = int((time.time() - start_time) * 1000)

        return {
            "workflow_id": workflow_id,
            "status": "failed" if exec_result["failed"] else "completed",
            "input_data": input_data,
            "nodes_total": exec_result["total"],
            "nodes_executed": exec_result["executed"],
            "nodes_skipped": exec_result["skipped"],
            "results": exec_result["results"],
            "error_message": exec_result["error_message"],
            "execution_time_ms": execution_time_ms,
            "executed_at": datetime.utcnow().isoformat(),
        }

    async def _execute_nodes(
        self,
        nodes: List[Dict[str, Any]],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ ì‹¤í–‰ (ì¬ê·€ í˜¸ì¶œ ê°€ëŠ¥)

        Returns:
            {
                "results": [...],
                "executed": int,
                "skipped": int,
                "total": int,
                "failed": bool,
                "error_message": str | None
            }
        """
        results = []
        executed_count = 0
        skipped_count = 0
        failed = False
        error_message = None

        for node in nodes:
            if failed:
                skipped_count += 1
                continue

            node_id = node.get("id", f"node_{uuid4().hex[:8]}")
            node_type = node.get("type")
            config = node.get("config", {})

            context["node_id"] = node_id

            try:
                if node_type == "condition":
                    result = await self._execute_condition_node(node_id, config, context)
                    results.append(result)

                    if not result.get("result", False):
                        # ì¡°ê±´ ë¶ˆì¶©ì¡± ì‹œ ì´í›„ ë…¸ë“œ ì‹¤í–‰ ì•ˆ í•¨
                        skipped_count += len(nodes) - len(results)
                        break

                    executed_count += 1

                elif node_type == "action":
                    result = await self._execute_action_node(node_id, config, context)
                    results.append(result)

                    if not result.get("success", False):
                        failed = True
                        error_message = result.get("message")
                        break

                    executed_count += 1

                elif node_type == "if_else":
                    result = await self._execute_if_else_node(node_id, config, context)
                    results.append(result)

                    if result.get("failed", False):
                        failed = True
                        error_message = result.get("error_message")
                        break

                    executed_count += 1

                elif node_type == "loop":
                    result = await self._execute_loop_node(node_id, config, context)
                    results.append(result)

                    if result.get("failed", False):
                        failed = True
                        error_message = result.get("error_message")
                        break

                    executed_count += 1

                elif node_type == "parallel":
                    result = await self._execute_parallel_node(node_id, config, context)
                    results.append(result)

                    if result.get("failed", False):
                        failed = True
                        error_message = result.get("error_message")
                        break

                    executed_count += 1

                elif node_type == "data":
                    result = await self._execute_data_node(node_id, config, context)
                    results.append(result)

                    if not result.get("success", False):
                        failed = True
                        error_message = result.get("message")
                        break

                    # ë°ì´í„° ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
                    output_var = config.get("output_variable", "data_result")
                    context[output_var] = result.get("data", {})
                    executed_count += 1

                elif node_type == "wait":
                    result = await self._execute_wait_node(node_id, config, context)
                    results.append(result)

                    if not result.get("success", False):
                        failed = True
                        error_message = result.get("message")
                        break

                    executed_count += 1

                elif node_type == "approval":
                    result = await self._execute_approval_node(node_id, config, context)
                    results.append(result)

                    if not result.get("success", False):
                        failed = True
                        error_message = result.get("message")
                        break

                    # ìŠ¹ì¸ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
                    context["approval_result"] = result.get("approval_result", {})
                    executed_count += 1

                elif node_type == "switch":
                    result = await self._execute_switch_node(node_id, config, context)
                    results.append(result)

                    if result.get("failed", False):
                        failed = True
                        error_message = result.get("error_message")
                        break

                    executed_count += 1

                elif node_type == "trigger":
                    result = await self._execute_trigger_node(node_id, config, context)
                    results.append(result)

                    if not result.get("success", False):
                        failed = True
                        error_message = result.get("message")
                        break

                    # íŠ¸ë¦¬ê±° ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
                    context["trigger_result"] = result.get("trigger_output", {})
                    executed_count += 1

                elif node_type == "code":
                    result = await self._execute_code_node(node_id, config, context)
                    results.append(result)

                    if not result.get("success", False):
                        failed = True
                        error_message = result.get("message")
                        break

                    # ì½”ë“œ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
                    output_var = config.get("output_variable", "code_result")
                    context[output_var] = result.get("output", {})
                    executed_count += 1

                else:
                    results.append({
                        "node_id": node_id,
                        "type": node_type,
                        "success": False,
                        "message": f"ì•Œ ìˆ˜ ì—†ëŠ” ë…¸ë“œ íƒ€ì…: {node_type}",
                    })
                    skipped_count += 1

            except Exception as e:
                logger.error(f"ë…¸ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {node_id} - {e}")
                failed = True
                error_message = f"ë…¸ë“œ {node_id} ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"
                results.append({
                    "node_id": node_id,
                    "type": node_type,
                    "success": False,
                    "message": error_message,
                })
                break

        return {
            "results": results,
            "executed": executed_count,
            "skipped": skipped_count,
            "total": len(nodes),
            "failed": failed,
            "error_message": error_message,
        }

    async def _execute_condition_node(
        self,
        node_id: str,
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì¡°ê±´ ë…¸ë“œ ì‹¤í–‰"""
        condition = config.get("condition", "")
        result, msg = self.condition_evaluator.evaluate(condition, context)

        return {
            "node_id": node_id,
            "type": "condition",
            "condition": condition,
            "result": result,
            "message": msg,
        }

    async def _execute_action_node(
        self,
        node_id: str,
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì•¡ì…˜ ë…¸ë“œ ì‹¤í–‰"""
        action_name = config.get("action", "")
        parameters = config.get("parameters", {})

        # íŒŒë¼ë¯¸í„°ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜ ì¹˜í™˜ ({{ë³€ìˆ˜ëª…}} í˜•ì‹)
        resolved_params = self._resolve_parameters(parameters, context)

        # ì•Œë¦¼ ì•¡ì…˜ì€ notification_managerì—ì„œ ì‹¤í–‰
        if action_name in ["send_slack_notification", "send_email", "send_sms"]:
            try:
                result = await notification_manager.execute_action(
                    action_name, resolved_params
                )
                success = result.status in [NotificationStatus.SUCCESS, NotificationStatus.SKIPPED]
                return {
                    "node_id": node_id,
                    "type": "action",
                    "action": action_name,
                    "success": success,
                    "status": result.status.value,
                    "message": result.message,
                    "details": result.details,
                }
            except Exception as e:
                logger.error(f"ì•Œë¦¼ ì•¡ì…˜ ì‹¤í–‰ ì˜¤ë¥˜: {action_name} - {e}")
                return {
                    "node_id": node_id,
                    "type": "action",
                    "action": action_name,
                    "success": False,
                    "status": "error",
                    "message": f"ì•Œë¦¼ ì•¡ì…˜ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
                }

        # ê¸°íƒ€ ì•¡ì…˜ ì§ì ‘ ì‹¤í–‰
        action_result = await self.action_executor.execute(
            action_name, resolved_params, context
        )

        return {
            "node_id": node_id,
            "type": "action",
            **action_result,
        }

    def _resolve_parameters(
        self,
        parameters: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        íŒŒë¼ë¯¸í„°ì—ì„œ {{ë³€ìˆ˜ëª…}} í˜•ì‹ì˜ í…œí”Œë¦¿ì„ ì»¨í…ìŠ¤íŠ¸ ê°’ìœ¼ë¡œ ì¹˜í™˜

        ì˜ˆ: {"message": "ì˜¨ë„ {{temperature}}ë„ ê°ì§€"} + {"temperature": 85}
            â†’ {"message": "ì˜¨ë„ 85ë„ ê°ì§€"}
        """
        import re

        def resolve_value(value: Any) -> Any:
            if isinstance(value, str):
                # {{ë³€ìˆ˜ëª…}} íŒ¨í„´ ì°¾ê¸°
                pattern = r'\{\{(\w+)\}\}'
                matches = re.findall(pattern, value)
                for var_name in matches:
                    if var_name in context:
                        # ì „ì²´ê°€ ë³€ìˆ˜ì¸ ê²½ìš° íƒ€ì… ë³´ì¡´
                        if value == f"{{{{{var_name}}}}}":
                            return context[var_name]
                        # ë¬¸ìì—´ ë‚´ ë¶€ë¶„ ì¹˜í™˜
                        value = value.replace(f"{{{{{var_name}}}}}", str(context[var_name]))
                return value
            elif isinstance(value, dict):
                return {k: resolve_value(v) for k, v in value.items()}
            elif isinstance(value, list):
                return [resolve_value(item) for item in value]
            return value

        return {k: resolve_value(v) for k, v in parameters.items()}

    async def _execute_if_else_node(
        self,
        node_id: str,
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        If/Else ë¶„ê¸° ë…¸ë“œ ì‹¤í–‰

        config í˜•ì‹:
        {
            "condition": "temperature > 80",
            "then": [ë…¸ë“œ ë¦¬ìŠ¤íŠ¸],  # ì¡°ê±´ ì°¸ì¼ ë•Œ ì‹¤í–‰
            "else": [ë…¸ë“œ ë¦¬ìŠ¤íŠ¸]   # ì¡°ê±´ ê±°ì§“ì¼ ë•Œ ì‹¤í–‰ (ì„ íƒ)
        }
        """
        condition = config.get("condition", "")
        then_nodes = config.get("then", [])
        else_nodes = config.get("else", [])

        # ì¡°ê±´ í‰ê°€
        cond_result, cond_msg = self.condition_evaluator.evaluate(condition, context)

        if cond_result:
            # then ë¸Œëœì¹˜ ì‹¤í–‰
            branch = "then"
            branch_result = await self._execute_nodes(then_nodes, context)
        else:
            # else ë¸Œëœì¹˜ ì‹¤í–‰
            branch = "else"
            if else_nodes:
                branch_result = await self._execute_nodes(else_nodes, context)
            else:
                branch_result = {
                    "results": [],
                    "executed": 0,
                    "skipped": 0,
                    "total": 0,
                    "failed": False,
                    "error_message": None,
                }

        return {
            "node_id": node_id,
            "type": "if_else",
            "condition": condition,
            "condition_result": cond_result,
            "condition_message": cond_msg,
            "branch_executed": branch,
            "branch_results": branch_result["results"],
            "branch_executed_count": branch_result["executed"],
            "failed": branch_result["failed"],
            "error_message": branch_result["error_message"],
            "success": not branch_result["failed"],
        }

    async def _execute_loop_node(
        self,
        node_id: str,
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Loop ë…¸ë“œ ì‹¤í–‰

        config í˜•ì‹ (while ë£¨í”„):
        {
            "loop_type": "while",
            "condition": "counter < 5",
            "nodes": [ë…¸ë“œ ë¦¬ìŠ¤íŠ¸],
            "max_iterations": 100  # ì„ íƒ, ê¸°ë³¸ê°’ 100
        }

        config í˜•ì‹ (for ë£¨í”„):
        {
            "loop_type": "for",
            "count": 3,
            "nodes": [ë…¸ë“œ ë¦¬ìŠ¤íŠ¸]
        }
        """
        loop_type = config.get("loop_type", "while")
        loop_nodes = config.get("nodes", [])
        max_iterations = config.get("max_iterations", self.MAX_LOOP_ITERATIONS)

        iterations = 0
        all_results = []
        failed = False
        error_message = None

        if loop_type == "for":
            # For ë£¨í”„ (íšŸìˆ˜ ê¸°ë°˜)
            count = config.get("count", 1)
            count = min(count, max_iterations)  # ìµœëŒ€ ë°˜ë³µ ì œí•œ

            for i in range(count):
                context["loop_index"] = i
                context["loop_iteration"] = i + 1

                iter_result = await self._execute_nodes(loop_nodes, context)
                all_results.append({
                    "iteration": i + 1,
                    "results": iter_result["results"],
                })

                iterations += 1

                if iter_result["failed"]:
                    failed = True
                    error_message = iter_result["error_message"]
                    break

        else:
            # While ë£¨í”„ (ì¡°ê±´ ê¸°ë°˜)
            condition = config.get("condition", "")

            while iterations < max_iterations:
                # ì¡°ê±´ í‰ê°€
                cond_result, cond_msg = self.condition_evaluator.evaluate(condition, context)

                if not cond_result:
                    break

                context["loop_index"] = iterations
                context["loop_iteration"] = iterations + 1

                iter_result = await self._execute_nodes(loop_nodes, context)
                all_results.append({
                    "iteration": iterations + 1,
                    "results": iter_result["results"],
                })

                iterations += 1

                if iter_result["failed"]:
                    failed = True
                    error_message = iter_result["error_message"]
                    break

            if iterations >= max_iterations:
                logger.warning(f"Loop {node_id} reached max iterations: {max_iterations}")

        # ë£¨í”„ ë³€ìˆ˜ ì •ë¦¬
        context.pop("loop_index", None)
        context.pop("loop_iteration", None)

        return {
            "node_id": node_id,
            "type": "loop",
            "loop_type": loop_type,
            "iterations": iterations,
            "max_iterations": max_iterations,
            "iteration_results": all_results,
            "failed": failed,
            "error_message": error_message,
            "success": not failed,
        }

    async def _execute_parallel_node(
        self,
        node_id: str,
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Parallel ë…¸ë“œ ì‹¤í–‰ (ë³‘ë ¬ ì‹¤í–‰)

        config í˜•ì‹:
        {
            "branches": [
                [ë…¸ë“œ ë¦¬ìŠ¤íŠ¸1],
                [ë…¸ë“œ ë¦¬ìŠ¤íŠ¸2],
                ...
            ],
            "fail_fast": false  # trueë©´ í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨ ì‹œ ì „ì²´ ì¤‘ë‹¨
        }
        """
        branches = config.get("branches", [])
        fail_fast = config.get("fail_fast", False)

        if not branches:
            return {
                "node_id": node_id,
                "type": "parallel",
                "branches_count": 0,
                "branch_results": [],
                "failed": False,
                "error_message": None,
                "success": True,
            }

        # ê° ë¸Œëœì¹˜ë¥¼ ë¹„ë™ê¸° íƒœìŠ¤í¬ë¡œ ìƒì„±
        async def execute_branch(branch_index: int, branch_nodes: List[Dict]) -> Dict:
            # ë¸Œëœì¹˜ë³„ ì»¨í…ìŠ¤íŠ¸ ë³µì‚¬ (ê²©ë¦¬)
            branch_context = context.copy()
            branch_context["parallel_branch_index"] = branch_index

            result = await self._execute_nodes(branch_nodes, branch_context)
            return {
                "branch_index": branch_index,
                **result,
            }

        # ëª¨ë“  ë¸Œëœì¹˜ ë³‘ë ¬ ì‹¤í–‰
        tasks = [
            execute_branch(i, branch)
            for i, branch in enumerate(branches)
        ]

        if fail_fast:
            # fail_fast: í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨í•˜ë©´ ë‚˜ë¨¸ì§€ ì·¨ì†Œ
            branch_results = []
            failed = False
            error_message = None

            for coro in asyncio.as_completed(tasks):
                result = await coro
                branch_results.append(result)

                if result["failed"]:
                    failed = True
                    error_message = f"Branch {result['branch_index']} failed: {result['error_message']}"
                    # ë‚˜ë¨¸ì§€ íƒœìŠ¤í¬ ì·¨ì†Œ (ì‹¤ì œë¡œëŠ” ì´ë¯¸ ì‹œì‘ëœ ê²ƒë“¤ì€ ì™„ë£Œë¨)
                    break

            # ë‚˜ë¨¸ì§€ ì™„ë£Œ ëŒ€ê¸°
            for task in tasks:
                if not task.done():
                    try:
                        result = await task
                        branch_results.append(result)
                    except Exception:
                        pass
        else:
            # ëª¨ë“  ë¸Œëœì¹˜ ì™„ë£Œ ëŒ€ê¸°
            branch_results = await asyncio.gather(*tasks, return_exceptions=True)

            # ì˜ˆì™¸ ì²˜ë¦¬
            processed_results = []
            failed = False
            error_messages = []

            for i, result in enumerate(branch_results):
                if isinstance(result, Exception):
                    processed_results.append({
                        "branch_index": i,
                        "results": [],
                        "executed": 0,
                        "skipped": 0,
                        "total": 0,
                        "failed": True,
                        "error_message": str(result),
                    })
                    failed = True
                    error_messages.append(f"Branch {i}: {str(result)}")
                else:
                    processed_results.append(result)
                    if result.get("failed"):
                        failed = True
                        error_messages.append(f"Branch {result['branch_index']}: {result['error_message']}")

            branch_results = processed_results
            error_message = "; ".join(error_messages) if error_messages else None

        return {
            "node_id": node_id,
            "type": "parallel",
            "branches_count": len(branches),
            "branch_results": branch_results,
            "failed": failed,
            "error_message": error_message,
            "success": not failed,
        }


    # ============ DATA ë…¸ë“œ ============

    async def _execute_data_node(
        self,
        node_id: str,
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Data ë…¸ë“œ ì‹¤í–‰ - ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ì¡°íšŒ

        config í˜•ì‹:
        {
            "source_type": "database" | "api" | "sensor" | "connector",
            "source_id": "connector_uuid" (connector íƒ€ì…ì¸ ê²½ìš°),
            "query": "SELECT * FROM ...", (database íƒ€ì…)
            "endpoint": "/api/...", (api íƒ€ì…)
            "sensor_ids": ["TEMP_01", "TEMP_02"], (sensor íƒ€ì…)
            "time_range": {"start": "...", "end": "..."}, (ì„ íƒ)
            "limit": 100, (ì„ íƒ)
            "output_variable": "sensor_data" (ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥í•  ë³€ìˆ˜ëª…)
        }
        """
        from app.database import get_db_context
        from sqlalchemy import text

        source_type = config.get("source_type", "database")
        output_variable = config.get("output_variable", "data_result")
        limit = config.get("limit", 100)

        try:
            if source_type == "database":
                # ì§ì ‘ SQL ì¿¼ë¦¬ ì‹¤í–‰ (SELECTë§Œ)
                query = config.get("query", "")
                if not query.strip().upper().startswith("SELECT"):
                    return {
                        "node_id": node_id,
                        "type": "data",
                        "success": False,
                        "message": "SELECT ì¿¼ë¦¬ë§Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
                    }

                with get_db_context() as db:
                    result = db.execute(text(query))
                    columns = list(result.keys()) if result.keys() else []
                    rows = [dict(zip(columns, row)) for row in result.fetchall()]

                return {
                    "node_id": node_id,
                    "type": "data",
                    "source_type": source_type,
                    "success": True,
                    "message": f"{len(rows)}ê±´ ì¡°íšŒë¨",
                    "data": {
                        "rows": rows[:limit],
                        "columns": columns,
                        "total_count": len(rows),
                    },
                }

            elif source_type == "sensor":
                # ì„¼ì„œ ë°ì´í„° ì¡°íšŒ (core.sensor_data í…Œì´ë¸”)
                sensor_ids = config.get("sensor_ids", [])
                time_range = config.get("time_range", {})

                with get_db_context() as db:
                    if sensor_ids:
                        # íŠ¹ì • ì„¼ì„œë§Œ ì¡°íšŒ
                        query = text("""
                            SELECT sensor_id, value, recorded_at
                            FROM core.sensor_data
                            WHERE sensor_id = ANY(:sensor_ids)
                            ORDER BY recorded_at DESC
                            LIMIT :limit
                        """)
                        result = db.execute(query, {"sensor_ids": sensor_ids, "limit": limit})
                    else:
                        # ì „ì²´ ì„¼ì„œ ì¡°íšŒ
                        query = text("""
                            SELECT sensor_id, value, recorded_at
                            FROM core.sensor_data
                            ORDER BY recorded_at DESC
                            LIMIT :limit
                        """)
                        result = db.execute(query, {"limit": limit})

                    rows = [dict(row._mapping) for row in result.fetchall()]

                return {
                    "node_id": node_id,
                    "type": "data",
                    "source_type": source_type,
                    "success": True,
                    "message": f"ì„¼ì„œ ë°ì´í„° {len(rows)}ê±´ ì¡°íšŒë¨",
                    "data": {
                        "rows": rows,
                        "sensor_ids": sensor_ids,
                        "total_count": len(rows),
                    },
                }

            elif source_type == "connector":
                # DataConnector í†µí•´ ë°ì´í„° ì¡°íšŒ (MVP: mock)
                source_id = config.get("source_id")
                return {
                    "node_id": node_id,
                    "type": "data",
                    "source_type": source_type,
                    "success": True,
                    "message": f"DataConnector {source_id} ì¡°íšŒ (mock)",
                    "data": {
                        "rows": [],
                        "connector_id": source_id,
                        "is_mock": True,
                    },
                }

            elif source_type == "api":
                # ì™¸ë¶€ API í˜¸ì¶œ (MVP: mock)
                endpoint = config.get("endpoint", "")
                return {
                    "node_id": node_id,
                    "type": "data",
                    "source_type": source_type,
                    "success": True,
                    "message": f"API {endpoint} í˜¸ì¶œ (mock)",
                    "data": {
                        "rows": [],
                        "endpoint": endpoint,
                        "is_mock": True,
                    },
                }

            else:
                return {
                    "node_id": node_id,
                    "type": "data",
                    "success": False,
                    "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” source_type: {source_type}",
                }

        except Exception as e:
            logger.error(f"Data ë…¸ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {node_id} - {e}")
            return {
                "node_id": node_id,
                "type": "data",
                "success": False,
                "message": f"ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {str(e)}",
            }

    # ============ WAIT ë…¸ë“œ ============

    async def _execute_wait_node(
        self,
        node_id: str,
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Wait ë…¸ë“œ ì‹¤í–‰ - ì§€ì • ì‹œê°„ ë˜ëŠ” ì´ë²¤íŠ¸ ëŒ€ê¸°

        config í˜•ì‹:
        {
            "wait_type": "duration" | "event" | "schedule",
            "duration_seconds": 10, (duration íƒ€ì…)
            "event_type": "sensor_alert", (event íƒ€ì…)
            "event_filter": {...}, (event íƒ€ì…)
            "schedule_cron": "0 9 * * *", (schedule íƒ€ì…)
            "timeout_seconds": 300 (ì´ë²¤íŠ¸/ìŠ¤ì¼€ì¤„ íƒ€ì„ì•„ì›ƒ)
        }
        """
        wait_type = config.get("wait_type", "duration")
        start_time = time.time()

        try:
            if wait_type == "duration":
                # ì§€ì • ì‹œê°„ ëŒ€ê¸°
                duration = config.get("duration_seconds", 0)
                duration = min(duration, self.MAX_WAIT_SECONDS)

                if duration > 0:
                    logger.info(f"Wait ë…¸ë“œ {node_id}: {duration}ì´ˆ ëŒ€ê¸° ì‹œì‘")
                    await asyncio.sleep(duration)

                elapsed = time.time() - start_time
                return {
                    "node_id": node_id,
                    "type": "wait",
                    "wait_type": wait_type,
                    "success": True,
                    "message": f"{duration}ì´ˆ ëŒ€ê¸° ì™„ë£Œ",
                    "data": {
                        "requested_duration": duration,
                        "actual_duration": round(elapsed, 2),
                    },
                }

            elif wait_type == "event":
                # ì´ë²¤íŠ¸ ëŒ€ê¸° (MVP: mock - ì¦‰ì‹œ ì™„ë£Œ)
                event_type = config.get("event_type", "unknown")
                timeout = config.get("timeout_seconds", 300)

                # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì´ë²¤íŠ¸ íë¥¼ í´ë§í•˜ê±°ë‚˜ webhook ìˆ˜ì‹ 
                # MVPì—ì„œëŠ” ì¦‰ì‹œ ì´ë²¤íŠ¸ ìˆ˜ì‹ ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
                logger.info(f"Wait ë…¸ë“œ {node_id}: ì´ë²¤íŠ¸ '{event_type}' ëŒ€ê¸° (mock)")

                return {
                    "node_id": node_id,
                    "type": "wait",
                    "wait_type": wait_type,
                    "success": True,
                    "message": f"ì´ë²¤íŠ¸ '{event_type}' ìˆ˜ì‹ ë¨ (mock)",
                    "data": {
                        "event_type": event_type,
                        "timeout_seconds": timeout,
                        "is_mock": True,
                        "event_data": {},
                    },
                }

            elif wait_type == "schedule":
                # ìŠ¤ì¼€ì¤„ ëŒ€ê¸° (cron í‘œí˜„ì‹)
                schedule_cron = config.get("schedule_cron", "")
                timeout = config.get("timeout_seconds", 3600)

                # MVP: ì¦‰ì‹œ ì™„ë£Œ
                logger.info(f"Wait ë…¸ë“œ {node_id}: ìŠ¤ì¼€ì¤„ '{schedule_cron}' ëŒ€ê¸° (mock)")

                return {
                    "node_id": node_id,
                    "type": "wait",
                    "wait_type": wait_type,
                    "success": True,
                    "message": f"ìŠ¤ì¼€ì¤„ '{schedule_cron}' ë„ë‹¬ (mock)",
                    "data": {
                        "schedule_cron": schedule_cron,
                        "timeout_seconds": timeout,
                        "is_mock": True,
                    },
                }

            else:
                return {
                    "node_id": node_id,
                    "type": "wait",
                    "success": False,
                    "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” wait_type: {wait_type}",
                }

        except asyncio.CancelledError:
            return {
                "node_id": node_id,
                "type": "wait",
                "success": False,
                "message": "ëŒ€ê¸° ì¤‘ ì·¨ì†Œë¨",
            }
        except Exception as e:
            logger.error(f"Wait ë…¸ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {node_id} - {e}")
            return {
                "node_id": node_id,
                "type": "wait",
                "success": False,
                "message": f"ëŒ€ê¸° ì˜¤ë¥˜: {str(e)}",
            }

    # ============ APPROVAL ë…¸ë“œ ============

    async def _execute_approval_node(
        self,
        node_id: str,
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Approval ë…¸ë“œ ì‹¤í–‰ - ì¸ê°„ ìŠ¹ì¸ ëŒ€ê¸°

        config í˜•ì‹:
        {
            "approval_type": "single" | "multi" | "quorum",
            "approvers": ["user1@example.com", "user2@example.com"],
            "quorum_count": 2, (quorum íƒ€ì…ì¼ ë•Œ í•„ìš”í•œ ìŠ¹ì¸ ìˆ˜)
            "timeout_seconds": 86400, (ê¸°ë³¸ 24ì‹œê°„)
            "notification_channel": "slack" | "email",
            "notification_message": "ìŠ¹ì¸ ìš”ì²­...",
            "auto_approve_on_timeout": false (íƒ€ì„ì•„ì›ƒ ì‹œ ìë™ ìŠ¹ì¸ ì—¬ë¶€)
        }

        MVP êµ¬í˜„:
        - ìŠ¹ì¸ ìš”ì²­ì„ DBì— ì €ì¥
        - ì•Œë¦¼ ì „ì†¡ (mock)
        - ì¦‰ì‹œ ìë™ ìŠ¹ì¸ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” webhook/í´ë§ìœ¼ë¡œ ìŠ¹ì¸ ëŒ€ê¸°)
        """

        approval_type = config.get("approval_type", "single")
        approvers = config.get("approvers", [])
        timeout_seconds = config.get("timeout_seconds", self.DEFAULT_APPROVAL_TIMEOUT)
        notification_channel = config.get("notification_channel", "slack")
        notification_message = config.get("notification_message", "ì›Œí¬í”Œë¡œìš° ìŠ¹ì¸ ìš”ì²­")
        auto_approve = config.get("auto_approve_on_timeout", False)

        approval_id = str(uuid4())
        workflow_id = context.get("workflow_id")

        try:
            # ìŠ¹ì¸ ìš”ì²­ ìƒì„± (DB ì €ì¥)
            # MVP: core.workflow_approvals í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ì¸ë©”ëª¨ë¦¬ë¡œ ì²˜ë¦¬
            approval_request = {
                "approval_id": approval_id,
                "workflow_id": workflow_id,
                "node_id": node_id,
                "approval_type": approval_type,
                "approvers": approvers,
                "status": "pending",
                "created_at": datetime.utcnow().isoformat(),
                "timeout_at": datetime.utcnow().isoformat(),  # ì‹¤ì œë¡œëŠ” + timeout_seconds
            }

            # ë¡œê·¸ì— ìŠ¹ì¸ ìš”ì²­ ê¸°ë¡
            log_entry = {
                "event_type": "approval_requested",
                "details": approval_request,
                "context": context,
                "workflow_id": workflow_id,
            }
            execution_log_store.add_log(log_entry)

            # ì•Œë¦¼ ì „ì†¡ (mock)
            logger.info(f"Approval ë…¸ë“œ {node_id}: ìŠ¹ì¸ ìš”ì²­ ìƒì„±ë¨ - {approvers}")
            if notification_channel == "slack":
                # ì‹¤ì œë¡œëŠ” notification_manager ì‚¬ìš©
                logger.info(f"Slack ì•Œë¦¼ ì „ì†¡ (mock): {notification_message}")
            elif notification_channel == "email":
                logger.info(f"ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡ (mock): {notification_message} -> {approvers}")

            # MVP: ìë™ ìŠ¹ì¸ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í´ë§/webhook ëŒ€ê¸°)
            approval_result = {
                "approval_id": approval_id,
                "status": "approved",  # approved | rejected | timeout
                "approved_by": approvers[0] if approvers else "system",
                "approved_at": datetime.utcnow().isoformat(),
                "comment": "Auto-approved (MVP mode)",
                "is_mock": True,
            }

            # ìŠ¹ì¸ ì™„ë£Œ ë¡œê·¸
            log_entry = {
                "event_type": "approval_completed",
                "details": approval_result,
                "context": context,
                "workflow_id": workflow_id,
            }
            execution_log_store.add_log(log_entry)

            return {
                "node_id": node_id,
                "type": "approval",
                "approval_type": approval_type,
                "success": True,
                "message": "ìŠ¹ì¸ ì™„ë£Œ (auto-approved in MVP)",
                "approval_result": approval_result,
                "data": {
                    "approval_id": approval_id,
                    "approvers": approvers,
                    "status": "approved",
                },
            }

        except Exception as e:
            logger.error(f"Approval ë…¸ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {node_id} - {e}")
            return {
                "node_id": node_id,
                "type": "approval",
                "success": False,
                "message": f"ìŠ¹ì¸ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}",
            }

    # ============ SWITCH ë…¸ë“œ ============

    async def _execute_switch_node(
        self,
        node_id: str,
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Switch ë…¸ë“œ ì‹¤í–‰ - ë‹¤ì¤‘ ë¶„ê¸° (ë‹¤ìˆ˜ case)

        config í˜•ì‹:
        {
            "expression": "status",  # í‰ê°€í•  ë³€ìˆ˜/í‘œí˜„ì‹
            "cases": [
                {"value": "running", "nodes": [...]},
                {"value": "stopped", "nodes": [...]},
                {"value": "error", "nodes": [...]}
            ],
            "default": [...]  # ë§¤ì¹­ë˜ëŠ” caseê°€ ì—†ì„ ë•Œ ì‹¤í–‰ (ì„ íƒ)
        }
        """
        expression = config.get("expression", "")
        cases = config.get("cases", [])
        default_nodes = config.get("default", [])

        # í‘œí˜„ì‹ í‰ê°€í•˜ì—¬ ê°’ ê°€ì ¸ì˜¤ê¸°
        switch_value = context.get(expression)
        if switch_value is None:
            # í‘œí˜„ì‹ì´ ì¡°ê±´ì‹ì¼ ìˆ˜ë„ ìˆìŒ
            switch_value = expression

        matched_case = None
        matched_nodes = None

        # case ë§¤ì¹­
        for case in cases:
            case_value = case.get("value")
            if switch_value == case_value:
                matched_case = case_value
                matched_nodes = case.get("nodes", [])
                break

        # ë§¤ì¹­ëœ caseê°€ ì—†ìœ¼ë©´ default ì‹¤í–‰
        if matched_nodes is None:
            if default_nodes:
                matched_case = "default"
                matched_nodes = default_nodes
            else:
                # ì•„ë¬´ê²ƒë„ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
                return {
                    "node_id": node_id,
                    "type": "switch",
                    "expression": expression,
                    "switch_value": switch_value,
                    "matched_case": None,
                    "case_results": [],
                    "failed": False,
                    "error_message": None,
                    "success": True,
                    "message": "ë§¤ì¹­ë˜ëŠ” case ì—†ìŒ (defaultë„ ì—†ìŒ)",
                }

        # ë§¤ì¹­ëœ ë…¸ë“œ ì‹¤í–‰
        case_result = await self._execute_nodes(matched_nodes, context)

        return {
            "node_id": node_id,
            "type": "switch",
            "expression": expression,
            "switch_value": switch_value,
            "matched_case": matched_case,
            "case_results": case_result["results"],
            "case_executed_count": case_result["executed"],
            "failed": case_result["failed"],
            "error_message": case_result["error_message"],
            "success": not case_result["failed"],
        }

    async def _execute_trigger_node(
        self,
        node_id: str,
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        TRIGGER ë…¸ë“œ ì‹¤í–‰

        ìŠ¤í™ (B-5 ì„¹ì…˜ 4.7):
        - trigger_type: schedule, event, condition, webhook, manual
        - schedule_config: cron í‘œí˜„ì‹, timezone
        - event_config: event_type, filter
        - condition_config: expression, check_interval_seconds, debounce_seconds
        - webhook_config: path, method, auth, rate_limit

        TRIGGER ë…¸ë“œëŠ” ì›Œí¬í”Œë¡œìš°ì˜ ì‹œì‘ì ìœ¼ë¡œ:
        1. ì›Œí¬í”Œë¡œìš° DSLì—ì„œ íŠ¸ë¦¬ê±° ì¡°ê±´ ì •ì˜
        2. ì¡°ê±´ ì¶©ì¡± ì‹œ ì›Œí¬í”Œë¡œìš° ìë™ ì‹œì‘
        3. ì´ ë©”ì„œë“œëŠ” íŠ¸ë¦¬ê±°ê°€ ì‹¤í–‰ë  ë•Œ ì´ˆê¸° ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
        """
        trigger_type = config.get("trigger_type", "manual")
        trigger_time = datetime.utcnow().isoformat()

        # íŠ¸ë¦¬ê±° íƒ€ì…ë³„ ì²˜ë¦¬
        if trigger_type == "schedule":
            schedule_config = config.get("schedule_config", {})
            cron_expression = schedule_config.get("cron", "")
            timezone = schedule_config.get("timezone", "UTC")

            trigger_output = {
                "triggered": True,
                "trigger_time": trigger_time,
                "trigger_reason": f"Schedule: {cron_expression}",
                "trigger_type": "schedule",
                "schedule": {
                    "cron": cron_expression,
                    "timezone": timezone,
                }
            }

        elif trigger_type == "event":
            event_config = config.get("event_config", {})
            event_type = event_config.get("event_type", "")
            event_filter = event_config.get("filter", {})

            # ì´ë²¤íŠ¸ ë°ì´í„°ëŠ” ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê°€ì ¸ì˜´ (ì´ë²¤íŠ¸ ë²„ìŠ¤ì—ì„œ ì „ë‹¬)
            event_data = context.get("_event_data", {})

            trigger_output = {
                "triggered": True,
                "trigger_time": trigger_time,
                "trigger_reason": f"Event: {event_type}",
                "trigger_type": "event",
                "event": {
                    "event_type": event_type,
                    "filter": event_filter,
                    "data": event_data,
                }
            }

        elif trigger_type == "condition":
            condition_config = config.get("condition_config", {})
            expression = condition_config.get("expression", "true")
            check_interval = condition_config.get("check_interval_seconds", 60)
            debounce = condition_config.get("debounce_seconds", 0)

            # ì¡°ê±´ í‰ê°€
            condition_result, condition_msg = self.condition_evaluator.evaluate(
                expression, context
            )

            trigger_output = {
                "triggered": condition_result,
                "trigger_time": trigger_time,
                "trigger_reason": f"Condition: {expression}",
                "trigger_type": "condition",
                "condition": {
                    "expression": expression,
                    "result": condition_result,
                    "message": condition_msg,
                    "check_interval_seconds": check_interval,
                    "debounce_seconds": debounce,
                }
            }

            if not condition_result:
                return {
                    "node_id": node_id,
                    "type": "trigger",
                    "success": False,
                    "message": f"íŠ¸ë¦¬ê±° ì¡°ê±´ ë¶ˆì¶©ì¡±: {condition_msg}",
                    "trigger_output": trigger_output,
                }

        elif trigger_type == "webhook":
            webhook_config = config.get("webhook_config", {})
            webhook_path = webhook_config.get("path", "")
            webhook_method = webhook_config.get("method", "POST")

            # ì›¹í›… ë°ì´í„°ëŠ” ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê°€ì ¸ì˜´
            webhook_data = context.get("_webhook_data", {})

            trigger_output = {
                "triggered": True,
                "trigger_time": trigger_time,
                "trigger_reason": f"Webhook: {webhook_method} {webhook_path}",
                "trigger_type": "webhook",
                "webhook": {
                    "path": webhook_path,
                    "method": webhook_method,
                    "data": webhook_data,
                }
            }

        else:  # manual
            trigger_output = {
                "triggered": True,
                "trigger_time": trigger_time,
                "trigger_reason": "Manual trigger",
                "trigger_type": "manual",
            }

        # ë¡œê·¸ ê¸°ë¡
        execution_log_store.add_log({
            "event_type": "trigger_executed",
            "workflow_id": context.get("workflow_id"),
            "node_id": node_id,
            "trigger_type": trigger_type,
            "trigger_output": trigger_output,
        })

        return {
            "node_id": node_id,
            "type": "trigger",
            "success": True,
            "message": f"íŠ¸ë¦¬ê±° ì‹¤í–‰ ì™„ë£Œ: {trigger_type}",
            "trigger_output": trigger_output,
        }

    async def _execute_code_node(
        self,
        node_id: str,
        config: Dict[str, Any],
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        CODE ë…¸ë“œ ì‹¤í–‰ (Python ìƒŒë“œë°•ìŠ¤)

        ìŠ¤í™ (B-5 ì„¹ì…˜ 4.4):
        - code_type: transform, calculate, validate, format, custom
        - code_template_id: ì‚¬ì „ ì •ì˜ëœ ì½”ë“œ í…œí”Œë¦¿ ID
        - inline_code: ì¸ë¼ì¸ ì½”ë“œ (ë³´ì•ˆ ì£¼ì˜)
        - sandbox_enabled: ìƒŒë“œë°•ìŠ¤ ëª¨ë“œ
        - allowed_imports: í—ˆìš©ëœ import ëª©ë¡

        ë³´ì•ˆ ê³ ë ¤ì‚¬í•­:
        1. RestrictedPython ì‚¬ìš© (exec ì§ì ‘ ì‚¬ìš© ê¸ˆì§€)
        2. í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ importë§Œ í—ˆìš©
        3. íƒ€ì„ì•„ì›ƒ ë° ë©”ëª¨ë¦¬ ì œí•œ
        4. íŒŒì¼ ì‹œìŠ¤í…œ ì ‘ê·¼ ì°¨ë‹¨
        """
        code_type = config.get("code_type", "custom")
        code_template_id = config.get("code_template_id")
        inline_code = config.get("inline_code")
        sandbox_enabled = config.get("sandbox_enabled", True)
        allowed_imports = config.get("allowed_imports", [
            "json", "datetime", "math", "statistics", "re"
        ])
        timeout_ms = config.get("timeout_ms", 30000)
        memory_limit_mb = config.get("memory_limit_mb", 256)

        # ì…ë ¥ ë°ì´í„°
        input_data = config.get("input", {})
        resolved_input = {}

        # ì…ë ¥ ë°ì´í„°ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜ ì°¸ì¡° í•´ì„
        for key, value in input_data.items():
            if isinstance(value, str) and value.startswith("${") and value.endswith("}"):
                var_name = value[2:-1]  # ${var} -> var
                resolved_input[key] = context.get(var_name, value)
            else:
                resolved_input[key] = value

        # ì½”ë“œ í…œí”Œë¦¿ ë¡œë“œ ë˜ëŠ” ì¸ë¼ì¸ ì½”ë“œ ì‚¬ìš©
        code_to_execute = None

        if code_template_id:
            # í…œí”Œë¦¿ ì €ì¥ì†Œì—ì„œ ì½”ë“œ ë¡œë“œ (í–¥í›„ DB ì—°ë™)
            code_to_execute = self._load_code_template(code_template_id)
            if not code_to_execute:
                return {
                    "node_id": node_id,
                    "type": "code",
                    "success": False,
                    "message": f"ì½”ë“œ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {code_template_id}",
                    "output": None,
                }
        elif inline_code:
            code_to_execute = inline_code
        else:
            return {
                "node_id": node_id,
                "type": "code",
                "success": False,
                "message": "ì‹¤í–‰í•  ì½”ë“œê°€ ì—†ìŒ (code_template_id ë˜ëŠ” inline_code í•„ìš”)",
                "output": None,
            }

        # ìƒŒë“œë°•ìŠ¤ ì‹¤í–‰
        start_time = time.time()
        try:
            if sandbox_enabled:
                output = await self._execute_code_sandbox(
                    code_to_execute,
                    resolved_input,
                    allowed_imports,
                    timeout_ms,
                    memory_limit_mb
                )
            else:
                # ë¹„ìƒŒë“œë°•ìŠ¤ ëª¨ë“œ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©, í”„ë¡œë•ì…˜ì—ì„œ ë¹„ê¶Œì¥)
                logger.warning(f"CODE ë…¸ë“œ {node_id} ë¹„ìƒŒë“œë°•ìŠ¤ ëª¨ë“œë¡œ ì‹¤í–‰")
                output = await self._execute_code_unsafe(
                    code_to_execute,
                    resolved_input,
                    timeout_ms
                )

            execution_time_ms = int((time.time() - start_time) * 1000)

            # ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ê²€ì¦ (ì„ íƒ)
            output_schema = config.get("output", {}).get("schema")
            if output_schema:
                # JSON Schema ê²€ì¦ (í–¥í›„ êµ¬í˜„)
                pass

            # ë¡œê·¸ ê¸°ë¡
            execution_log_store.add_log({
                "event_type": "code_executed",
                "workflow_id": context.get("workflow_id"),
                "node_id": node_id,
                "code_type": code_type,
                "execution_time_ms": execution_time_ms,
                "sandbox_enabled": sandbox_enabled,
            })

            return {
                "node_id": node_id,
                "type": "code",
                "success": True,
                "message": f"ì½”ë“œ ì‹¤í–‰ ì™„ë£Œ ({execution_time_ms}ms)",
                "output": output,
                "execution_time_ms": execution_time_ms,
                "code_type": code_type,
                "sandbox_enabled": sandbox_enabled,
            }

        except asyncio.TimeoutError:
            return {
                "node_id": node_id,
                "type": "code",
                "success": False,
                "message": f"ì½”ë“œ ì‹¤í–‰ íƒ€ì„ì•„ì›ƒ ({timeout_ms}ms)",
                "output": None,
            }
        except Exception as e:
            logger.error(f"CODE ë…¸ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {node_id} - {e}")
            return {
                "node_id": node_id,
                "type": "code",
                "success": False,
                "message": f"ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}",
                "output": None,
            }

    def _load_code_template(self, template_id: str) -> Optional[str]:
        """
        ì½”ë“œ í…œí”Œë¦¿ ë¡œë“œ

        ì‚¬ì „ ì •ì˜ëœ ì•ˆì „í•œ ì½”ë“œ í…œí”Œë¦¿:
        - defect_rate_calc: ë¶ˆëŸ‰ë¥  ê³„ì‚°
        - moving_average: ì´ë™ í‰ê·  ê³„ì‚°
        - data_transform: ë°ì´í„° ë³€í™˜
        - anomaly_score: ì´ìƒì¹˜ ì ìˆ˜ ê³„ì‚°
        """
        # ë‚´ì¥ í…œí”Œë¦¿
        templates = {
            "defect_rate_calc": '''
# ë¶ˆëŸ‰ë¥  ê³„ì‚° í…œí”Œë¦¿
total = data.get("total_count", 0)
defects = data.get("defect_count", 0)
threshold = parameters.get("threshold", 0.05)

if total > 0:
    defect_rate = defects / total
else:
    defect_rate = 0

result = {
    "defect_rate": defect_rate,
    "is_over_threshold": defect_rate > threshold,
    "total_count": total,
    "defect_count": defects,
}
''',
            "moving_average": '''
# ì´ë™ í‰ê·  ê³„ì‚° í…œí”Œë¦¿
import statistics
values = data.get("values", [])
window = parameters.get("window", 7)

if len(values) >= window:
    ma = statistics.mean(values[-window:])
else:
    ma = statistics.mean(values) if values else 0

result = {
    "moving_average": ma,
    "window_size": window,
    "data_points": len(values),
}
''',
            "data_transform": '''
# ë°ì´í„° ë³€í™˜ í…œí”Œë¦¿
import json
source_data = data.get("source", {})
mapping = parameters.get("mapping", {})

transformed = {}
for target_key, source_key in mapping.items():
    if source_key in source_data:
        transformed[target_key] = source_data[source_key]

result = transformed
''',
            "anomaly_score": '''
# ì´ìƒì¹˜ ì ìˆ˜ ê³„ì‚° í…œí”Œë¦¿
import statistics
values = data.get("values", [])
current = data.get("current_value", 0)

if len(values) >= 2:
    mean = statistics.mean(values)
    stdev = statistics.stdev(values)
    if stdev > 0:
        z_score = abs(current - mean) / stdev
    else:
        z_score = 0
else:
    z_score = 0
    mean = current
    stdev = 0

result = {
    "z_score": z_score,
    "mean": mean,
    "stdev": stdev,
    "is_anomaly": z_score > 2.0,
}
''',
        }

        return templates.get(template_id)

    async def _execute_code_sandbox(
        self,
        code: str,
        input_data: Dict[str, Any],
        allowed_imports: List[str],
        timeout_ms: int,
        memory_limit_mb: int
    ) -> Dict[str, Any]:
        """
        ì œí•œëœ ìƒŒë“œë°•ìŠ¤ í™˜ê²½ì—ì„œ Python ì½”ë“œ ì‹¤í–‰

        ë³´ì•ˆ ì¡°ì¹˜:
        1. í—ˆìš©ëœ importë§Œ ê°€ëŠ¥
        2. ë‚´ì¥ í•¨ìˆ˜ ì œí•œ (open, exec, eval ë“± ì°¨ë‹¨)
        3. íƒ€ì„ì•„ì›ƒ ì ìš©
        4. ê²°ê³¼ëŠ” 'result' ë³€ìˆ˜ë¡œ ë°˜í™˜
        """
        # í—ˆìš©ëœ ëª¨ë“ˆ ì‚¬ì „ import
        safe_globals = {
            "__builtins__": {
                # ì•ˆì „í•œ ë‚´ì¥ í•¨ìˆ˜ë§Œ í—ˆìš©
                "len": len,
                "range": range,
                "enumerate": enumerate,
                "zip": zip,
                "map": map,
                "filter": filter,
                "sorted": sorted,
                "reversed": reversed,
                "min": min,
                "max": max,
                "sum": sum,
                "abs": abs,
                "round": round,
                "int": int,
                "float": float,
                "str": str,
                "bool": bool,
                "list": list,
                "dict": dict,
                "set": set,
                "tuple": tuple,
                "isinstance": isinstance,
                "type": type,
                "None": None,
                "True": True,
                "False": False,
            }
        }

        # í—ˆìš©ëœ ëª¨ë“ˆ import
        for module_name in allowed_imports:
            try:
                if module_name == "json":
                    import json as _json
                    safe_globals["json"] = _json
                elif module_name == "datetime":
                    import datetime as _datetime
                    safe_globals["datetime"] = _datetime
                elif module_name == "math":
                    import math as _math
                    safe_globals["math"] = _math
                elif module_name == "statistics":
                    import statistics as _statistics
                    safe_globals["statistics"] = _statistics
                elif module_name == "re":
                    import re as _re
                    safe_globals["re"] = _re
                # pandas, numpyëŠ” ì„¤ì¹˜ ì—¬ë¶€ì— ë”°ë¼ ì„ íƒì  í—ˆìš©
                elif module_name == "pandas":
                    try:
                        import pandas as _pd
                        safe_globals["pd"] = _pd
                    except ImportError:
                        pass
                elif module_name == "numpy":
                    try:
                        import numpy as _np
                        safe_globals["np"] = _np
                    except ImportError:
                        pass
            except ImportError:
                logger.warning(f"ëª¨ë“ˆ import ì‹¤íŒ¨: {module_name}")

        # ì…ë ¥ ë°ì´í„°ë¥¼ localsì— ì„¤ì •
        safe_locals = {
            "data": input_data.get("data", {}),
            "parameters": input_data.get("parameters", {}),
            "context": input_data.get("context", {}),
            "result": None,  # ê²°ê³¼ ì €ì¥ìš©
        }

        # íƒ€ì„ì•„ì›ƒ ì ìš©í•˜ì—¬ ì‹¤í–‰
        timeout_sec = timeout_ms / 1000

        def run_code():
            exec(code, safe_globals, safe_locals)
            return safe_locals.get("result", {})

        # asyncioì—ì„œ ë™ê¸° ì½”ë“œ ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ í¬í•¨)
        loop = asyncio.get_event_loop()
        try:
            result = await asyncio.wait_for(
                loop.run_in_executor(None, run_code),
                timeout=timeout_sec
            )
            return result if result is not None else {}
        except asyncio.TimeoutError:
            raise

    async def _execute_code_unsafe(
        self,
        code: str,
        input_data: Dict[str, Any],
        timeout_ms: int
    ) -> Dict[str, Any]:
        """
        ë¹„ìƒŒë“œë°•ìŠ¤ ëª¨ë“œ ì‹¤í–‰ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)

        ì£¼ì˜: í”„ë¡œë•ì…˜ì—ì„œ ì‚¬ìš© ê¸ˆì§€
        """
        safe_locals = {
            "data": input_data.get("data", {}),
            "parameters": input_data.get("parameters", {}),
            "context": input_data.get("context", {}),
            "result": None,
        }

        timeout_sec = timeout_ms / 1000

        def run_code():
            exec(code, {"__builtins__": __builtins__}, safe_locals)
            return safe_locals.get("result", {})

        loop = asyncio.get_event_loop()
        try:
            result = await asyncio.wait_for(
                loop.run_in_executor(None, run_code),
                timeout=timeout_sec
            )
            return result if result is not None else {}
        except asyncio.TimeoutError:
            raise


# ì „ì—­ ì›Œí¬í”Œë¡œìš° ì—”ì§„
workflow_engine = WorkflowEngine()
