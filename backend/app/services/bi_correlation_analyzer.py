"""
BI Correlation Analyzer - ì—°ê´€ ë¶„ì„ ì—”ì§„

ë‹¬ì„±ë¥ , ë¶ˆëŸ‰ë¥ , ë¹„ê°€ë™ ì‹œê°„ ë“±ì˜ ì´ìƒ ì§•í›„ë¥¼ ê°ì§€í•˜ê³ 
ìë™ìœ¼ë¡œ ì›ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

from dataclasses import dataclass
from datetime import date, timedelta
from decimal import Decimal
from typing import Any, Optional
from uuid import UUID

from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

import logging

logger = logging.getLogger(__name__)


def _convert_decimal(value: Any) -> Any:
    """Decimalì„ floatë¡œ ë³€í™˜"""
    if isinstance(value, Decimal):
        return float(value)
    if isinstance(value, dict):
        return {k: _convert_decimal(v) for k, v in value.items()}
    if isinstance(value, list):
        return [_convert_decimal(v) for v in value]
    return value


@dataclass
class AnalysisTrigger:
    """ë¶„ì„ íŠ¸ë¦¬ê±° ì¡°ê±´"""

    trigger_type: str  # 'low_achievement', 'high_defect', 'sudden_drop', 'high_downtime'
    severity: str  # 'warning', 'critical'
    affected_line: str
    metric_name: str
    metric_value: float
    threshold_value: float
    message: str


class CorrelationAnalyzer:
    """
    ì—°ê´€ ë¶„ì„ ì—”ì§„

    ì´ìƒ ì§•í›„ ê°ì§€ ì‹œ ìë™ìœ¼ë¡œ ì›ì¸ ë¶„ì„ì„ ìˆ˜í–‰:
    - ë‹¬ì„±ë¥  ì €ì¡° â†’ ë¹„ê°€ë™ ì›ì¸ ë¶„ì„
    - ë¶ˆëŸ‰ë¥  ê¸‰ì¦ â†’ ë¶ˆëŸ‰ ìœ í˜• ë° íŒŒë¼ë¯¸í„° ë¶„ì„
    - ê¸‰ê²©í•œ ë³€ë™ â†’ ë³€í™” ì›ì¸ ë¶„ì„
    """

    def __init__(self, db: AsyncSession, tenant_id: UUID):
        self.db = db
        self.tenant_id = tenant_id

    # =====================================================
    # 1. íŠ¸ë¦¬ê±° ì¡°ê±´ ê°ì§€
    # =====================================================
    def detect_triggers(
        self,
        production_data: list[dict],
        comparison_data: dict,
        thresholds: dict,
    ) -> list[AnalysisTrigger]:
        """
        ìƒì‚° ë°ì´í„°ì—ì„œ ë¶„ì„ì´ í•„ìš”í•œ ì´ìƒ ì§•í›„ ê°ì§€

        Args:
            production_data: ë¼ì¸ë³„ ìƒì‚° í˜„í™©
            comparison_data: ì „ì¼/ì „ì£¼ ëŒ€ë¹„ ë°ì´í„°
            thresholds: KPI ê¸°ì¤€ê°’

        Returns:
            ê°ì§€ëœ íŠ¸ë¦¬ê±° ëª©ë¡
        """
        triggers = []

        # ë‹¬ì„±ë¥  ê¸°ì¤€ê°’
        ach_green = thresholds.get("achievement_rate", {}).get("green", 95.0)
        ach_yellow = thresholds.get("achievement_rate", {}).get("yellow", 80.0)

        # ë¶ˆëŸ‰ë¥  ê¸°ì¤€ê°’
        def_green = thresholds.get("defect_rate", {}).get("green", 2.0)
        def_yellow = thresholds.get("defect_rate", {}).get("yellow", 3.0)

        # ë¹„ê°€ë™ ê¸°ì¤€ê°’ (ë¶„)
        dt_green = thresholds.get("downtime_minutes", {}).get("green", 30.0)
        dt_yellow = thresholds.get("downtime_minutes", {}).get("yellow", 60.0)

        for line in production_data:
            line_code = line.get("line_code", "Unknown")
            achievement = line.get("achievement_rate", 0)
            defect_rate = line.get("defect_rate", 0)
            downtime = line.get("downtime_min", 0)

            # 1. ë‹¬ì„±ë¥  ì €ì¡°
            if achievement < ach_yellow:
                severity = "critical" if achievement < ach_yellow * 0.8 else "warning"
                triggers.append(
                    AnalysisTrigger(
                        trigger_type="low_achievement",
                        severity=severity,
                        affected_line=line_code,
                        metric_name="ë‹¬ì„±ë¥ ",
                        metric_value=achievement,
                        threshold_value=ach_yellow,
                        message=f"{line_code} ë¼ì¸ ë‹¬ì„±ë¥  {achievement}% (ëª©í‘œ {ach_yellow}% ë¯¸ë‹¬)",
                    )
                )

            # 2. ë¶ˆëŸ‰ë¥  ì´ˆê³¼
            if defect_rate > def_yellow:
                severity = "critical" if defect_rate > def_yellow * 1.5 else "warning"
                triggers.append(
                    AnalysisTrigger(
                        trigger_type="high_defect",
                        severity=severity,
                        affected_line=line_code,
                        metric_name="ë¶ˆëŸ‰ë¥ ",
                        metric_value=defect_rate,
                        threshold_value=def_yellow,
                        message=f"{line_code} ë¼ì¸ ë¶ˆëŸ‰ë¥  {defect_rate}% (ê¸°ì¤€ {def_yellow}% ì´ˆê³¼)",
                    )
                )

            # 3. ë¹„ê°€ë™ ì‹œê°„ ì´ˆê³¼
            if downtime > dt_yellow:
                severity = "critical" if downtime > dt_yellow * 1.5 else "warning"
                triggers.append(
                    AnalysisTrigger(
                        trigger_type="high_downtime",
                        severity=severity,
                        affected_line=line_code,
                        metric_name="ë¹„ê°€ë™ ì‹œê°„",
                        metric_value=downtime,
                        threshold_value=dt_yellow,
                        message=f"{line_code} ë¼ì¸ ë¹„ê°€ë™ {downtime}ë¶„ (ê¸°ì¤€ {dt_yellow}ë¶„ ì´ˆê³¼)",
                    )
                )

        # 4. ì „ì¼ ëŒ€ë¹„ ê¸‰ê²©í•œ í•˜ë½ (10% ì´ìƒ)
        if comparison_data and "by_line" in comparison_data:
            for line_code, comp in comparison_data["by_line"].items():
                vs_yesterday = comp.get("vs_yesterday_pct", 0)
                if vs_yesterday < -10:
                    triggers.append(
                        AnalysisTrigger(
                            trigger_type="sudden_drop",
                            severity="warning" if vs_yesterday > -20 else "critical",
                            affected_line=line_code,
                            metric_name="ì „ì¼ ëŒ€ë¹„",
                            metric_value=vs_yesterday,
                            threshold_value=-10,
                            message=f"{line_code} ë¼ì¸ ì „ì¼ ëŒ€ë¹„ {vs_yesterday}% ê°ì†Œ",
                        )
                    )

        return triggers

    # =====================================================
    # 2. ë¹„ê°€ë™ ì›ì¸ ë¶„ì„
    # =====================================================
    async def analyze_downtime_causes(
        self,
        line_code: str,
        target_date: Optional[date] = None,
        limit: int = 5,
    ) -> dict:
        """
        íŠ¹ì • ë¼ì¸ì˜ ë¹„ê°€ë™ ì›ì¸ Top N ë¶„ì„

        Args:
            line_code: ë¶„ì„ ëŒ€ìƒ ë¼ì¸
            target_date: ë¶„ì„ ë‚ ì§œ
            limit: ìƒìœ„ Nê°œ

        Returns:
            ë¹„ê°€ë™ ì›ì¸ ë¶„ì„ ê²°ê³¼
        """
        if target_date is None:
            target_date = date.today()

        # ë¹„ê°€ë™ ìœ í˜•ë³„ ì§‘ê³„
        query = text("""
            SELECT
                f.event_type,
                SUM(f.event_count) as event_count,
                SUM(f.total_duration_minutes) as total_min,
                AVG(f.avg_duration_minutes) as avg_min,
                e.equipment_code,
                e.name as equipment_name
            FROM bi.fact_equipment_event f
            JOIN bi.dim_equipment e
                ON f.tenant_id = e.tenant_id
                AND f.equipment_code = e.equipment_code
            WHERE f.tenant_id = :tenant_id
              AND f.date = :target_date
              AND e.line_code = :line_code
            GROUP BY f.event_type, e.equipment_code, e.name
            ORDER BY total_min DESC
            LIMIT :limit
        """)

        result = await self.db.execute(
            query,
            {
                "tenant_id": str(self.tenant_id),
                "target_date": target_date,
                "line_code": line_code,
                "limit": limit,
            },
        )
        rows = result.fetchall()

        causes = []
        total_downtime = 0

        for row in rows:
            causes.append({
                "event_type": row.event_type,
                "event_type_label": self._get_event_type_label(row.event_type),
                "equipment_code": row.equipment_code,
                "equipment_name": row.equipment_name,
                "event_count": row.event_count,
                "total_min": _convert_decimal(row.total_min),
                "avg_min": _convert_decimal(row.avg_min),
            })
            total_downtime += row.total_min or 0

        # ë¹„ìœ¨ ê³„ì‚°
        for cause in causes:
            if total_downtime > 0:
                cause["percentage"] = round(100 * cause["total_min"] / float(total_downtime), 1)
            else:
                cause["percentage"] = 0

        return {
            "line_code": line_code,
            "date": target_date.isoformat(),
            "total_downtime_min": float(total_downtime),
            "causes": causes,
            "analysis_summary": self._summarize_downtime_causes(causes),
        }

    def _get_event_type_label(self, event_type: str) -> str:
        """ì´ë²¤íŠ¸ ìœ í˜• ë¼ë²¨"""
        labels = {
            "alarm": "ì•ŒëŒ/ê²½ë³´",
            "breakdown": "ê³ ì¥/ì¥ì• ",
            "maintenance": "ì •ë¹„/PM",
            "setup": "ì…‹ì—…/í’ˆì¢… êµì²´",
            "idle": "ëŒ€ê¸°/ê³µíšŒì „",
        }
        return labels.get(event_type, event_type)

    def _summarize_downtime_causes(self, causes: list[dict]) -> str:
        """ë¹„ê°€ë™ ì›ì¸ ìš”ì•½ ìƒì„±"""
        if not causes:
            return "ë¹„ê°€ë™ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        top_cause = causes[0]
        summary = f"ì£¼ìš” ë¹„ê°€ë™ ì›ì¸: {top_cause['event_type_label']}"
        summary += f" ({top_cause['equipment_name']}, {top_cause['total_min']}ë¶„, {top_cause['percentage']}%)"

        if len(causes) > 1:
            second = causes[1]
            summary += f". 2ìœ„: {second['event_type_label']} ({second['total_min']}ë¶„)"

        return summary

    # =====================================================
    # 3. ë¶ˆëŸ‰ ì›ì¸ ë¶„ì„
    # =====================================================
    async def analyze_defect_distribution(
        self,
        line_code: str,
        target_date: Optional[date] = None,
        limit: int = 5,
    ) -> dict:
        """
        íŠ¹ì • ë¼ì¸ì˜ ë¶ˆëŸ‰ ìœ í˜• ë¶„í¬ ë¶„ì„

        Args:
            line_code: ë¶„ì„ ëŒ€ìƒ ë¼ì¸
            target_date: ë¶„ì„ ë‚ ì§œ
            limit: ìƒìœ„ Nê°œ

        Returns:
            ë¶ˆëŸ‰ ìœ í˜• ë¶„ì„ ê²°ê³¼
        """
        if target_date is None:
            target_date = date.today()

        query = text("""
            SELECT
                f.defect_type,
                SUM(f.defect_qty) as total_qty,
                SUM(f.defect_cost) as total_cost,
                COUNT(DISTINCT f.product_code) as product_count,
                ARRAY_AGG(DISTINCT f.root_cause) FILTER (WHERE f.root_cause IS NOT NULL) as root_causes,
                ARRAY_AGG(DISTINCT p.name) FILTER (WHERE p.name IS NOT NULL) as product_names
            FROM bi.fact_daily_defect f
            LEFT JOIN bi.dim_product p
                ON f.tenant_id = p.tenant_id AND f.product_code = p.product_code
            WHERE f.tenant_id = :tenant_id
              AND f.date = :target_date
              AND f.line_code = :line_code
            GROUP BY f.defect_type
            ORDER BY total_qty DESC
            LIMIT :limit
        """)

        result = await self.db.execute(
            query,
            {
                "tenant_id": str(self.tenant_id),
                "target_date": target_date,
                "line_code": line_code,
                "limit": limit,
            },
        )
        rows = result.fetchall()

        defects = []
        total_defect = 0

        for row in rows:
            defects.append({
                "defect_type": row.defect_type,
                "total_qty": _convert_decimal(row.total_qty),
                "total_cost": _convert_decimal(row.total_cost),
                "product_count": row.product_count,
                "root_causes": row.root_causes or [],
                "product_names": (row.product_names or [])[:3],  # ìµœëŒ€ 3ê°œ
            })
            total_defect += row.total_qty or 0

        # ë¹„ìœ¨ ê³„ì‚°
        for defect in defects:
            if total_defect > 0:
                defect["percentage"] = round(100 * defect["total_qty"] / float(total_defect), 1)
            else:
                defect["percentage"] = 0

        return {
            "line_code": line_code,
            "date": target_date.isoformat(),
            "total_defect_qty": float(total_defect),
            "defect_types": defects,
            "analysis_summary": self._summarize_defect_distribution(defects),
        }

    def _summarize_defect_distribution(self, defects: list[dict]) -> str:
        """ë¶ˆëŸ‰ ìœ í˜• ìš”ì•½ ìƒì„±"""
        if not defects:
            return "ë¶ˆëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        top_defect = defects[0]
        summary = f"ì£¼ìš” ë¶ˆëŸ‰ ìœ í˜•: {top_defect['defect_type']} ({top_defect['total_qty']}EA, {top_defect['percentage']}%)"

        if top_defect.get("root_causes"):
            summary += f". ì›ì¸: {', '.join(top_defect['root_causes'][:2])}"

        return summary

    # =====================================================
    # 4. ë³€ë™ ì›ì¸ ë¶„ì„
    # =====================================================
    async def analyze_change_causes(
        self,
        line_code: str,
        target_date: Optional[date] = None,
    ) -> dict:
        """
        ì „ì¼ ëŒ€ë¹„ ê¸‰ê²©í•œ ë³€ë™ ì›ì¸ ë¶„ì„

        Args:
            line_code: ë¶„ì„ ëŒ€ìƒ ë¼ì¸
            target_date: ê¸°ì¤€ ë‚ ì§œ

        Returns:
            ë³€ë™ ì›ì¸ ë¶„ì„ ê²°ê³¼
        """
        if target_date is None:
            target_date = date.today()

        yesterday = target_date - timedelta(days=1)

        # ì˜¤ëŠ˜ vs ì–´ì œ ë¹„êµ
        query = text("""
            WITH today AS (
                SELECT
                    SUM(total_qty) as total_qty,
                    SUM(good_qty) as good_qty,
                    SUM(defect_qty) as defect_qty,
                    SUM(downtime_minutes) as downtime_min,
                    SUM(runtime_minutes) as runtime_min
                FROM bi.fact_daily_production
                WHERE tenant_id = :tenant_id
                  AND date = :today
                  AND line_code = :line_code
            ),
            yesterday AS (
                SELECT
                    SUM(total_qty) as total_qty,
                    SUM(good_qty) as good_qty,
                    SUM(defect_qty) as defect_qty,
                    SUM(downtime_minutes) as downtime_min,
                    SUM(runtime_minutes) as runtime_min
                FROM bi.fact_daily_production
                WHERE tenant_id = :tenant_id
                  AND date = :yesterday
                  AND line_code = :line_code
            )
            SELECT
                COALESCE(t.total_qty, 0) as today_qty,
                COALESCE(y.total_qty, 0) as yesterday_qty,
                COALESCE(t.downtime_min, 0) as today_downtime,
                COALESCE(y.downtime_min, 0) as yesterday_downtime,
                COALESCE(t.runtime_min, 0) as today_runtime,
                COALESCE(y.runtime_min, 0) as yesterday_runtime,
                COALESCE(t.defect_qty, 0) as today_defect,
                COALESCE(y.defect_qty, 0) as yesterday_defect
            FROM today t, yesterday y
        """)

        result = await self.db.execute(
            query,
            {
                "tenant_id": str(self.tenant_id),
                "today": target_date,
                "yesterday": yesterday,
                "line_code": line_code,
            },
        )
        row = result.fetchone()

        if not row:
            return {
                "line_code": line_code,
                "analysis_summary": "ë¹„êµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.",
            }

        today_qty = float(row.today_qty or 0)
        yesterday_qty = float(row.yesterday_qty or 0)
        qty_change = (
            round(100 * (today_qty - yesterday_qty) / yesterday_qty, 1)
            if yesterday_qty > 0 else 0
        )

        today_downtime = float(row.today_downtime or 0)
        yesterday_downtime = float(row.yesterday_downtime or 0)
        downtime_change = today_downtime - yesterday_downtime

        today_defect = float(row.today_defect or 0)
        yesterday_defect = float(row.yesterday_defect or 0)
        defect_change = today_defect - yesterday_defect

        # ë³€ë™ ì›ì¸ ì¶”ë¡ 
        causes = []
        if downtime_change > 30:
            causes.append(f"ë¹„ê°€ë™ ì‹œê°„ ì¦ê°€ (+{downtime_change:.0f}ë¶„)")
        if defect_change > 10:
            causes.append(f"ë¶ˆëŸ‰ ì¦ê°€ (+{defect_change:.0f}EA)")

        return {
            "line_code": line_code,
            "date": target_date.isoformat(),
            "yesterday_date": yesterday.isoformat(),
            "metrics": {
                "qty_change_pct": qty_change,
                "today_qty": today_qty,
                "yesterday_qty": yesterday_qty,
                "downtime_change_min": downtime_change,
                "defect_change": defect_change,
            },
            "possible_causes": causes,
            "analysis_summary": self._summarize_change_causes(qty_change, causes),
        }

    def _summarize_change_causes(self, qty_change: float, causes: list[str]) -> str:
        """ë³€ë™ ì›ì¸ ìš”ì•½ ìƒì„±"""
        direction = "ê°ì†Œ" if qty_change < 0 else "ì¦ê°€"
        summary = f"ì „ì¼ ëŒ€ë¹„ ìƒì‚°ëŸ‰ {abs(qty_change)}% {direction}"

        if causes:
            summary += f". ì£¼ìš” ì›ì¸: {', '.join(causes)}"
        else:
            summary += ". íŠ¹ì´ì‚¬í•­ ì—†ìŒ"

        return summary

    # =====================================================
    # 5. ì¢…í•© ì—°ê´€ ë¶„ì„ ì‹¤í–‰
    # =====================================================
    async def run_correlation_analysis(
        self,
        production_data: list[dict],
        comparison_data: dict,
        thresholds: dict,
        target_date: Optional[date] = None,
    ) -> dict:
        """
        íŠ¸ë¦¬ê±° ê°ì§€ ë° ì—°ê´€ ë¶„ì„ ì¢…í•© ì‹¤í–‰

        Args:
            production_data: ë¼ì¸ë³„ ìƒì‚° í˜„í™©
            comparison_data: ì „ì¼/ì „ì£¼ ëŒ€ë¹„ ë°ì´í„°
            thresholds: KPI ê¸°ì¤€ê°’
            target_date: ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ

        Returns:
            ì¢…í•© ë¶„ì„ ê²°ê³¼
        """
        if target_date is None:
            target_date = date.today()

        # 1. íŠ¸ë¦¬ê±° ê°ì§€
        triggers = self.detect_triggers(production_data, comparison_data, thresholds)

        if not triggers:
            return {
                "has_issues": False,
                "triggers": [],
                "analysis_results": {},
                "summary": "ëª¨ë“  ì§€í‘œê°€ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤.",
            }

        # 2. íŠ¸ë¦¬ê±°ë³„ ìƒì„¸ ë¶„ì„
        analysis_results = {}

        for trigger in triggers:
            line_code = trigger.affected_line

            if trigger.trigger_type == "low_achievement" or trigger.trigger_type == "high_downtime":
                # ë¹„ê°€ë™ ì›ì¸ ë¶„ì„
                if line_code not in analysis_results:
                    analysis_results[line_code] = {}
                if "downtime_analysis" not in analysis_results[line_code]:
                    analysis_results[line_code]["downtime_analysis"] = (
                        await self.analyze_downtime_causes(line_code, target_date)
                    )

            elif trigger.trigger_type == "high_defect":
                # ë¶ˆëŸ‰ ë¶„ì„
                if line_code not in analysis_results:
                    analysis_results[line_code] = {}
                if "defect_analysis" not in analysis_results[line_code]:
                    analysis_results[line_code]["defect_analysis"] = (
                        await self.analyze_defect_distribution(line_code, target_date)
                    )

            elif trigger.trigger_type == "sudden_drop":
                # ë³€ë™ ì›ì¸ ë¶„ì„
                if line_code not in analysis_results:
                    analysis_results[line_code] = {}
                if "change_analysis" not in analysis_results[line_code]:
                    analysis_results[line_code]["change_analysis"] = (
                        await self.analyze_change_causes(line_code, target_date)
                    )

        # 3. ì „ì²´ ìš”ì•½ ìƒì„±
        critical_count = sum(1 for t in triggers if t.severity == "critical")
        warning_count = sum(1 for t in triggers if t.severity == "warning")

        summary_parts = []
        if critical_count > 0:
            summary_parts.append(f"ğŸš¨ ê¸´ê¸‰ {critical_count}ê±´")
        if warning_count > 0:
            summary_parts.append(f"âš ï¸ ì£¼ì˜ {warning_count}ê±´")

        return {
            "has_issues": True,
            "triggers": [
                {
                    "type": t.trigger_type,
                    "severity": t.severity,
                    "line_code": t.affected_line,
                    "metric_name": t.metric_name,
                    "metric_value": t.metric_value,
                    "threshold_value": t.threshold_value,
                    "message": t.message,
                }
                for t in triggers
            ],
            "analysis_results": analysis_results,
            "summary": f"ì´ìƒ ì§•í›„ ê°ì§€: {', '.join(summary_parts)}",
            "critical_count": critical_count,
            "warning_count": warning_count,
        }
